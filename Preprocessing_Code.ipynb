{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99be733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Libraries\n",
    "import random,time,calendar\n",
    "import math,copy\n",
    "import sys,os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#SMOTE - Needed for FairMASK.\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#Train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Metrics\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "#Preprocessing library.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Fairness Metrics\n",
    "from aif360.datasets import BinaryLabelDataset, StructuredDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54abe60b",
   "metadata": {},
   "source": [
    "## COMPAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa12f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset\n",
    "dataset_orig = pd.read_csv('../data/compas-scores-two-years.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd4b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop categorical features\n",
    "## Removed two duplicate coumns - 'decile_score','priors_count'\n",
    "dataset_orig = dataset_orig.drop(['id','name','first','last','compas_screening_date',\n",
    "                                  'dob','age','juv_fel_count','decile_score',\n",
    "                                  'juv_misd_count','juv_other_count','days_b_screening_arrest',\n",
    "                                  'c_jail_in','c_jail_out','c_case_number','c_offense_date','c_arrest_date',\n",
    "                                  'c_days_from_compas','c_charge_desc','is_recid','r_case_number','r_charge_degree',\n",
    "                                  'r_days_from_arrest','r_offense_date','r_charge_desc','r_jail_in','r_jail_out',\n",
    "                                  'violent_recid','is_violent_recid','vr_case_number','vr_charge_degree','vr_offense_date',\n",
    "                                  'vr_charge_desc','type_of_assessment','decile_score','score_text','screening_date',\n",
    "                                  'v_type_of_assessment','v_decile_score','v_score_text','v_screening_date','in_custody',\n",
    "                                  'out_custody','start','end','event'],axis=1)\n",
    "\n",
    "## Drop NULL values\n",
    "dataset_orig = dataset_orig.dropna()\n",
    "\n",
    "\n",
    "## Change symbolics to numerics\n",
    "dataset_orig['sex'] = np.where(dataset_orig['sex'] == 'Female', 1, 0)\n",
    "dataset_orig['race'] = np.where(dataset_orig['race'] != 'Caucasian', 0, 1)\n",
    "dataset_orig['priors_count'] = np.where((dataset_orig['priors_count'] >= 1 ) & (dataset_orig['priors_count'] <= 3), 3, dataset_orig['priors_count'])\n",
    "dataset_orig['priors_count'] = np.where(dataset_orig['priors_count'] > 3, 4, dataset_orig['priors_count'])\n",
    "dataset_orig['age_cat'] = np.where(dataset_orig['age_cat'] == 'Greater than 45',45,dataset_orig['age_cat'])\n",
    "dataset_orig['age_cat'] = np.where(dataset_orig['age_cat'] == '25 - 45', 25, dataset_orig['age_cat'])\n",
    "dataset_orig['age_cat'] = np.where(dataset_orig['age_cat'] == 'Less than 25', 0, dataset_orig['age_cat'])\n",
    "dataset_orig['c_charge_degree'] = np.where(dataset_orig['c_charge_degree'] == 'F', 1, 0)\n",
    "\n",
    "## Rename class column\n",
    "dataset_orig.rename(index=str, columns={\"two_year_recid\": \"Probability\"}, inplace=True)\n",
    "\n",
    "# Here did not rec means 0 is the favorable lable\n",
    "dataset_orig['Probability'] = np.where(dataset_orig['Probability'] == 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd06dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig.to_csv('processed_compas.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79089cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20976f58",
   "metadata": {},
   "source": [
    "# Adult Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9dfb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset\n",
    "dataset_orig = pd.read_csv('../data/adult.data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b4c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop NULL values\n",
    "dataset_orig = dataset_orig.dropna()\n",
    "\n",
    "## Drop categorical features\n",
    "dataset_orig = dataset_orig.drop(['workclass','fnlwgt','education','marital-status','occupation','relationship','native-country'],axis=1)\n",
    "        \n",
    "## Change symbolics to numerics\n",
    "dataset_orig['sex'] = np.where(dataset_orig['sex'] == ' Male', 1, 0)\n",
    "dataset_orig['race'] = np.where(dataset_orig['race'] != ' White', 0, 1)\n",
    "dataset_orig['Probability'] = np.where(dataset_orig['Probability'] == ' <=50K', 0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0547b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save dataset\n",
    "dataset_orig.to_csv('processed_adult.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa1dd5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c322cfca",
   "metadata": {},
   "source": [
    "# German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62abe8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset\n",
    "dataset_orig = pd.read_csv('../data/GermanData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0328ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop categorical features\n",
    "dataset_orig = dataset_orig.drop(['1','2','4','5','8','10','11','12','14','15','16','17','18','19','20'],axis=1)\n",
    "\n",
    "## Drop NULL values\n",
    "dataset_orig = dataset_orig.dropna()\n",
    "\n",
    "\n",
    "## Change symbolics to numerics\n",
    "dataset_orig['sex'] = np.where(dataset_orig['sex'] == 'A91', 1, dataset_orig['sex'])\n",
    "dataset_orig['sex'] = np.where(dataset_orig['sex'] == 'A92', 0, dataset_orig['sex'])\n",
    "dataset_orig['sex'] = np.where(dataset_orig['sex'] == 'A93', 1, dataset_orig['sex'])\n",
    "dataset_orig['sex'] = np.where(dataset_orig['sex'] == 'A94', 1, dataset_orig['sex'])\n",
    "dataset_orig['sex'] = np.where(dataset_orig['sex'] == 'A95', 0, dataset_orig['sex'])\n",
    "\n",
    "# mean = dataset_orig.loc[:,\"age\"].mean()\n",
    "# dataset_orig['age'] = np.where(dataset_orig['age'] >= mean, 1, 0)\n",
    "dataset_orig['age'] = np.where(dataset_orig['age'] >= 25, 1, 0)\n",
    "\n",
    "dataset_orig['credit_history'] = np.where(dataset_orig['credit_history'] == 'A30', 1, dataset_orig['credit_history'])\n",
    "dataset_orig['credit_history'] = np.where(dataset_orig['credit_history'] == 'A31', 1, dataset_orig['credit_history'])\n",
    "dataset_orig['credit_history'] = np.where(dataset_orig['credit_history'] == 'A32', 1, dataset_orig['credit_history'])\n",
    "dataset_orig['credit_history'] = np.where(dataset_orig['credit_history'] == 'A33', 2, dataset_orig['credit_history'])\n",
    "dataset_orig['credit_history'] = np.where(dataset_orig['credit_history'] == 'A34', 3, dataset_orig['credit_history'])\n",
    "\n",
    "dataset_orig['savings'] = np.where(dataset_orig['savings'] == 'A61', 1, dataset_orig['savings'])\n",
    "dataset_orig['savings'] = np.where(dataset_orig['savings'] == 'A62', 1, dataset_orig['savings'])\n",
    "dataset_orig['savings'] = np.where(dataset_orig['savings'] == 'A63', 2, dataset_orig['savings'])\n",
    "dataset_orig['savings'] = np.where(dataset_orig['savings'] == 'A64', 2, dataset_orig['savings'])\n",
    "dataset_orig['savings'] = np.where(dataset_orig['savings'] == 'A65', 3, dataset_orig['savings'])\n",
    "\n",
    "dataset_orig['employment'] = np.where(dataset_orig['employment'] == 'A72', 1, dataset_orig['employment'])\n",
    "dataset_orig['employment'] = np.where(dataset_orig['employment'] == 'A73', 1, dataset_orig['employment'])\n",
    "dataset_orig['employment'] = np.where(dataset_orig['employment'] == 'A74', 2, dataset_orig['employment'])\n",
    "dataset_orig['employment'] = np.where(dataset_orig['employment'] == 'A75', 2, dataset_orig['employment'])\n",
    "dataset_orig['employment'] = np.where(dataset_orig['employment'] == 'A71', 3, dataset_orig['employment'])\n",
    "\n",
    "## ADD Columns\n",
    "dataset_orig['credit_history=Delay'] = 0\n",
    "dataset_orig['credit_history=None/Paid'] = 0\n",
    "dataset_orig['credit_history=Other'] = 0\n",
    "\n",
    "dataset_orig['credit_history=Delay'] = np.where(dataset_orig['credit_history'] == 1, 1, dataset_orig['credit_history=Delay'])\n",
    "dataset_orig['credit_history=None/Paid'] = np.where(dataset_orig['credit_history'] == 2, 1, dataset_orig['credit_history=None/Paid'])\n",
    "dataset_orig['credit_history=Other'] = np.where(dataset_orig['credit_history'] == 3, 1, dataset_orig['credit_history=Other'])\n",
    "\n",
    "dataset_orig['savings=500+'] = 0\n",
    "dataset_orig['savings=<500'] = 0\n",
    "dataset_orig['savings=Unknown/None'] = 0\n",
    "\n",
    "dataset_orig['savings=500+'] = np.where(dataset_orig['savings'] == 1, 1, dataset_orig['savings=500+'])\n",
    "dataset_orig['savings=<500'] = np.where(dataset_orig['savings'] == 2, 1, dataset_orig['savings=<500'])\n",
    "dataset_orig['savings=Unknown/None'] = np.where(dataset_orig['savings'] == 3, 1, dataset_orig['savings=Unknown/None'])\n",
    "\n",
    "dataset_orig['employment=1-4 years'] = 0\n",
    "dataset_orig['employment=4+ years'] = 0\n",
    "dataset_orig['employment=Unemployed'] = 0\n",
    "\n",
    "dataset_orig['employment=1-4 years'] = np.where(dataset_orig['employment'] == 1, 1, dataset_orig['employment=1-4 years'])\n",
    "dataset_orig['employment=4+ years'] = np.where(dataset_orig['employment'] == 2, 1, dataset_orig['employment=4+ years'])\n",
    "dataset_orig['employment=Unemployed'] = np.where(dataset_orig['employment'] == 3, 1, dataset_orig['employment=Unemployed'])\n",
    "\n",
    "\n",
    "dataset_orig = dataset_orig.drop(['credit_history','savings','employment'],axis=1)\n",
    "## In dataset 1 means good, 2 means bad for probability. I change 2 to 0\n",
    "dataset_orig['Probability'] = np.where(dataset_orig['Probability'] == 2, 0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39aa217",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save dataset\n",
    "dataset_orig.to_csv('processed_german.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6864d51f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15c6dde0",
   "metadata": {},
   "source": [
    "## Heart Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b52c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset\n",
    "dataset_orig = pd.read_csv('../data/processed.cleveland.data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc5bfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop NULL values\n",
    "dataset_orig = dataset_orig.dropna()\n",
    "\n",
    "## calculate mean of age column\n",
    "mean = dataset_orig.loc[:,\"age\"].mean()\n",
    "dataset_orig['age'] = np.where(dataset_orig['age'] >= mean, 1, 0)\n",
    "\n",
    "## Make goal column binary\n",
    "dataset_orig['Probability'] = np.where(dataset_orig['Probability'] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9710d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save dataset\n",
    "dataset_orig.to_csv('processed_heart.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86ae2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ce6abd0",
   "metadata": {},
   "source": [
    "## Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2545df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig = pd.read_csv('../data/Student.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313ec636",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig = dataset_orig.drop(['school','address','famsize','Pstatus','Mjob','Fjob','reason','guardian'],axis=1)\n",
    "\n",
    "## Drop NULL values\n",
    "dataset_orig = dataset_orig.dropna()\n",
    "\n",
    "## calculate mean of age column\n",
    "mean = dataset_orig.loc[:,\"age\"].mean()\n",
    "\n",
    "dataset_orig['sex'] = np.where(dataset_orig['sex'] == 'M', 1, 0)\n",
    "\n",
    "dataset_orig['age'] = np.where(dataset_orig['age'] >= mean, 1, 0)\n",
    "dataset_orig['schoolsup'] = np.where(dataset_orig['schoolsup'] == 'yes', 1, 0)\n",
    "dataset_orig['famsup'] = np.where(dataset_orig['famsup'] == 'yes', 1, 0)\n",
    "dataset_orig['paid'] = np.where(dataset_orig['paid'] == 'yes', 1, 0)\n",
    "dataset_orig['activities'] = np.where(dataset_orig['activities'] == 'yes', 1, 0)\n",
    "dataset_orig['nursery'] = np.where(dataset_orig['nursery'] == 'yes', 1, 0)\n",
    "dataset_orig['higher'] = np.where(dataset_orig['higher'] == 'yes', 1, 0)\n",
    "dataset_orig['internet'] = np.where(dataset_orig['internet'] == 'yes', 1, 0)\n",
    "dataset_orig['romantic'] = np.where(dataset_orig['romantic'] == 'yes', 1, 0)\n",
    "\n",
    "mean = dataset_orig.loc[:,\"G1\"].mean()\n",
    "dataset_orig['G1'] = np.where(dataset_orig['G1'] >= mean, 1, 0)\n",
    "\n",
    "mean = dataset_orig.loc[:,\"G2\"].mean()\n",
    "dataset_orig['G2'] = np.where(dataset_orig['G2'] >= mean, 1, 0)\n",
    "\n",
    "## Make goal column binary\n",
    "mean = dataset_orig.loc[:,\"Probability\"].mean()\n",
    "dataset_orig['Probability'] = np.where(dataset_orig['Probability'] >= mean, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99d782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save dataset\n",
    "dataset_orig.to_csv('processed_student.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c847ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc7426bb",
   "metadata": {},
   "source": [
    "## Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da631019",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset\n",
    "dataset_orig = pd.read_csv('../data/bank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4c9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop categorical features\n",
    "\n",
    "dataset_orig = dataset_orig.drop(['job','marital','education','contact','month','poutcome'],axis=1)\n",
    "\n",
    "## Drop NULL values\n",
    "dataset_orig = dataset_orig.dropna()\n",
    "\n",
    "## calculate mean of age column\n",
    "mean = dataset_orig.loc[:,\"age\"].mean()\n",
    "dataset_orig['age'] = np.where(dataset_orig['age'] >= mean, 1, 0)\n",
    "dataset_orig['default'] = np.where(dataset_orig['default'] == 'yes', 1, 0)\n",
    "dataset_orig['housing'] = np.where(dataset_orig['housing'] == 'yes', 1, 0)\n",
    "dataset_orig['loan'] = np.where(dataset_orig['loan'] == 'yes', 1, 0)\n",
    "\n",
    "## Make goal column binary\n",
    "dataset_orig['Probability'] = np.where(dataset_orig['Probability'] == 'yes', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622ebc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save dataset\n",
    "dataset_orig.to_csv('processed_bank.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3076f119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e90e45a9",
   "metadata": {},
   "source": [
    "## Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14df9009",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset\n",
    "dataset_orig = pd.read_csv('../data/default_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2999d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop NULL values\n",
    "dataset_orig = dataset_orig.dropna()\n",
    "\n",
    "\n",
    "\n",
    "## Change column values\n",
    "dataset_orig['sex'] = np.where(dataset_orig['sex'] == 2, 0,1)\n",
    "dataset_orig.rename(columns={'default payment next month':'Probability'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e867a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save dataset\n",
    "dataset_orig.to_csv('processed_default.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ae9ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afdcff71",
   "metadata": {},
   "source": [
    "## MEPS15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ac2027",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from aif360.datasets import MEPSDataset19,MEPSDataset21\n",
    "\n",
    "dataset_orig = MEPSDataset19()\n",
    "dataset_orig = dataset_orig.convert_to_dataframe()[0]\n",
    "\n",
    "dataset_orig.rename(index=str, columns={\"UTILIZATION\": \"Probability\"}, inplace=True)\n",
    "dataset_orig.rename(index=str, columns={\"RACE\": \"race\"}, inplace=True)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dataset_orig = pd.DataFrame(scaler.fit_transform(dataset_orig),columns = dataset_orig.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4feb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save dataset\n",
    "dataset_orig.to_csv('processed_meps15.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c60b9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c0203c5",
   "metadata": {},
   "source": [
    "## MEPS16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59da0cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "from aif360.datasets import MEPSDataset19,MEPSDataset21\n",
    "\n",
    "dataset_orig = MEPSDataset21()\n",
    "dataset_orig = dataset_orig.convert_to_dataframe()[0]\n",
    "\n",
    "dataset_orig.rename(index=str, columns={\"UTILIZATION\": \"Probability\"}, inplace=True)\n",
    "dataset_orig.rename(index=str, columns={\"RACE\": \"race\"}, inplace=True)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dataset_orig = pd.DataFrame(scaler.fit_transform(dataset_orig),columns = dataset_orig.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1088c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save dataset\n",
    "dataset_orig.to_csv('processed_meps16.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb97ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e7c5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
