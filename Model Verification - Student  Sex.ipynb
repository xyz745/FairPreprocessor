{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46ffbdcd",
   "metadata": {},
   "source": [
    "## Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb7cf3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_attribute = 'sex'\n",
    "dataset_name='Student'\n",
    "folder_name='student_sex'\n",
    "time_stamp=1708792630\n",
    "random_state=range(0,11)\n",
    "\n",
    "test_size_input=.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec21c2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfba2776",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c9945d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "#Basic Libraries\n",
    "import random,time,calendar\n",
    "import math,copy\n",
    "import sys,os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#SMOTE - Needed for FairMASK.\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#Train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#OverSampling Technique\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#Performance Metrics\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "#Preprocessing library.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Fairness Metrics\n",
    "from aif360.datasets import BinaryLabelDataset, StructuredDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "\n",
    "#TDD\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca6954f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a5dc142",
   "metadata": {},
   "source": [
    "## To hide warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b06c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb3b87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "772f469e",
   "metadata": {},
   "source": [
    "## FairSMOTE and FairGenerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8b0c3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fair_preprocessor_Samples import fair_preprocessor_samples\n",
    "#from Generate_Samples import generate_samples\n",
    "\n",
    "##FairWay\n",
    "from remove_bias import remove_bias\n",
    "from flash import flash_fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d323745c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a28ea8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Template------------->\n",
    "##Performance Metrics\n",
    "##Fairness Metrics\n",
    "\n",
    "#*--------------------------------------------------*\n",
    "#**-----------For Storing Defaults Results---------**\n",
    "#*--------------------------------------------------*\n",
    "\n",
    "#Default-Logistic Regression - for storing results of logistic regression.\n",
    "default_lgr_recall,default_lgr_far,default_lgr_precision,default_lgr_accuracy,default_lgr_f1score=[],[],[],[],[]\n",
    "default_lgr_aod,default_lgr_eod,default_lgr_spd,default_lgr_di=[],[],[],[]\n",
    "\n",
    "#Default-SVM - for storing results of Support Vector Machine.\n",
    "default_svm_recall,default_svm_far,default_svm_precision,default_svm_accuracy,default_svm_f1score=[],[],[],[],[]\n",
    "default_svm_aod,default_svm_eod,default_svm_spd,default_svm_di=[],[],[],[]\n",
    "\n",
    "#Default-Random Forest - for storing results of Random Forest.\n",
    "default_rf_recall,default_rf_far,default_rf_precision,default_rf_accuracy,default_rf_f1score=[],[],[],[],[]\n",
    "default_rf_aod,default_rf_eod,default_rf_spd,default_rf_di=[],[],[],[]\n",
    "\n",
    "#Default-Naive Bayes - for storing results of Naive Bayes.\n",
    "default_nb_recall,default_nb_far,default_nb_precision,default_nb_accuracy,default_nb_f1score=[],[],[],[],[]\n",
    "default_nb_aod,default_nb_eod,default_nb_spd,default_nb_di=[],[],[],[]\n",
    "\n",
    "#Default-Multi layer perceptron - for storing results of Multi layer perceptron.\n",
    "default_mlp_recall,default_mlp_far,default_mlp_precision,default_mlp_accuracy,default_mlp_f1score=[],[],[],[],[]\n",
    "default_mlp_aod,default_mlp_eod,default_mlp_spd,default_mlp_di=[],[],[],[]\n",
    "\n",
    "#Default-Decision Trees - for storing results of Decision Tree.\n",
    "default_dt_recall,default_dt_far,default_dt_precision,default_dt_accuracy,default_dt_f1score=[],[],[],[],[]\n",
    "default_dt_aod,default_dt_eod,default_dt_spd,default_dt_di=[],[],[],[]\n",
    "\n",
    "#Default-K Nearest Neighbour - for storing results of K nearest neighbour.\n",
    "default_knn_recall,default_knn_far,default_knn_precision,default_knn_accuracy,default_knn_f1score=[],[],[],[],[]\n",
    "default_knn_aod,default_knn_eod,default_knn_spd,default_knn_di=[],[],[],[]\n",
    "\n",
    "#*--------------------------------------------------*\n",
    "#**-----------Fair SMOTE Results-------------------**\n",
    "#*--------------------------------------------------*\n",
    "\n",
    "#Fair-Smote-Logistic Regression - for storing results of logistic regression.\n",
    "fair_smote_lgr_recall,fair_smote_lgr_far,fair_smote_lgr_precision,fair_smote_lgr_accuracy,fair_smote_lgr_f1score=[],[],[],[],[]\n",
    "fair_smote_lgr_aod,fair_smote_lgr_eod,fair_smote_lgr_spd,fair_smote_lgr_di=[],[],[],[]\n",
    "\n",
    "#Fair-Smote-SVM - for storing results of Support Vector Machine.\n",
    "fair_smote_svm_recall,fair_smote_svm_far,fair_smote_svm_precision,fair_smote_svm_accuracy,fair_smote_svm_f1score=[],[],[],[],[]\n",
    "fair_smote_svm_aod,fair_smote_svm_eod,fair_smote_svm_spd,fair_smote_svm_di=[],[],[],[]\n",
    "\n",
    "#Fair-Smote-Random Forest - for storing results of Random Forest.\n",
    "fair_smote_rf_recall,fair_smote_rf_far,fair_smote_rf_precision,fair_smote_rf_accuracy,fair_smote_rf_f1score=[],[],[],[],[]\n",
    "fair_smote_rf_aod,fair_smote_rf_eod,fair_smote_rf_spd,fair_smote_rf_di=[],[],[],[]\n",
    "\n",
    "#Fair-Smote-Naive Bayes - for storing results of Naive Bayes.\n",
    "fair_smote_nb_recall,fair_smote_nb_far,fair_smote_nb_precision,fair_smote_nb_accuracy,fair_smote_nb_f1score=[],[],[],[],[]\n",
    "fair_smote_nb_aod,fair_smote_nb_eod,fair_smote_nb_spd,fair_smote_nb_di=[],[],[],[]\n",
    "\n",
    "#Fair-Smote-Multi layer perceptron - for storing results of Multi layer perceptron.\n",
    "fair_smote_mlp_recall,fair_smote_mlp_far,fair_smote_mlp_precision,fair_smote_mlp_accuracy,fair_smote_mlp_f1score=[],[],[],[],[]\n",
    "fair_smote_mlp_aod,fair_smote_mlp_eod,fair_smote_mlp_spd,fair_smote_mlp_di=[],[],[],[]\n",
    "\n",
    "#Fair-Smote-Decision Trees - for storing results of Decision Tree.\n",
    "fair_smote_dt_recall,fair_smote_dt_far,fair_smote_dt_precision,fair_smote_dt_accuracy,fair_smote_dt_f1score=[],[],[],[],[]\n",
    "fair_smote_dt_aod,fair_smote_dt_eod,fair_smote_dt_spd,fair_smote_dt_di=[],[],[],[]\n",
    "\n",
    "#Fair-Smote-K Nearest Neighbour - for storing results of K nearest neighbour.\n",
    "fair_smote_knn_recall,fair_smote_knn_far,fair_smote_knn_precision,fair_smote_knn_accuracy,fair_smote_knn_f1score=[],[],[],[],[]\n",
    "fair_smote_knn_aod,fair_smote_knn_eod,fair_smote_knn_spd,fair_smote_knn_di=[],[],[],[]\n",
    "\n",
    "#*--------------------------------------------------*\n",
    "#**-----------Fair Generate Results----------------**\n",
    "#*--------------------------------------------------*\n",
    "\n",
    "#Fair-Generate-Logistic Regression - for storing results of logistic regression.\n",
    "fair_preprocessor_lgr_recall,fair_preprocessor_lgr_far,fair_preprocessor_lgr_precision,fair_preprocessor_lgr_accuracy,fair_preprocessor_lgr_f1score=[],[],[],[],[]\n",
    "fair_preprocessor_lgr_aod,fair_preprocessor_lgr_eod,fair_preprocessor_lgr_spd,fair_preprocessor_lgr_di=[],[],[],[]\n",
    "\n",
    "#Fair-Generate-SVM - for storing results of Support Vector Machine.\n",
    "fair_preprocessor_svm_recall,fair_preprocessor_svm_far,fair_preprocessor_svm_precision,fair_preprocessor_svm_accuracy,fair_preprocessor_svm_f1score=[],[],[],[],[]\n",
    "fair_preprocessor_svm_aod,fair_preprocessor_svm_eod,fair_preprocessor_svm_spd,fair_preprocessor_svm_di=[],[],[],[]\n",
    "\n",
    "#Fair-Generate-Random Forest - for storing results of Random Forest.\n",
    "fair_preprocessor_rf_recall,fair_preprocessor_rf_far,fair_preprocessor_rf_precision,fair_preprocessor_rf_accuracy,fair_preprocessor_rf_f1score=[],[],[],[],[]\n",
    "fair_preprocessor_rf_aod,fair_preprocessor_rf_eod,fair_preprocessor_rf_spd,fair_preprocessor_rf_di=[],[],[],[]\n",
    "\n",
    "#Fair-Generate-Naive Bayes - for storing results of Naive Bayes.\n",
    "fair_preprocessor_nb_recall,fair_preprocessor_nb_far,fair_preprocessor_nb_precision,fair_preprocessor_nb_accuracy,fair_preprocessor_nb_f1score=[],[],[],[],[]\n",
    "fair_preprocessor_nb_aod,fair_preprocessor_nb_eod,fair_preprocessor_nb_spd,fair_preprocessor_nb_di=[],[],[],[]\n",
    "\n",
    "#Fair-Generate-Multi layer perceptron - for storing results of Multi layer perceptron.\n",
    "fair_preprocessor_mlp_recall,fair_preprocessor_mlp_far,fair_preprocessor_mlp_precision,fair_preprocessor_mlp_accuracy,fair_preprocessor_mlp_f1score=[],[],[],[],[]\n",
    "fair_preprocessor_mlp_aod,fair_preprocessor_mlp_eod,fair_preprocessor_mlp_spd,fair_preprocessor_mlp_di=[],[],[],[]\n",
    "\n",
    "#Fair-Generate-Decision Trees - for storing results of Decision Tree.\n",
    "fair_preprocessor_dt_recall,fair_preprocessor_dt_far,fair_preprocessor_dt_precision,fair_preprocessor_dt_accuracy,fair_preprocessor_dt_f1score=[],[],[],[],[]\n",
    "fair_preprocessor_dt_aod,fair_preprocessor_dt_eod,fair_preprocessor_dt_spd,fair_preprocessor_dt_di=[],[],[],[]\n",
    "\n",
    "#Fair-Generate-K Nearest Neighbour - for storing results of K nearest neighbour.\n",
    "fair_preprocessor_knn_recall,fair_preprocessor_knn_far,fair_preprocessor_knn_precision,fair_preprocessor_knn_accuracy,fair_preprocessor_knn_f1score=[],[],[],[],[]\n",
    "fair_preprocessor_knn_aod,fair_preprocessor_knn_eod,fair_preprocessor_knn_spd,fair_preprocessor_knn_di=[],[],[],[]\n",
    "\n",
    "#*--------------------------------------------------*\n",
    "#**-------------FairMask Results-------------------**\n",
    "#*--------------------------------------------------*\n",
    "\n",
    "#Fair-Mask-Logistic Regression - for storing results of logistic regression.\n",
    "fair_mask_lgr_recall,fair_mask_lgr_far,fair_mask_lgr_precision,fair_mask_lgr_accuracy,fair_mask_lgr_f1score=[],[],[],[],[]\n",
    "fair_mask_lgr_aod,fair_mask_lgr_eod,fair_mask_lgr_spd,fair_mask_lgr_di=[],[],[],[]\n",
    "\n",
    "#Fair-Mask-SVM - for storing results of Support Vector Machine.\n",
    "fair_mask_svm_recall,fair_mask_svm_far,fair_mask_svm_precision,fair_mask_svm_accuracy,fair_mask_svm_f1score=[],[],[],[],[]\n",
    "fair_mask_svm_aod,fair_mask_svm_eod,fair_mask_svm_spd,fair_mask_svm_di=[],[],[],[]\n",
    "\n",
    "#Fair-Mask-Random Forest - for storing results of Random Forest.\n",
    "fair_mask_rf_recall,fair_mask_rf_far,fair_mask_rf_precision,fair_mask_rf_accuracy,fair_mask_rf_f1score=[],[],[],[],[]\n",
    "fair_mask_rf_aod,fair_mask_rf_eod,fair_mask_rf_spd,fair_mask_rf_di=[],[],[],[]\n",
    "\n",
    "#Fair-Mask-Naive Bayes - for storing results of Naive Bayes.\n",
    "fair_mask_nb_recall,fair_mask_nb_far,fair_mask_nb_precision,fair_mask_nb_accuracy,fair_mask_nb_f1score=[],[],[],[],[]\n",
    "fair_mask_nb_aod,fair_mask_nb_eod,fair_mask_nb_spd,fair_mask_nb_di=[],[],[],[]\n",
    "\n",
    "#Fair-Mask-Multi layer perceptron - for storing results of Multi layer perceptron.\n",
    "fair_mask_mlp_recall,fair_mask_mlp_far,fair_mask_mlp_precision,fair_mask_mlp_accuracy,fair_mask_mlp_f1score=[],[],[],[],[]\n",
    "fair_mask_mlp_aod,fair_mask_mlp_eod,fair_mask_mlp_spd,fair_mask_mlp_di=[],[],[],[]\n",
    "\n",
    "#Fair-Mask-Decision Trees - for storing results of Decision Tree.\n",
    "fair_mask_dt_recall,fair_mask_dt_far,fair_mask_dt_precision,fair_mask_dt_accuracy,fair_mask_dt_f1score=[],[],[],[],[]\n",
    "fair_mask_dt_aod,fair_mask_dt_eod,fair_mask_dt_spd,fair_mask_dt_di=[],[],[],[]\n",
    "\n",
    "#Fair-Mask-K Nearest Neighbour - for storing results of K nearest neighbour.\n",
    "fair_mask_knn_recall,fair_mask_knn_far,fair_mask_knn_precision,fair_mask_knn_accuracy,fair_mask_knn_f1score=[],[],[],[],[]\n",
    "fair_mask_knn_aod,fair_mask_knn_eod,fair_mask_knn_spd,fair_mask_knn_di=[],[],[],[]\n",
    "\n",
    "\n",
    "#*--------------------------------------------------*\n",
    "#**-------------FairWay Results-------------------**\n",
    "#*--------------------------------------------------*\n",
    "\n",
    "#Fair-Way-Logistic Regression - for storing results of logistic regression.\n",
    "fair_way_lgr_recall,fair_way_lgr_far,fair_way_lgr_precision,fair_way_lgr_accuracy,fair_way_lgr_f1score=[],[],[],[],[]\n",
    "fair_way_lgr_aod,fair_way_lgr_eod,fair_way_lgr_spd,fair_way_lgr_di=[],[],[],[]\n",
    "\n",
    "#Fair-Way-SVM - for storing results of Support Vector Machine.\n",
    "fair_way_svm_recall,fair_way_svm_far,fair_way_svm_precision,fair_way_svm_accuracy,fair_way_svm_f1score=[],[],[],[],[]\n",
    "fair_way_svm_aod,fair_way_svm_eod,fair_way_svm_spd,fair_way_svm_di=[],[],[],[]\n",
    "\n",
    "#Fair-Way-Random Forest - for storing results of Random Forest.\n",
    "fair_way_rf_recall,fair_way_rf_far,fair_way_rf_precision,fair_way_rf_accuracy,fair_way_rf_f1score=[],[],[],[],[]\n",
    "fair_way_rf_aod,fair_way_rf_eod,fair_way_rf_spd,fair_way_rf_di=[],[],[],[]\n",
    "\n",
    "#Fair-Way-Naive Bayes - for storing results of Naive Bayes.\n",
    "fair_way_nb_recall,fair_way_nb_far,fair_way_nb_precision,fair_way_nb_accuracy,fair_way_nb_f1score=[],[],[],[],[]\n",
    "fair_way_nb_aod,fair_way_nb_eod,fair_way_nb_spd,fair_way_nb_di=[],[],[],[]\n",
    "\n",
    "#Fair-Way-Multi layer perceptron - for storing results of Multi layer perceptron.\n",
    "fair_way_mlp_recall,fair_way_mlp_far,fair_way_mlp_precision,fair_way_mlp_accuracy,fair_way_mlp_f1score=[],[],[],[],[]\n",
    "fair_way_mlp_aod,fair_way_mlp_eod,fair_way_mlp_spd,fair_way_mlp_di=[],[],[],[]\n",
    "\n",
    "#Fair-Way-Decision Trees - for storing results of Decision Tree.\n",
    "fair_way_dt_recall,fair_way_dt_far,fair_way_dt_precision,fair_way_dt_accuracy,fair_way_dt_f1score=[],[],[],[],[]\n",
    "fair_way_dt_aod,fair_way_dt_eod,fair_way_dt_spd,fair_way_dt_di=[],[],[],[]\n",
    "\n",
    "#Fair-Way-K Nearest Neighbour - for storing results of K nearest neighbour.\n",
    "fair_way_knn_recall,fair_way_knn_far,fair_way_knn_precision,fair_way_knn_accuracy,fair_way_knn_f1score=[],[],[],[],[]\n",
    "fair_way_knn_aod,fair_way_knn_eod,fair_way_knn_spd,fair_way_knn_di=[],[],[],[]\n",
    "\n",
    "\n",
    "#*--------------------------------------------------*\n",
    "#**-------------TDD Results-------------------**\n",
    "#*--------------------------------------------------*\n",
    "\n",
    "#TDD-Logistic Regression - for storing results of logistic regression.\n",
    "tdd_lgr_recall,tdd_lgr_far,tdd_lgr_precision,tdd_lgr_accuracy,tdd_lgr_f1score=[],[],[],[],[]\n",
    "tdd_lgr_aod,tdd_lgr_eod,tdd_lgr_spd,tdd_lgr_di=[],[],[],[]\n",
    "\n",
    "#TDD-SVM - for storing results of Support Vector Machine.\n",
    "tdd_svm_recall,tdd_svm_far,tdd_svm_precision,tdd_svm_accuracy,tdd_svm_f1score=[],[],[],[],[]\n",
    "tdd_svm_aod,tdd_svm_eod,tdd_svm_spd,tdd_svm_di=[],[],[],[]\n",
    "\n",
    "#TDD-Random Forest - for storing results of Random Forest.\n",
    "tdd_rf_recall,tdd_rf_far,tdd_rf_precision,tdd_rf_accuracy,tdd_rf_f1score=[],[],[],[],[]\n",
    "tdd_rf_aod,tdd_rf_eod,tdd_rf_spd,tdd_rf_di=[],[],[],[]\n",
    "\n",
    "#TDD-Naive Bayes - for storing results of Naive Bayes.\n",
    "tdd_nb_recall,tdd_nb_far,tdd_nb_precision,tdd_nb_accuracy,tdd_nb_f1score=[],[],[],[],[]\n",
    "tdd_nb_aod,tdd_nb_eod,tdd_nb_spd,tdd_nb_di=[],[],[],[]\n",
    "\n",
    "#TDD-Multi layer perceptron - for storing results of Multi layer perceptron.\n",
    "tdd_mlp_recall,tdd_mlp_far,tdd_mlp_precision,tdd_mlp_accuracy,tdd_mlp_f1score=[],[],[],[],[]\n",
    "tdd_mlp_aod,tdd_mlp_eod,tdd_mlp_spd,tdd_mlp_di=[],[],[],[]\n",
    "\n",
    "#TDD-Decision Trees - for storing results of Decision Tree.\n",
    "tdd_dt_recall,tdd_dt_far,tdd_dt_precision,tdd_dt_accuracy,tdd_dt_f1score=[],[],[],[],[]\n",
    "tdd_dt_aod,tdd_dt_eod,tdd_dt_spd,tdd_dt_di=[],[],[],[]\n",
    "\n",
    "#TDD-K Nearest Neighbour - for storing results of K nearest neighbour.\n",
    "tdd_knn_recall,tdd_knn_far,tdd_knn_precision,tdd_knn_accuracy,tdd_knn_f1score=[],[],[],[],[]\n",
    "tdd_knn_aod,tdd_knn_eod,tdd_knn_spd,tdd_knn_di=[],[],[],[]\n",
    "\n",
    "#*--------------------------------------------------*\n",
    "#**-------------Reweighing Results-------------------**\n",
    "#*--------------------------------------------------*\n",
    "\n",
    "#reweigh-Logistic Regression - for storing results of logistic regression.\n",
    "reweigh_lgr_recall,reweigh_lgr_far,reweigh_lgr_precision,reweigh_lgr_accuracy,reweigh_lgr_f1score=[],[],[],[],[]\n",
    "reweigh_lgr_aod,reweigh_lgr_eod,reweigh_lgr_spd,reweigh_lgr_di=[],[],[],[]\n",
    "\n",
    "#reweigh-SVM - for storing results of Support Vector Machine.\n",
    "reweigh_svm_recall,reweigh_svm_far,reweigh_svm_precision,reweigh_svm_accuracy,reweigh_svm_f1score=[],[],[],[],[]\n",
    "reweigh_svm_aod,reweigh_svm_eod,reweigh_svm_spd,reweigh_svm_di=[],[],[],[]\n",
    "\n",
    "#reweigh-Random Forest - for storing results of Random Forest.\n",
    "reweigh_rf_recall,reweigh_rf_far,reweigh_rf_precision,reweigh_rf_accuracy,reweigh_rf_f1score=[],[],[],[],[]\n",
    "reweigh_rf_aod,reweigh_rf_eod,reweigh_rf_spd,reweigh_rf_di=[],[],[],[]\n",
    "\n",
    "#reweigh-Naive Bayes - for storing results of Naive Bayes.\n",
    "reweigh_nb_recall,reweigh_nb_far,reweigh_nb_precision,reweigh_nb_accuracy,reweigh_nb_f1score=[],[],[],[],[]\n",
    "reweigh_nb_aod,reweigh_nb_eod,reweigh_nb_spd,reweigh_nb_di=[],[],[],[]\n",
    "\n",
    "#reweigh-Multi layer perceptron - for storing results of Multi layer perceptron.\n",
    "reweigh_mlp_recall,reweigh_mlp_far,reweigh_mlp_precision,reweigh_mlp_accuracy,reweigh_mlp_f1score=[],[],[],[],[]\n",
    "reweigh_mlp_aod,reweigh_mlp_eod,reweigh_mlp_spd,reweigh_mlp_di=[],[],[],[]\n",
    "\n",
    "#reweigh-Decision Trees - for storing results of Decision Tree.\n",
    "reweigh_dt_recall,reweigh_dt_far,reweigh_dt_precision,reweigh_dt_accuracy,reweigh_dt_f1score=[],[],[],[],[]\n",
    "reweigh_dt_aod,reweigh_dt_eod,reweigh_dt_spd,reweigh_dt_di=[],[],[],[]\n",
    "\n",
    "#reweigh-K Nearest Neighbour - for storing results of K nearest neighbour.\n",
    "reweigh_knn_recall,reweigh_knn_far,reweigh_knn_precision,reweigh_knn_accuracy,reweigh_knn_f1score=[],[],[],[],[]\n",
    "reweigh_knn_aod,reweigh_knn_eod,reweigh_knn_spd,reweigh_knn_di=[],[],[],[]\n",
    "\n",
    "\n",
    "#*--------------------------------------------------*\n",
    "#**-------------SMOTE Results-------------------**\n",
    "#*--------------------------------------------------*\n",
    "\n",
    "#smote-Logistic Regression - for storing results of logistic regression.\n",
    "smote_lgr_recall,smote_lgr_far,smote_lgr_precision,smote_lgr_accuracy,smote_lgr_f1score=[],[],[],[],[]\n",
    "smote_lgr_aod,smote_lgr_eod,smote_lgr_spd,smote_lgr_di=[],[],[],[]\n",
    "\n",
    "#smote-SVM - for storing results of Support Vector Machine.\n",
    "smote_svm_recall,smote_svm_far,smote_svm_precision,smote_svm_accuracy,smote_svm_f1score=[],[],[],[],[]\n",
    "smote_svm_aod,smote_svm_eod,smote_svm_spd,smote_svm_di=[],[],[],[]\n",
    "\n",
    "#smote-Random Forest - for storing results of Random Forest.\n",
    "smote_rf_recall,smote_rf_far,smote_rf_precision,smote_rf_accuracy,smote_rf_f1score=[],[],[],[],[]\n",
    "smote_rf_aod,smote_rf_eod,smote_rf_spd,smote_rf_di=[],[],[],[]\n",
    "\n",
    "#smote-Naive Bayes - for storing results of Naive Bayes.\n",
    "smote_nb_recall,smote_nb_far,smote_nb_precision,smote_nb_accuracy,smote_nb_f1score=[],[],[],[],[]\n",
    "smote_nb_aod,smote_nb_eod,smote_nb_spd,smote_nb_di=[],[],[],[]\n",
    "\n",
    "#smote-Multi layer perceptron - for storing results of Multi layer perceptron.\n",
    "smote_mlp_recall,smote_mlp_far,smote_mlp_precision,smote_mlp_accuracy,smote_mlp_f1score=[],[],[],[],[]\n",
    "smote_mlp_aod,smote_mlp_eod,smote_mlp_spd,smote_mlp_di=[],[],[],[]\n",
    "\n",
    "#smote-Decision Trees - for storing results of Decision Tree.\n",
    "smote_dt_recall,smote_dt_far,smote_dt_precision,smote_dt_accuracy,smote_dt_f1score=[],[],[],[],[]\n",
    "smote_dt_aod,smote_dt_eod,smote_dt_spd,smote_dt_di=[],[],[],[]\n",
    "\n",
    "#smote-K Nearest Neighbour - for storing results of K nearest neighbour.\n",
    "smote_knn_recall,smote_knn_far,smote_knn_precision,smote_knn_accuracy,smote_knn_f1score=[],[],[],[],[]\n",
    "smote_knn_aod,smote_knn_eod,smote_knn_spd,smote_knn_di=[],[],[],[]\n",
    "\n",
    "\n",
    "\n",
    "#*--------------------------------------------------*\n",
    "#**----------------------Random Under Sampling Results-------------------**\n",
    "#*--------------------------------------------------*\n",
    "\n",
    "#rus-Logistic Regression - for storing results of logistic regression.\n",
    "rus_lgr_recall,rus_lgr_far,rus_lgr_precision,rus_lgr_accuracy,rus_lgr_f1score=[],[],[],[],[]\n",
    "rus_lgr_aod,rus_lgr_eod,rus_lgr_spd,rus_lgr_di=[],[],[],[]\n",
    "\n",
    "#rus-SVM - for storing results of Support Vector Machine.\n",
    "rus_svm_recall,rus_svm_far,rus_svm_precision,rus_svm_accuracy,rus_svm_f1score=[],[],[],[],[]\n",
    "rus_svm_aod,rus_svm_eod,rus_svm_spd,rus_svm_di=[],[],[],[]\n",
    "\n",
    "#rus-Random Forest - for storing results of Random Forest.\n",
    "rus_rf_recall,rus_rf_far,rus_rf_precision,rus_rf_accuracy,rus_rf_f1score=[],[],[],[],[]\n",
    "rus_rf_aod,rus_rf_eod,rus_rf_spd,rus_rf_di=[],[],[],[]\n",
    "\n",
    "#rus-Naive Bayes - for storing results of Naive Bayes.\n",
    "rus_nb_recall,rus_nb_far,rus_nb_precision,rus_nb_accuracy,rus_nb_f1score=[],[],[],[],[]\n",
    "rus_nb_aod,rus_nb_eod,rus_nb_spd,rus_nb_di=[],[],[],[]\n",
    "\n",
    "#rus-Multi layer perceptron - for storing results of Multi layer perceptron.\n",
    "rus_mlp_recall,rus_mlp_far,rus_mlp_precision,rus_mlp_accuracy,rus_mlp_f1score=[],[],[],[],[]\n",
    "rus_mlp_aod,rus_mlp_eod,rus_mlp_spd,rus_mlp_di=[],[],[],[]\n",
    "\n",
    "#rus-Decision Trees - for storing results of Decision Tree.\n",
    "rus_dt_recall,rus_dt_far,rus_dt_precision,rus_dt_accuracy,rus_dt_f1score=[],[],[],[],[]\n",
    "rus_dt_aod,rus_dt_eod,rus_dt_spd,rus_dt_di=[],[],[],[]\n",
    "\n",
    "#rus-K Nearest Neighbour - for storing results of K nearest neighbour.\n",
    "rus_knn_recall,rus_knn_far,rus_knn_precision,rus_knn_accuracy,rus_knn_f1score=[],[],[],[],[]\n",
    "rus_knn_aod,rus_knn_eod,rus_knn_spd,rus_knn_di=[],[],[],[]\n",
    "\n",
    "\n",
    "\n",
    "#*--------------------------------------------------*\n",
    "#**-------------Random OverSampling Results-------------------**\n",
    "#*--------------------------------------------------*\n",
    "\n",
    "#ros-Logistic Regression - for storing results of logistic regression.\n",
    "ros_lgr_recall,ros_lgr_far,ros_lgr_precision,ros_lgr_accuracy,ros_lgr_f1score=[],[],[],[],[]\n",
    "ros_lgr_aod,ros_lgr_eod,ros_lgr_spd,ros_lgr_di=[],[],[],[]\n",
    "\n",
    "#ros-SVM - for storing results of Support Vector Machine.\n",
    "ros_svm_recall,ros_svm_far,ros_svm_precision,ros_svm_accuracy,ros_svm_f1score=[],[],[],[],[]\n",
    "ros_svm_aod,ros_svm_eod,ros_svm_spd,ros_svm_di=[],[],[],[]\n",
    "\n",
    "#ros-Random Forest - for storing results of Random Forest.\n",
    "ros_rf_recall,ros_rf_far,ros_rf_precision,ros_rf_accuracy,ros_rf_f1score=[],[],[],[],[]\n",
    "ros_rf_aod,ros_rf_eod,ros_rf_spd,ros_rf_di=[],[],[],[]\n",
    "\n",
    "#ros-Naive Bayes - for storing results of Naive Bayes.\n",
    "ros_nb_recall,ros_nb_far,ros_nb_precision,ros_nb_accuracy,ros_nb_f1score=[],[],[],[],[]\n",
    "ros_nb_aod,ros_nb_eod,ros_nb_spd,ros_nb_di=[],[],[],[]\n",
    "\n",
    "#ros-Multi layer perceptron - for storing results of Multi layer perceptron.\n",
    "ros_mlp_recall,ros_mlp_far,ros_mlp_precision,ros_mlp_accuracy,ros_mlp_f1score=[],[],[],[],[]\n",
    "ros_mlp_aod,ros_mlp_eod,ros_mlp_spd,ros_mlp_di=[],[],[],[]\n",
    "\n",
    "#ros-Decision Trees - for storing results of Decision Tree.\n",
    "ros_dt_recall,ros_dt_far,ros_dt_precision,ros_dt_accuracy,ros_dt_f1score=[],[],[],[],[]\n",
    "ros_dt_aod,ros_dt_eod,ros_dt_spd,ros_dt_di=[],[],[],[]\n",
    "\n",
    "#ros-K Nearest Neighbour - for storing results of K nearest neighbour.\n",
    "ros_knn_recall,ros_knn_far,ros_knn_precision,ros_knn_accuracy,ros_knn_f1score=[],[],[],[],[]\n",
    "ros_knn_aod,ros_knn_eod,ros_knn_spd,ros_knn_di=[],[],[],[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36026a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd8b1a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default(random_seed,dataset_orig_test1,X_train1,y_train1,X_test1,y_test1,protected_attribute,folder_name):\n",
    "    \n",
    "    dataset_orig_test=copy.deepcopy(dataset_orig_test1)\n",
    "    X_train=copy.deepcopy(X_train1)\n",
    "    y_train=copy.deepcopy(y_train1)\n",
    "    X_test=copy.deepcopy(X_test1)\n",
    "    y_test=copy.deepcopy(y_test1)\n",
    "    \n",
    "    default_results={} #for storing all results.\n",
    "    \n",
    "    default_lgr={}\n",
    "    default_svm={}\n",
    "    default_rf={}\n",
    "    default_nb={}\n",
    "    default_mlp={}\n",
    "    default_dt={}\n",
    "    default_knn={}\n",
    "       \n",
    "    #======================================= Default - LGR - START ================================================#\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    # --- LSR\n",
    "    clf = LogisticRegression(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                               unfavorable_label=0.0,\n",
    "                               df=dataset_orig_test,\n",
    "                               label_names=['Probability'],\n",
    "                               protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "\n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "\n",
    "    \n",
    "    #print(\"--------------------Default Classifier----------------------\")\n",
    "    \n",
    "   \n",
    "    default_lgr['recall']=round(class_metrics.recall(),2)\n",
    "    default_lgr['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    default_lgr['precision']=round(class_metrics.precision(),2)\n",
    "    default_lgr['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    default_lgr['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    default_lgr['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    default_lgr['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    default_lgr['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    default_lgr['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('LGR-', round(time.time() - start,2),end='| ')\n",
    "        \n",
    "    #========================================= Default - LGR - END ================================================#\n",
    "\n",
    "    \n",
    "    #Default-SVM Classifier---------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "   \n",
    "    #classifier\n",
    "    clf=SVC(random_state=random_seed)\n",
    "    \n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    default_svm['recall']=round(class_metrics.recall(),2)\n",
    "    default_svm['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    default_svm['precision']=round(class_metrics.precision(),2)\n",
    "    default_svm['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    default_svm['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    default_svm['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    default_svm['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    default_svm['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    default_svm['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('SVM-', round(time.time() - start,2),end='| ')\n",
    "    \n",
    "\n",
    "    #======================================= Default - RF - START =============================================#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf=RandomForestClassifier(random_state=random_seed)   \n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                               unfavorable_label=0.0,\n",
    "                               df=dataset_orig_test,\n",
    "                               label_names=['Probability'],\n",
    "                               protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "\n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    default_rf['recall']=round(class_metrics.recall(),2)\n",
    "    default_rf['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    default_rf['precision']=round(class_metrics.precision(),2)\n",
    "    default_rf['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    default_rf['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    default_rf['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    default_rf['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    default_rf['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    default_rf['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    " \n",
    "    print('RF-', round(time.time() - start,2),end='|')\n",
    "    \n",
    "    #======================================= Default - RF - END ================================================#\n",
    "\n",
    "    #Default-Naive Bayes Classifier------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf= GaussianNB()    \n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    default_nb['recall']=round(class_metrics.recall(),2)\n",
    "    default_nb['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    default_nb['precision']=round(class_metrics.precision(),2)\n",
    "    default_nb['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    default_nb['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    default_nb['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    default_nb['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    default_nb['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    default_nb['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('NB-', round(time.time() - start,2),end='|')\n",
    "    \n",
    "    #Default-MLP Classifier--------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf= MLPClassifier(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    default_mlp['recall']=round(class_metrics.recall(),2)\n",
    "    default_mlp['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    default_mlp['precision']=round(class_metrics.precision(),2)\n",
    "    default_mlp['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    default_mlp['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    default_mlp['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    default_mlp['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    default_mlp['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    default_mlp['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "        \n",
    "    print('MLP-', round(time.time() - start,2),end='| ')\n",
    "    \n",
    "    #======================================= Default - DT - START ================================================#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                               unfavorable_label=0.0,\n",
    "                               df=dataset_orig_test,\n",
    "                               label_names=['Probability'],\n",
    "                               protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "\n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    default_dt['recall']=round(class_metrics.recall(),2)\n",
    "    default_dt['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    default_dt['precision']=round(class_metrics.precision(),2)\n",
    "    default_dt['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    default_dt['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    default_dt['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    default_dt['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    default_dt['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    default_dt['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "     \n",
    "    print('DT-',  round(time.time() - start,2),end='| ')\n",
    "    \n",
    "     #=======================================Default - DT - END ================================================#\n",
    "\n",
    "\n",
    "    #Default-KNN Classifier---------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf=  KNeighborsClassifier()\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    default_knn['recall']=round(class_metrics.recall(),2)\n",
    "    default_knn['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    default_knn['precision']=round(class_metrics.precision(),2)\n",
    "    default_knn['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    default_knn['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    default_knn['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    default_knn['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    default_knn['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    default_knn['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "        \n",
    "    print('KNN-', round(time.time() - start,2),end='| ') \n",
    "\n",
    "    #pass all results in default_results dictionary.\n",
    "    default_results['default_lgr']=default_lgr\n",
    "    default_results['default_svm']=default_svm\n",
    "    default_results['default_rf']=default_rf\n",
    "    default_results['default_nb']=default_nb\n",
    "    default_results['default_mlp']=default_mlp\n",
    "    default_results['default_dt']=default_dt\n",
    "    default_results['default_knn']=default_knn\n",
    "    \n",
    "    return default_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1430189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7db8b269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_(random_seed,dataset_orig_test1,X_train1,y_train1,X_test1,y_test1,protected_attribute,folder_name):\n",
    "    \n",
    "    dataset_orig_test=copy.deepcopy(dataset_orig_test1)\n",
    "    X_train=copy.deepcopy(X_train1)\n",
    "    y_train=copy.deepcopy(y_train1)\n",
    "    X_test=copy.deepcopy(X_test1)\n",
    "    y_test=copy.deepcopy(y_test1)\n",
    "    \n",
    "    smote_results={} #for storing all results.\n",
    "    \n",
    "    smote_lgr={}\n",
    "    smote_svm={}\n",
    "    smote_rf={}\n",
    "    smote_nb={}\n",
    "    smote_mlp={}\n",
    "    smote_dt={}\n",
    "    smote_knn={}\n",
    "    \n",
    "    sm = SMOTE(random_state=random_seed)\n",
    "    X_train_smote, y_train_smote = sm.fit_resample(X_train, y_train)\n",
    "       \n",
    "    #======================================= smote - LGR - START ================================================#\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    # --- LSR\n",
    "    clf = LogisticRegression(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train_smote, y_train_smote) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                               unfavorable_label=0.0,\n",
    "                               df=dataset_orig_test,\n",
    "                               label_names=['Probability'],\n",
    "                               protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "\n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "\n",
    "    \n",
    "    #print(\"--------------------smote Classifier----------------------\")\n",
    "    \n",
    "   \n",
    "    smote_lgr['recall']=round(class_metrics.recall(),2)\n",
    "    smote_lgr['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    smote_lgr['precision']=round(class_metrics.precision(),2)\n",
    "    smote_lgr['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    smote_lgr['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    smote_lgr['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    smote_lgr['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    smote_lgr['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    smote_lgr['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('LGR-', round(time.time() - start,2),end='| ')\n",
    "        \n",
    "    #========================================= smote - LGR - END ================================================#\n",
    "\n",
    "    \n",
    "    #smote-SVM Classifier---------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "   \n",
    "    #classifier\n",
    "    clf=SVC(random_state=random_seed)\n",
    "    \n",
    "    #Model Fit\n",
    "    clf.fit(X_train_smote, y_train_smote) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    smote_svm['recall']=round(class_metrics.recall(),2)\n",
    "    smote_svm['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    smote_svm['precision']=round(class_metrics.precision(),2)\n",
    "    smote_svm['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    smote_svm['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    smote_svm['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    smote_svm['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    smote_svm['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    smote_svm['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('SVM-', round(time.time() - start,2),end='| ')\n",
    "    \n",
    "\n",
    "    #======================================= smote - RF - START =============================================#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf=RandomForestClassifier(random_state=random_seed)   \n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train_smote, y_train_smote) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                               unfavorable_label=0.0,\n",
    "                               df=dataset_orig_test,\n",
    "                               label_names=['Probability'],\n",
    "                               protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "\n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    smote_rf['recall']=round(class_metrics.recall(),2)\n",
    "    smote_rf['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    smote_rf['precision']=round(class_metrics.precision(),2)\n",
    "    smote_rf['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    smote_rf['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    smote_rf['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    smote_rf['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    smote_rf['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    smote_rf['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    " \n",
    "    print('RF-', round(time.time() - start,2),end='|')\n",
    "    \n",
    "    #======================================= smote - RF - END ================================================#\n",
    "\n",
    "    #smote-Naive Bayes Classifier------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf= GaussianNB()    \n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train_smote, y_train_smote) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    smote_nb['recall']=round(class_metrics.recall(),2)\n",
    "    smote_nb['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    smote_nb['precision']=round(class_metrics.precision(),2)\n",
    "    smote_nb['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    smote_nb['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    smote_nb['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    smote_nb['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    smote_nb['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    smote_nb['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('NB-', round(time.time() - start,2),end='|')\n",
    "    \n",
    "    #smote-MLP Classifier--------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf= MLPClassifier(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train_smote, y_train_smote) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    smote_mlp['recall']=round(class_metrics.recall(),2)\n",
    "    smote_mlp['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    smote_mlp['precision']=round(class_metrics.precision(),2)\n",
    "    smote_mlp['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    smote_mlp['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    smote_mlp['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    smote_mlp['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    smote_mlp['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    smote_mlp['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "        \n",
    "    print('MLP-', round(time.time() - start,2),end='| ')\n",
    "    \n",
    "    #======================================= smote - DT - START ================================================#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train_smote, y_train_smote) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                               unfavorable_label=0.0,\n",
    "                               df=dataset_orig_test,\n",
    "                               label_names=['Probability'],\n",
    "                               protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "\n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    smote_dt['recall']=round(class_metrics.recall(),2)\n",
    "    smote_dt['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    smote_dt['precision']=round(class_metrics.precision(),2)\n",
    "    smote_dt['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    smote_dt['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    smote_dt['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    smote_dt['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    smote_dt['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    smote_dt['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "     \n",
    "    print('DT-',  round(time.time() - start,2),end='| ')\n",
    "    \n",
    "     #=======================================smote - DT - END ================================================#\n",
    "\n",
    "\n",
    "    #smote-KNN Classifier---------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf=  KNeighborsClassifier()\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train_smote, y_train_smote) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    smote_knn['recall']=round(class_metrics.recall(),2)\n",
    "    smote_knn['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    smote_knn['precision']=round(class_metrics.precision(),2)\n",
    "    smote_knn['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    smote_knn['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    smote_knn['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    smote_knn['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    smote_knn['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    smote_knn['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "        \n",
    "    print('KNN-', round(time.time() - start,2),end='| ') \n",
    "\n",
    "    #pass all results in smote_results dictionary.\n",
    "    smote_results['smote_lgr']=smote_lgr\n",
    "    smote_results['smote_svm']=smote_svm\n",
    "    smote_results['smote_rf']=smote_rf\n",
    "    smote_results['smote_nb']=smote_nb\n",
    "    smote_results['smote_mlp']=smote_mlp\n",
    "    smote_results['smote_dt']=smote_dt\n",
    "    smote_results['smote_knn']=smote_knn\n",
    "    \n",
    "    return smote_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb02a0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aa381a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rus(random_seed,dataset_orig_test1,X_train_res1,y_train_res1,X_test1,y_test1,protected_attribute,folder_name):\n",
    "    \n",
    "    dataset_orig_test=copy.deepcopy(dataset_orig_test1)\n",
    "    X_train_res=copy.deepcopy(X_train_res1)\n",
    "    y_train_res=copy.deepcopy(y_train_res1)\n",
    "    X_test=copy.deepcopy(X_test1)\n",
    "    y_test=copy.deepcopy(y_test1)\n",
    "    \n",
    "    rus_results={} #for storing all results.\n",
    "    \n",
    "    rus_lgr={}\n",
    "    rus_svm={}\n",
    "    rus_rf={}\n",
    "    rus_nb={}\n",
    "    rus_mlp={}\n",
    "    rus_dt={}\n",
    "    rus_knn={}\n",
    "       \n",
    "    rus = RandomUnderSampler(random_state=random_seed)\n",
    "    X_train_res, y_train_res = rus.fit_resample(X_train, y_train)\n",
    "  \n",
    "    #======================================= rus - LGR - START ================================================#\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    # --- LSR\n",
    "    clf = LogisticRegression(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train_res, y_train_res) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                               unfavorable_label=0.0,\n",
    "                               df=dataset_orig_test,\n",
    "                               label_names=['Probability'],\n",
    "                               protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "\n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "\n",
    "    \n",
    "    #print(\"--------------------rus Classifier----------------------\")\n",
    "    \n",
    "   \n",
    "    rus_lgr['recall']=round(class_metrics.recall(),2)\n",
    "    rus_lgr['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    rus_lgr['precision']=round(class_metrics.precision(),2)\n",
    "    rus_lgr['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    rus_lgr['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    rus_lgr['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    rus_lgr['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    rus_lgr['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    rus_lgr['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('LGR-', round(time.time() - start,2),end='| ')\n",
    "        \n",
    "    #========================================= rus - LGR - END ================================================#\n",
    "\n",
    "    \n",
    "    #rus-SVM Classifier---------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "   \n",
    "    #classifier\n",
    "    clf=SVC(random_state=random_seed)\n",
    "    \n",
    "    #Model Fit\n",
    "    clf.fit(X_train_res, y_train_res) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    rus_svm['recall']=round(class_metrics.recall(),2)\n",
    "    rus_svm['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    rus_svm['precision']=round(class_metrics.precision(),2)\n",
    "    rus_svm['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    rus_svm['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    rus_svm['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    rus_svm['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    rus_svm['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    rus_svm['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('SVM-', round(time.time() - start,2),end='| ')\n",
    "    \n",
    "\n",
    "    #======================================= rus - RF - START =============================================#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf=RandomForestClassifier(random_state=random_seed)   \n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train_res, y_train_res) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                               unfavorable_label=0.0,\n",
    "                               df=dataset_orig_test,\n",
    "                               label_names=['Probability'],\n",
    "                               protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "\n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    rus_rf['recall']=round(class_metrics.recall(),2)\n",
    "    rus_rf['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    rus_rf['precision']=round(class_metrics.precision(),2)\n",
    "    rus_rf['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    rus_rf['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    rus_rf['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    rus_rf['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    rus_rf['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    rus_rf['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    " \n",
    "    print('RF-', round(time.time() - start,2),end='|')\n",
    "    \n",
    "    #======================================= rus - RF - END ================================================#\n",
    "\n",
    "    #rus-Naive Bayes Classifier------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf= GaussianNB()    \n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train_res, y_train_res) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    rus_nb['recall']=round(class_metrics.recall(),2)\n",
    "    rus_nb['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    rus_nb['precision']=round(class_metrics.precision(),2)\n",
    "    rus_nb['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    rus_nb['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    rus_nb['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    rus_nb['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    rus_nb['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    rus_nb['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('NB-', round(time.time() - start,2),end='|')\n",
    "    \n",
    "    #rus-MLP Classifier--------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf= MLPClassifier(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train_res, y_train_res) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    rus_mlp['recall']=round(class_metrics.recall(),2)\n",
    "    rus_mlp['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    rus_mlp['precision']=round(class_metrics.precision(),2)\n",
    "    rus_mlp['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    rus_mlp['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    rus_mlp['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    rus_mlp['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    rus_mlp['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    rus_mlp['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "        \n",
    "    print('MLP-', round(time.time() - start,2),end='| ')\n",
    "    \n",
    "    #======================================= rus - DT - START ================================================#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train_res, y_train_res) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                               unfavorable_label=0.0,\n",
    "                               df=dataset_orig_test,\n",
    "                               label_names=['Probability'],\n",
    "                               protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "\n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    rus_dt['recall']=round(class_metrics.recall(),2)\n",
    "    rus_dt['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    rus_dt['precision']=round(class_metrics.precision(),2)\n",
    "    rus_dt['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    rus_dt['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    rus_dt['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    rus_dt['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    rus_dt['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    rus_dt['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "     \n",
    "    print('DT-',  round(time.time() - start,2),end='| ')\n",
    "    \n",
    "     #=======================================rus - DT - END ================================================#\n",
    "\n",
    "\n",
    "    #rus-KNN Classifier---------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf=  KNeighborsClassifier()\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train_res, y_train_res) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    rus_knn['recall']=round(class_metrics.recall(),2)\n",
    "    rus_knn['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    rus_knn['precision']=round(class_metrics.precision(),2)\n",
    "    rus_knn['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    rus_knn['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    rus_knn['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    rus_knn['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    rus_knn['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    rus_knn['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "        \n",
    "    print('KNN-', round(time.time() - start,2),end='| ') \n",
    "\n",
    "    #pass all results in rus_results dictionary.\n",
    "    rus_results['rus_lgr']=rus_lgr\n",
    "    rus_results['rus_svm']=rus_svm\n",
    "    rus_results['rus_rf']=rus_rf\n",
    "    rus_results['rus_nb']=rus_nb\n",
    "    rus_results['rus_mlp']=rus_mlp\n",
    "    rus_results['rus_dt']=rus_dt\n",
    "    rus_results['rus_knn']=rus_knn\n",
    "    \n",
    "    return rus_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1396a170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cacc209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ros(random_seed,dataset_orig_test1,X_train_ros1,y_train_ros1,X_test1,y_test1,protected_attribute,folder_name):\n",
    "    \n",
    "    dataset_orig_test=copy.deepcopy(dataset_orig_test1)\n",
    "    X_train_ros=copy.deepcopy(X_train_ros1)\n",
    "    y_train_ros=copy.deepcopy(y_train_ros1)\n",
    "    X_test=copy.deepcopy(X_test1)\n",
    "    y_test=copy.deepcopy(y_test1)\n",
    "    \n",
    "    ros_results={} #for storing all results.\n",
    "    \n",
    "    ros_lgr={}\n",
    "    ros_svm={}\n",
    "    ros_rf={}\n",
    "    ros_nb={}\n",
    "    ros_mlp={}\n",
    "    ros_dt={}\n",
    "    ros_knn={}\n",
    "    \n",
    "    ros = RandomOverSampler(random_state=random_seed)\n",
    "    X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "       \n",
    "    #======================================= ros - LGR - START ================================================#\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    # --- LSR\n",
    "    clf = LogisticRegression(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train_ros, y_train_ros) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                               unfavorable_label=0.0,\n",
    "                               df=dataset_orig_test,\n",
    "                               label_names=['Probability'],\n",
    "                               protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "\n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "\n",
    "    \n",
    "    #print(\"--------------------ros Classifier----------------------\")\n",
    "    \n",
    "   \n",
    "    ros_lgr['recall']=round(class_metrics.recall(),2)\n",
    "    ros_lgr['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    ros_lgr['precision']=round(class_metrics.precision(),2)\n",
    "    ros_lgr['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    ros_lgr['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    ros_lgr['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    ros_lgr['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    ros_lgr['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    ros_lgr['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('LGR-', round(time.time() - start,2),end='| ')\n",
    "        \n",
    "    #========================================= ros - LGR - END ================================================#\n",
    "\n",
    "    \n",
    "    #ros-SVM Classifier---------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "   \n",
    "    #classifier\n",
    "    clf=SVC(random_state=random_seed)\n",
    "    \n",
    "    #Model Fit\n",
    "    clf.fit(X_train_ros, y_train_ros) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    ros_svm['recall']=round(class_metrics.recall(),2)\n",
    "    ros_svm['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    ros_svm['precision']=round(class_metrics.precision(),2)\n",
    "    ros_svm['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    ros_svm['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    ros_svm['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    ros_svm['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    ros_svm['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    ros_svm['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('SVM-', round(time.time() - start,2),end='| ')\n",
    "    \n",
    "\n",
    "    #======================================= ros - RF - START =============================================#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf=RandomForestClassifier(random_state=random_seed)   \n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train_ros, y_train_ros) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                               unfavorable_label=0.0,\n",
    "                               df=dataset_orig_test,\n",
    "                               label_names=['Probability'],\n",
    "                               protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "\n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    ros_rf['recall']=round(class_metrics.recall(),2)\n",
    "    ros_rf['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    ros_rf['precision']=round(class_metrics.precision(),2)\n",
    "    ros_rf['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    ros_rf['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    ros_rf['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    ros_rf['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    ros_rf['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    ros_rf['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    " \n",
    "    print('RF-', round(time.time() - start,2),end='|')\n",
    "    \n",
    "    #======================================= ros - RF - END ================================================#\n",
    "\n",
    "    #ros-Naive Bayes Classifier------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf= GaussianNB()    \n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train_ros, y_train_ros) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    ros_nb['recall']=round(class_metrics.recall(),2)\n",
    "    ros_nb['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    ros_nb['precision']=round(class_metrics.precision(),2)\n",
    "    ros_nb['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    ros_nb['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    ros_nb['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    ros_nb['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    ros_nb['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    ros_nb['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('NB-', round(time.time() - start,2),end='|')\n",
    "    \n",
    "    #ros-MLP Classifier--------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf= MLPClassifier(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train_ros, y_train_ros) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    ros_mlp['recall']=round(class_metrics.recall(),2)\n",
    "    ros_mlp['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    ros_mlp['precision']=round(class_metrics.precision(),2)\n",
    "    ros_mlp['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    ros_mlp['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    ros_mlp['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    ros_mlp['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    ros_mlp['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    ros_mlp['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "        \n",
    "    print('MLP-', round(time.time() - start,2),end='| ')\n",
    "    \n",
    "    #======================================= ros - DT - START ================================================#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train_ros, y_train_ros) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                               unfavorable_label=0.0,\n",
    "                               df=dataset_orig_test,\n",
    "                               label_names=['Probability'],\n",
    "                               protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "\n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    ros_dt['recall']=round(class_metrics.recall(),2)\n",
    "    ros_dt['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    ros_dt['precision']=round(class_metrics.precision(),2)\n",
    "    ros_dt['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    ros_dt['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    ros_dt['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    ros_dt['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    ros_dt['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    ros_dt['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "     \n",
    "    print('DT-',  round(time.time() - start,2),end='| ')\n",
    "    \n",
    "     #=======================================ros - DT - END ================================================#\n",
    "\n",
    "\n",
    "    #ros-KNN Classifier---------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf=  KNeighborsClassifier()\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train_ros, y_train_ros) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    ros_knn['recall']=round(class_metrics.recall(),2)\n",
    "    ros_knn['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    ros_knn['precision']=round(class_metrics.precision(),2)\n",
    "    ros_knn['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    ros_knn['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    ros_knn['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    ros_knn['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    ros_knn['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    ros_knn['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "        \n",
    "    print('KNN-', round(time.time() - start,2),end='| ') \n",
    "\n",
    "    #pass all results in ros_results dictionary.\n",
    "    ros_results['ros_lgr']=ros_lgr\n",
    "    ros_results['ros_svm']=ros_svm\n",
    "    ros_results['ros_rf']=ros_rf\n",
    "    ros_results['ros_nb']=ros_nb\n",
    "    ros_results['ros_mlp']=ros_mlp\n",
    "    ros_results['ros_dt']=ros_dt\n",
    "    ros_results['ros_knn']=ros_knn\n",
    "    \n",
    "    return ros_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dbd57b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cc1e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fair_smote(random_state,dataset_orig_train1,dataset_orig_test1,X_train1,y_train1,X_test1,y_test1,protected_attribute,global_timestamp,folder_name,dataset_name):\n",
    "  \n",
    "    dataset_orig_train=copy.deepcopy(dataset_orig_train1)\n",
    "    dataset_orig_test=copy.deepcopy(dataset_orig_test1)\n",
    "    X_train=copy.deepcopy(X_train1)\n",
    "    y_train=copy.deepcopy(y_train1)\n",
    "    X_test=copy.deepcopy(X_test1)\n",
    "    y_test=copy.deepcopy(y_test1)\n",
    "    \n",
    "    fair_smote_results={} #for storing all results.\n",
    "    \n",
    "    fair_smote_lgr={}\n",
    "    fair_smote_svm={}\n",
    "    fair_smote_rf={}\n",
    "    fair_smote_nb={}\n",
    "    fair_smote_mlp={}\n",
    "    fair_smote_dt={}\n",
    "    fair_smote_knn={}\n",
    "    \n",
    "    df=pd.read_csv('generated_data/'+folder_name+'/'+str(global_timestamp)+'/fairsmote'+str(random_seed)+'.csv')\n",
    "    X_train, y_train = df.loc[:, df.columns != 'Probability'], df['Probability']\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "     # --- LSR\n",
    "    clf = LogisticRegression(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "\n",
    "    #=========================================Below is common for all========================================#\n",
    "    \n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                               unfavorable_label=0.0,\n",
    "                               df=dataset_orig_test,\n",
    "                               label_names=['Probability'],\n",
    "                               protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "\n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    #=======================================================================================================#\n",
    "\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "        \n",
    "    \n",
    "    #print(\"--------------------fair_smote Classifier----------------------\")\n",
    "    \n",
    "   \n",
    "    fair_smote_lgr['recall']=round(class_metrics.recall(),2)\n",
    "    fair_smote_lgr['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    fair_smote_lgr['precision']=round(class_metrics.precision(),2)\n",
    "    fair_smote_lgr['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    fair_smote_lgr['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    fair_smote_lgr['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    fair_smote_lgr['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    fair_smote_lgr['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    fair_smote_lgr['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('LGR-', round(time.time() - start,2),end='| ')\n",
    "    \n",
    "    \n",
    "    #fair_smote-SVM Classifier---------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "   \n",
    "    #classifier\n",
    "    clf=SVC(random_state=random_seed)\n",
    "    \n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_pred.labels = y_pred\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    fair_smote_svm['recall']=round(class_metrics.recall(),2)\n",
    "    fair_smote_svm['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    fair_smote_svm['precision']=round(class_metrics.precision(),2)\n",
    "    fair_smote_svm['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    fair_smote_svm['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    fair_smote_svm['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    fair_smote_svm['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    fair_smote_svm['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    fair_smote_svm['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('SVM-', round(time.time() - start,2),end='| ')\n",
    "    \n",
    "\n",
    "    #fair_smote-Random Forest Classifier-----------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf=RandomForestClassifier(random_state=random_seed)   \n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_pred.labels = y_pred\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    fair_smote_rf['recall']=round(class_metrics.recall(),2)\n",
    "    fair_smote_rf['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    fair_smote_rf['precision']=round(class_metrics.precision(),2)\n",
    "    fair_smote_rf['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    fair_smote_rf['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    fair_smote_rf['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    fair_smote_rf['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    fair_smote_rf['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    fair_smote_rf['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    " \n",
    "    print('RF-', round(time.time() - start,2),end='|')\n",
    "    \n",
    "    #fair_smote-Naive Bayes Classifier------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf= GaussianNB()    \n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_pred.labels = y_pred\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    fair_smote_nb['recall']=round(class_metrics.recall(),2)\n",
    "    fair_smote_nb['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    fair_smote_nb['precision']=round(class_metrics.precision(),2)\n",
    "    fair_smote_nb['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    fair_smote_nb['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    fair_smote_nb['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    fair_smote_nb['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    fair_smote_nb['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    fair_smote_nb['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('NB-', round(time.time() - start,2),end='|')\n",
    "    \n",
    "    #fair_smote-MLP Classifier--------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf= MLPClassifier(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_pred.labels = y_pred\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    fair_smote_mlp['recall']=round(class_metrics.recall(),2)\n",
    "    fair_smote_mlp['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    fair_smote_mlp['precision']=round(class_metrics.precision(),2)\n",
    "    fair_smote_mlp['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    fair_smote_mlp['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    fair_smote_mlp['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    fair_smote_mlp['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    fair_smote_mlp['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    fair_smote_mlp['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "        \n",
    "    print('MLP-', round(time.time() - start,2),end='| ')\n",
    "    \n",
    "    #fair_smote-Decision Trees Classifier----------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_pred.labels = y_pred\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    fair_smote_dt['recall']=round(class_metrics.recall(),2)\n",
    "    fair_smote_dt['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    fair_smote_dt['precision']=round(class_metrics.precision(),2)\n",
    "    fair_smote_dt['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    fair_smote_dt['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    fair_smote_dt['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    fair_smote_dt['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    fair_smote_dt['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    fair_smote_dt['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "     \n",
    "    print('DT-',  round(time.time() - start,2),end='| ')\n",
    "\n",
    "    #fair_smote-KNN Classifier---------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf=  KNeighborsClassifier()\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_pred.labels = y_pred\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    fair_smote_knn['recall']=round(class_metrics.recall(),2)\n",
    "    fair_smote_knn['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    fair_smote_knn['precision']=round(class_metrics.precision(),2)\n",
    "    fair_smote_knn['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    fair_smote_knn['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    fair_smote_knn['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    fair_smote_knn['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    fair_smote_knn['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    fair_smote_knn['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "        \n",
    "    print('KNN-', round(time.time() - start,2),end='| ') \n",
    "\n",
    "    #pass all results in fair_smote_results.\n",
    "    fair_smote_results['fair_smote_lgr']=fair_smote_lgr\n",
    "    fair_smote_results['fair_smote_svm']=fair_smote_svm\n",
    "    fair_smote_results['fair_smote_rf']=fair_smote_rf\n",
    "    fair_smote_results['fair_smote_nb']=fair_smote_nb\n",
    "    fair_smote_results['fair_smote_mlp']=fair_smote_mlp\n",
    "    fair_smote_results['fair_smote_dt']=fair_smote_dt\n",
    "    fair_smote_results['fair_smote_knn']=fair_smote_knn\n",
    "\n",
    "    return fair_smote_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22109f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80776509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fair_preprocessor(random_state,dataset_orig_train1,dataset_orig_test1,X_train1,y_train1,X_test1,y_test1,protected_attribute,time_stamp,folder_name,dataset_name):\n",
    "  \n",
    "    dataset_orig_train=copy.deepcopy(dataset_orig_train1)\n",
    "    dataset_orig_test=copy.deepcopy(dataset_orig_test1)\n",
    "    X_train=copy.deepcopy(X_train1)\n",
    "    y_train=copy.deepcopy(y_train1)\n",
    "    X_test=copy.deepcopy(X_test1)\n",
    "    y_test=copy.deepcopy(y_test1)\n",
    "    \n",
    "    fair_preprocessor_results={} #for storing all results.\n",
    "    \n",
    "    fair_preprocessor_lgr={}\n",
    "    fair_preprocessor_svm={}\n",
    "    fair_preprocessor_rf={}\n",
    "    fair_preprocessor_nb={}\n",
    "    fair_preprocessor_mlp={}\n",
    "    fair_preprocessor_dt={}\n",
    "    fair_preprocessor_knn={}\n",
    "    \n",
    "    fair_preprocessor_parameters={}\n",
    "\n",
    "    #print(\"{} : Fair-generate Running\".format(random_seed))\n",
    "    # first one is class value and second one is protected attribute value\n",
    "   \n",
    "   \n",
    "    df=pd.read_csv('generated_data/'+folder_name+'/'+str(time_stamp)+'/fairgenerate'+str(random_seed)+'.csv')\n",
    "    X_train, y_train = df.loc[:, df.columns != 'Probability'], df['Probability']\n",
    "  \n",
    "   \n",
    "    # --- LSR\n",
    "     \n",
    "   \n",
    "     #fair_preprocessor-LogisticRegression Classifier-----------------------------------------------------------------------#\n",
    "   \n",
    "    start = time.time()\n",
    "    \n",
    "    # --- LSR\n",
    "    clf = LogisticRegression(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "\n",
    "    #=========================================Below is common for all========================================#\n",
    "    \n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                               unfavorable_label=0.0,\n",
    "                               df=dataset_orig_test,\n",
    "                               label_names=['Probability'],\n",
    "                               protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "\n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    #==========================================Above is common for all========================================#\n",
    "\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "        \n",
    "    \n",
    "    #print(\"--------------------Fair Generate Classifier----------------------\")\n",
    "    \n",
    "   \n",
    "    fair_preprocessor_lgr['recall']=round(class_metrics.recall(),2)\n",
    "    fair_preprocessor_lgr['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    fair_preprocessor_lgr['precision']=round(class_metrics.precision(),2)\n",
    "    fair_preprocessor_lgr['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    fair_preprocessor_lgr['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    fair_preprocessor_lgr['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    fair_preprocessor_lgr['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    fair_preprocessor_lgr['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    fair_preprocessor_lgr['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('LGR-', round(time.time() - start,2),end='| ')\n",
    "    \n",
    "    \n",
    "    #fair_preprocessor-SVM Classifier---------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "   \n",
    "    #classifier\n",
    "    clf=SVC(random_state=random_seed)\n",
    "    \n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test)\n",
    "    dataset_pred.labels = y_pred\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    fair_preprocessor_svm['recall']=round(class_metrics.recall(),2)\n",
    "    fair_preprocessor_svm['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    fair_preprocessor_svm['precision']=round(class_metrics.precision(),2)\n",
    "    fair_preprocessor_svm['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    fair_preprocessor_svm['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    fair_preprocessor_svm['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    fair_preprocessor_svm['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    fair_preprocessor_svm['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    fair_preprocessor_svm['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('SVM-', round(time.time() - start,2),end='| ')\n",
    "    \n",
    "\n",
    "    #fair_preprocessor-Random Forest Classifier-----------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf=RandomForestClassifier(random_state=random_seed)   \n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_pred.labels = y_pred\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    fair_preprocessor_rf['recall']=round(class_metrics.recall(),2)\n",
    "    fair_preprocessor_rf['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    fair_preprocessor_rf['precision']=round(class_metrics.precision(),2)\n",
    "    fair_preprocessor_rf['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    fair_preprocessor_rf['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    fair_preprocessor_rf['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    fair_preprocessor_rf['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    fair_preprocessor_rf['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    fair_preprocessor_rf['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    " \n",
    "    print('RF-', round(time.time() - start,2),end='|')\n",
    "    \n",
    "    #fair_preprocessor-Naive Bayes Classifier------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf= GaussianNB()    \n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_pred.labels = y_pred\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    fair_preprocessor_nb['recall']=round(class_metrics.recall(),2)\n",
    "    fair_preprocessor_nb['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    fair_preprocessor_nb['precision']=round(class_metrics.precision(),2)\n",
    "    fair_preprocessor_nb['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    fair_preprocessor_nb['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    fair_preprocessor_nb['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    fair_preprocessor_nb['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    fair_preprocessor_nb['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    fair_preprocessor_nb['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('NB-', round(time.time() - start,2),end='|')\n",
    "    \n",
    "    #fair_preprocessor-MLP Classifier--------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf= MLPClassifier(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_pred.labels = y_pred\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    fair_preprocessor_mlp['recall']=round(class_metrics.recall(),2)\n",
    "    fair_preprocessor_mlp['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    fair_preprocessor_mlp['precision']=round(class_metrics.precision(),2)\n",
    "    fair_preprocessor_mlp['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    fair_preprocessor_mlp['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    fair_preprocessor_mlp['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    fair_preprocessor_mlp['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    fair_preprocessor_mlp['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    fair_preprocessor_mlp['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "        \n",
    "    print('MLP-', round(time.time() - start,2),end='| ')\n",
    "    \n",
    "    #fair_preprocessor-Decision Trees Classifier----------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    fair_preprocessor_dt['recall']=round(class_metrics.recall(),2)\n",
    "    fair_preprocessor_dt['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    fair_preprocessor_dt['precision']=round(class_metrics.precision(),2)\n",
    "    fair_preprocessor_dt['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    fair_preprocessor_dt['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    fair_preprocessor_dt['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    fair_preprocessor_dt['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    fair_preprocessor_dt['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    fair_preprocessor_dt['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "     \n",
    "    print('DT-',  round(time.time() - start,2),end='| ')\n",
    "\n",
    "    #fair_preprocessor-KNN Classifier---------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf=  KNeighborsClassifier()\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_pred.labels = y_pred\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    fair_preprocessor_knn['recall']=round(class_metrics.recall(),2)\n",
    "    fair_preprocessor_knn['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    fair_preprocessor_knn['precision']=round(class_metrics.precision(),2)\n",
    "    fair_preprocessor_knn['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    fair_preprocessor_knn['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    fair_preprocessor_knn['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    fair_preprocessor_knn['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    fair_preprocessor_knn['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    fair_preprocessor_knn['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "        \n",
    "    print('KNN-', round(time.time() - start,2),end='| ') \n",
    "    \n",
    "     #pass all results in fair_preprocessor_results.\n",
    "    fair_preprocessor_results['fair_preprocessor_lgr']=fair_preprocessor_lgr\n",
    "    fair_preprocessor_results['fair_preprocessor_svm']=fair_preprocessor_svm\n",
    "    fair_preprocessor_results['fair_preprocessor_rf']=fair_preprocessor_rf\n",
    "    fair_preprocessor_results['fair_preprocessor_nb']=fair_preprocessor_nb\n",
    "    fair_preprocessor_results['fair_preprocessor_mlp']=fair_preprocessor_mlp\n",
    "    fair_preprocessor_results['fair_preprocessor_dt']=fair_preprocessor_dt\n",
    "    fair_preprocessor_results['fair_preprocessor_knn']=fair_preprocessor_knn\n",
    "\n",
    "    \n",
    "    return fair_preprocessor_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed5e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d890520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg2clf(protected_pred,threshold=.5):\n",
    "    out = []\n",
    "    for each in protected_pred:\n",
    "        if each >=threshold:\n",
    "            out.append(1)\n",
    "        else: out.append(0)\n",
    "    return out\n",
    "\n",
    "\n",
    "def xFAIR(dataset_orig_test,X_train1,y_train1,X_test1,y_test1,base_clf,base2,protected_attribute,global_timestamp):\n",
    "    \n",
    "    X_train=copy.deepcopy(X_train1)\n",
    "    y_train=copy.deepcopy(y_train1)\n",
    "    X_test=copy.deepcopy(X_test1)\n",
    "    y_test=copy.deepcopy(y_test1)\n",
    "    \n",
    "    #for storing results.\n",
    "    acc, pre, recall, f1 ,falsealarm = [], [], [], [],[]\n",
    "    aod, eod, spd, di = [], [], [], []\n",
    "    \n",
    "    #default parameters\n",
    "    ratio=.2\n",
    "    smote1=True\n",
    "    thresh=.5\n",
    "    keyword=protected_attribute \n",
    "\n",
    "    reduced = list(X_train.columns) \n",
    "    #['age', 'education-num', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "    reduced.remove(keyword)\n",
    "    #['age', 'education-num', 'race', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "    X_reduced, y_reduced = X_train.loc[:, reduced], X_train[keyword]\n",
    "    #X_reduced contains - [39073 rows x 6 columns] and below columns\n",
    "    #age  education-num  race  capital-gain  capital-loss hours-per-week  \n",
    "\n",
    "    #y_reduced ontains - [39073 rows x 1 column] and below column\n",
    "    #sex\n",
    "\n",
    "    # Build model to predict the protect attribute\n",
    "    clf1 = copy.deepcopy(base2)  #base2 is set as clf1.\n",
    "    if smote1:                   #smote1 is true.\n",
    "        sm = SMOTE()             #sm is SMOTE object.\n",
    "        X_trains, y_trains = sm.fit_resample(X_reduced, y_reduced)  #Resample the dataset\n",
    "        clf = copy.deepcopy(base_clf)   #base_clf is set as clf.\n",
    "        clf.fit(X_trains, y_trains)      #fit the base_clf with X_trains and y_trains. Original dataset.\n",
    "        y_proba = clf.predict_proba(X_trains)   \n",
    "        #A method in classifiers and clusterers that can return probability estimates for each class/cluster. \n",
    "        #Its input is usually only some observed data, X.\n",
    "        #If the estimator was not already fitted, calling this method should raise a exceptions.NotFittedError.\n",
    "        #y_proba contains the probability estimates of dependent variable.\n",
    "        #y_proba is fitted on X_train and y_train dataset. \n",
    "\n",
    "\n",
    "        y_proba = [each[1] for each in y_proba]\n",
    "\n",
    "        if isinstance(clf1, DecisionTreeClassifier) or isinstance(clf1, LogisticRegression) or isinstance(clf1, SVC)  or isinstance(clf1, RandomForestClassifier)  or isinstance(clf1, GaussianNB)  or isinstance(clf1, MLPClassifier)  or isinstance(clf1, DecisionTreeClassifier) or isinstance(clf1, KNeighborsClassifier):\n",
    "            #if we have - decisiontreeclassifer or logisticregression classifier\n",
    "            #fit it on X_trains and y_trains.\n",
    "            clf1.fit(X_trains, y_trains)\n",
    "        else:\n",
    "            clf1.fit(X_trains, y_proba)\n",
    "            #fit on X_trains and y_proba.\n",
    "    else:\n",
    "        clf = copy.deepcopy(base_clf)\n",
    "        clf.fit(X_reduced, y_reduced)\n",
    "        y_proba = clf.predict_proba(X_reduced)\n",
    "        y_proba = [each[1] for each in y_proba]\n",
    "        if isinstance(clf1, DecisionTreeClassifier) or isinstance(clf1, LogisticRegression) or isinstance(clf1, SVC) :\n",
    "            clf1.fit(X_reduced, y_reduced)\n",
    "        else:\n",
    "            clf1.fit(X_reduced, y_proba)\n",
    "    #             clf1.fit(X_reduced,y_reduced)\n",
    "\n",
    "    X_test_reduced = X_test.loc[:, X_test.columns != keyword]\n",
    "    #X_test_reduced dataset does not contain the keyword column only.\n",
    "    protected_pred = clf1.predict(X_test_reduced)\n",
    "    #predict the protected attribute using clf1 on X_test_reduced. \n",
    "    #what is clf1?\n",
    "    if isinstance(clf1, DecisionTreeClassifier) or isinstance(clf1, LogisticRegression) or isinstance(clf1, SVC)  or isinstance(clf1, RandomForestClassifier)  or isinstance(clf1, GaussianNB)  or isinstance(clf1, MLPClassifier)  or isinstance(clf1, DecisionTreeClassifier) or isinstance(clf1, KNeighborsClassifier):\n",
    "        protected_pred = reg2clf(protected_pred, threshold=thresh)\n",
    "    # Build model to predict the taget attribute Y\n",
    "    clf2 = copy.deepcopy(base_clf)\n",
    "\n",
    "    X_test.loc[:, keyword] = protected_pred\n",
    "\n",
    "    #X_test=pd.read_csv('generated_data/'+folder_name+'/'+str(global_timestamp)+'/fairmask_test'+str(base2)+str(random_seed)+'.csv')\n",
    "    \n",
    "    #Model Predict\n",
    "    clf2.fit(X_train,y_train)\n",
    "    \n",
    "    y_pred = clf2.predict(X_test) \n",
    "\n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                                   unfavorable_label=0.0,\n",
    "                                   df=dataset_orig_test,\n",
    "                                   label_names=['Probability'],\n",
    "                                   protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "\n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups) \n",
    "    \n",
    "        \n",
    "        \n",
    "    acc.append(round(class_metrics.accuracy(),2))\n",
    "    pre.append(round(class_metrics.precision(),2))\n",
    "    recall.append(round(class_metrics.recall(),2))\n",
    "    f1.append(round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2))\n",
    "    falsealarm.append(round(class_metrics.false_positive_rate(),2))\n",
    "\n",
    "    aod.append(round(np.abs(class_metrics.average_odds_difference()),2))\n",
    "    eod.append(round(np.abs(class_metrics.equal_opportunity_difference()),2))\n",
    "    spd.append(round(np.abs(class_metrics.statistical_parity_difference()),2))\n",
    "    di.append(round(np.abs(1-class_metrics.disparate_impact()),2))\n",
    "              \n",
    "    #print(\"Round\", (i + 1), \"finished.\")\n",
    "    #print('Time', time.time() - start)\n",
    "    \n",
    "    return acc[0],pre[0],recall[0],f1[0],falsealarm[0],aod[0],eod[0],spd[0],di[0]\n",
    "              \n",
    "#   return round(acc[0],2), round(pre[0],2), round(recall[0],2), round(f1[0],2), round(falsealarm[0],2), round(aod[0],2), round(eod[0],2), round(spd[0],2), round(di[0],2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e603c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fair_mask(random_state,dataset_orig_test,X_train,y_train,X_test,y_test,protected_attribute,time_stamp,folder_name):\n",
    "\n",
    "    fair_mask_results={} #for storing all results.\n",
    "    \n",
    "    fair_mask_lgr={}\n",
    "    fair_mask_svm={}\n",
    "    fair_mask_rf={}\n",
    "    fair_mask_nb={}\n",
    "    fair_mask_mlp={}\n",
    "    fair_mask_dt={}\n",
    "    fair_mask_knn={}\n",
    "    \n",
    "    \n",
    "    base = DecisionTreeClassifier(random_state=random_seed) \n",
    "    base2 = LogisticRegression(random_state=random_seed)\n",
    "   \n",
    "    a, p, r, f, far,ao, eo, spd, di = xFAIR(dataset_orig_test,X_train,y_train,X_test,y_test,base,base2,protected_attribute,time_stamp)\n",
    "   \n",
    "    fair_mask_lgr['recall']=r\n",
    "    fair_mask_lgr['far']=far\n",
    "    fair_mask_lgr['precision']=p\n",
    "    fair_mask_lgr['accuracy']=a\n",
    "    fair_mask_lgr['f1score']=f\n",
    "    fair_mask_lgr['aod']=ao\n",
    "    fair_mask_lgr['eod']=eo\n",
    "    fair_mask_lgr['spd']=spd\n",
    "    fair_mask_lgr['di']=di\n",
    "    \n",
    "    \n",
    "    base = DecisionTreeClassifier(random_state=random_seed) \n",
    "    base2 = SVC(random_state=random_seed)\n",
    "   \n",
    "    a, p, r, f, far,ao, eo, spd, di = xFAIR(dataset_orig_test,X_train,y_train,X_test,y_test,base,base2,protected_attribute,time_stamp)\n",
    "    \n",
    "    fair_mask_svm['recall']=r\n",
    "    fair_mask_svm['far']=far\n",
    "    fair_mask_svm['precision']=p\n",
    "    fair_mask_svm['accuracy']=a\n",
    "    fair_mask_svm['f1score']=f\n",
    "    fair_mask_svm['aod']=ao\n",
    "    fair_mask_svm['eod']=eo\n",
    "    fair_mask_svm['spd']=spd\n",
    "    fair_mask_svm['di']=di\n",
    "    \n",
    "    base = DecisionTreeClassifier(random_state=random_seed) \n",
    "    base2 = RandomForestClassifier(random_state=random_seed)\n",
    "    \n",
    "    a, p, r, f,far, ao, eo, spd, di = xFAIR(dataset_orig_test,X_train,y_train,X_test,y_test,base,base2,protected_attribute,time_stamp)\n",
    "    \n",
    "    fair_mask_rf['recall']=r\n",
    "    fair_mask_rf['far']=far\n",
    "    fair_mask_rf['precision']=p\n",
    "    fair_mask_rf['accuracy']=a\n",
    "    fair_mask_rf['f1score']=f\n",
    "    fair_mask_rf['aod']=ao\n",
    "    fair_mask_rf['eod']=eo\n",
    "    fair_mask_rf['spd']=spd\n",
    "    fair_mask_rf['di']=di\n",
    "    \n",
    "    base = DecisionTreeClassifier(random_state=random_seed) \n",
    "    base2 = GaussianNB()\n",
    "    \n",
    "    a, p, r, f, far, ao, eo, spd, di = xFAIR(dataset_orig_test,X_train,y_train,X_test,y_test,base,base2,protected_attribute,time_stamp)\n",
    "    \n",
    "    fair_mask_nb['recall']=r\n",
    "    fair_mask_nb['far']=far\n",
    "    fair_mask_nb['precision']=p\n",
    "    fair_mask_nb['accuracy']=a\n",
    "    fair_mask_nb['f1score']=f\n",
    "    fair_mask_nb['aod']=ao\n",
    "    fair_mask_nb['eod']=eo\n",
    "    fair_mask_nb['spd']=spd\n",
    "    fair_mask_nb['di']=di\n",
    "    \n",
    "    base = DecisionTreeClassifier(random_state=random_seed) \n",
    "    base2 = MLPClassifier(random_state=random_seed)\n",
    "    \n",
    "    a, p, r, f,far, ao, eo, spd, di = xFAIR(dataset_orig_test,X_train,y_train,X_test,y_test,base,base2,protected_attribute,time_stamp)\n",
    "    \n",
    "    fair_mask_mlp['recall']=r\n",
    "    fair_mask_mlp['far']=far\n",
    "    fair_mask_mlp['precision']=p\n",
    "    fair_mask_mlp['accuracy']=a\n",
    "    fair_mask_mlp['f1score']=f\n",
    "    fair_mask_mlp['aod']=ao\n",
    "    fair_mask_mlp['eod']=eo\n",
    "    fair_mask_mlp['spd']=spd\n",
    "    fair_mask_mlp['di']=di\n",
    "    \n",
    "    base = DecisionTreeClassifier(random_state=random_seed) \n",
    "    base2 = DecisionTreeClassifier(random_state=random_seed)\n",
    "    \n",
    "    a, p, r, f,far, ao, eo, spd, di = xFAIR(dataset_orig_test,X_train,y_train,X_test,y_test,base,base2,protected_attribute,time_stamp)\n",
    "    \n",
    "    fair_mask_dt['recall']=r\n",
    "    fair_mask_dt['far']=far\n",
    "    fair_mask_dt['precision']=p\n",
    "    fair_mask_dt['accuracy']=a\n",
    "    fair_mask_dt['f1score']=f\n",
    "    fair_mask_dt['aod']=ao\n",
    "    fair_mask_dt['eod']=eo\n",
    "    fair_mask_dt['spd']=spd\n",
    "    fair_mask_dt['di']=di\n",
    "    \n",
    "    base = DecisionTreeClassifier(random_state=random_seed) \n",
    "    base2 = KNeighborsClassifier()\n",
    "    \n",
    "    a, p, r, f,far, ao, eo, spd, di = xFAIR(dataset_orig_test,X_train,y_train,X_test,y_test,base,base2,protected_attribute,time_stamp)\n",
    "    \n",
    "    fair_mask_knn['recall']=r\n",
    "    fair_mask_knn['far']=far\n",
    "    fair_mask_knn['precision']=p\n",
    "    fair_mask_knn['accuracy']=a\n",
    "    fair_mask_knn['f1score']=f\n",
    "    fair_mask_knn['aod']=ao\n",
    "    fair_mask_knn['eod']=eo\n",
    "    fair_mask_knn['spd']=spd\n",
    "    fair_mask_knn['di']=di\n",
    "    \n",
    "    fair_mask_results['fair_mask_lgr']=fair_mask_lgr\n",
    "    fair_mask_results['fair_mask_svm']=fair_mask_svm\n",
    "    fair_mask_results['fair_mask_rf']=fair_mask_rf\n",
    "    fair_mask_results['fair_mask_nb']=fair_mask_nb\n",
    "    fair_mask_results['fair_mask_mlp']=fair_mask_mlp\n",
    "    fair_mask_results['fair_mask_dt']=fair_mask_dt\n",
    "    fair_mask_results['fair_mask_knn']=fair_mask_knn\n",
    "    \n",
    "    return fair_mask_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e908c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f411d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tdd(random_seed,dataset_orig_train1,dataset_orig_test1,X_train1,y_train1,X_test1,y_test1,\n",
    "        protected_attribute,global_timestamp,folder_name,dataset_name):\n",
    "    \n",
    "    dataset_orig_train=copy.deepcopy(dataset_orig_train1)\n",
    "    dataset_orig_test=copy.deepcopy(dataset_orig_test1)\n",
    "    X_train=copy.deepcopy(X_train1)\n",
    "    y_train=copy.deepcopy(y_train1)\n",
    "    X_test=copy.deepcopy(X_test1)\n",
    "    y_test=copy.deepcopy(y_test1)\n",
    "    \n",
    "    ce_list = []\n",
    "    ce_times = []\n",
    "    \n",
    "    tdd_results={} #for storing all results.\n",
    "    \n",
    "    tdd_lgr={}\n",
    "    tdd_svm={}\n",
    "    tdd_rf={}\n",
    "    tdd_nb={}\n",
    "    tdd_mlp={}\n",
    "    tdd_dt={}\n",
    "    tdd_knn={}\n",
    "    \n",
    "    \n",
    "    column_train = [column for column in X_train]\n",
    "    slope_store = []\n",
    "    intercept_store = []\n",
    "    rvalue_store = []\n",
    "    pvalue_store = []\n",
    "    column_u = []\n",
    "    flag = 0\n",
    "    ce = []\n",
    "    times = 0\n",
    "    \n",
    "    def Linear_regression(x, slope, intercept):\n",
    "        return x * slope + intercept\n",
    "    for i in column_train:\n",
    "        flag = flag + 1\n",
    "        if i != protected_attribute:\n",
    "            slope,intercept,rvalue,pvalue,stderr=stats.linregress(X_train[protected_attribute], X_train[i])\n",
    "            rvalue_store.append(rvalue)\n",
    "            pvalue_store.append(pvalue)\n",
    "            if i != protected_attribute:\n",
    "                if pvalue < 0.05:\n",
    "                    times = times + 1\n",
    "                    column_u.append(i)\n",
    "                    ce.append(flag)\n",
    "                    slope_store.append(slope)\n",
    "                    intercept_store.append(intercept)\n",
    "                    X_train[i] = X_train[i] - Linear_regression(X_train[protected_attribute], slope, intercept)\n",
    "\n",
    "    ce_list.append(ce)\n",
    "    ce_times.append(times)\n",
    "\n",
    "    X_train = X_train.drop([protected_attribute],axis = 1)\n",
    "\n",
    "    for i in range(len(column_u)):\n",
    "        X_test[column_u[i]] = X_test[column_u[i]] - Linear_regression(X_test[protected_attribute], slope_store[i],\n",
    "                                                                      intercept_store[i])\n",
    "\n",
    "    X_test = X_test.drop([protected_attribute],axis = 1)\n",
    " \n",
    "    #======================================= FairGenerate - LGR - START =========================================#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "       # --- LSR\n",
    "    clf = LogisticRegression(random_state=random_seed)\n",
    "    \n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "    \n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    \n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                                   unfavorable_label=0.0,\n",
    "                                   df=dataset_orig_test,\n",
    "                                   label_names=['Probability'],\n",
    "                                   protected_attribute_names=[protected_attribute])\n",
    "    \n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "    \n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "    \n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "    \n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "    \n",
    "   \n",
    "    tdd_lgr['recall']=round(class_metrics.recall(),2)\n",
    "    tdd_lgr['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    tdd_lgr['precision']=round(class_metrics.precision(),2)\n",
    "    tdd_lgr['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    tdd_lgr['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    tdd_lgr['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    tdd_lgr['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    tdd_lgr['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    tdd_lgr['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('LGR-', round(time.time() - start,2),end='| ')\n",
    "\n",
    "    \n",
    "    #tdd-SVM Classifier---------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "   \n",
    "    #classifier\n",
    "    clf=SVC(random_state=random_seed)\n",
    "    \n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test)\n",
    "    dataset_pred.labels = y_pred\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    tdd_svm['recall']=round(class_metrics.recall(),2)\n",
    "    tdd_svm['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    tdd_svm['precision']=round(class_metrics.precision(),2)\n",
    "    tdd_svm['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    tdd_svm['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    tdd_svm['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    tdd_svm['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    tdd_svm['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    tdd_svm['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('SVM-', round(time.time() - start,2),end='| ')\n",
    "    \n",
    "\n",
    "    #======================================= FairGenerate - RF - START =========================================#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf=RandomForestClassifier(random_state=random_seed)   \n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "   \n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                               unfavorable_label=0.0,\n",
    "                               df=dataset_orig_test,\n",
    "                               label_names=['Probability'],\n",
    "                               protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "\n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                   \n",
    "\n",
    "     \n",
    "    tdd_rf['recall']=round(class_metrics.recall(),2)\n",
    "    tdd_rf['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    tdd_rf['precision']=round(class_metrics.precision(),2)\n",
    "    tdd_rf['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    tdd_rf['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    tdd_rf['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    tdd_rf['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    tdd_rf['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    tdd_rf['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    " \n",
    "    print('RF-', round(time.time() - start,2),end='|')\n",
    "    \n",
    "      \n",
    "    \n",
    "    #tdd-Naive Bayes Classifier------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf= GaussianNB()    \n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_pred.labels = y_pred\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    tdd_nb['recall']=round(class_metrics.recall(),2)\n",
    "    tdd_nb['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    tdd_nb['precision']=round(class_metrics.precision(),2)\n",
    "    tdd_nb['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    tdd_nb['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    tdd_nb['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    tdd_nb['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    tdd_nb['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    tdd_nb['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('NB-', round(time.time() - start,2),end='|')\n",
    "    \n",
    "    #tdd-MLP Classifier--------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf= MLPClassifier(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_pred.labels = y_pred\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    tdd_mlp['recall']=round(class_metrics.recall(),2)\n",
    "    tdd_mlp['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    tdd_mlp['precision']=round(class_metrics.precision(),2)\n",
    "    tdd_mlp['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    tdd_mlp['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    tdd_mlp['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    tdd_mlp['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    tdd_mlp['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    tdd_mlp['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "        \n",
    "    print('MLP-', round(time.time() - start,2),end='| ')\n",
    "    \n",
    "    #tdd-Decision Trees Classifier----------------------------------------------------------------------------#\n",
    "    \n",
    "  \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "   \n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                               unfavorable_label=0.0,\n",
    "                               df=dataset_orig_test,\n",
    "                               label_names=['Probability'],\n",
    "                               protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "\n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)               \n",
    "    \n",
    "       \n",
    "    tdd_dt['recall']=round(class_metrics.recall(),2)\n",
    "    tdd_dt['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    tdd_dt['precision']=round(class_metrics.precision(),2)\n",
    "    tdd_dt['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    tdd_dt['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    tdd_dt['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    tdd_dt['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    tdd_dt['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    tdd_dt['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "     \n",
    "    print('DT-',  round(time.time() - start,2),end='| ')\n",
    "    \n",
    "        #=======================================TDD - DT - END  =========================================#\n",
    "\n",
    "\n",
    "    #tdd-KNN Classifier---------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf=  KNeighborsClassifier()\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_pred.labels = y_pred\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    tdd_knn['recall']=round(class_metrics.recall(),2)\n",
    "    tdd_knn['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    tdd_knn['precision']=round(class_metrics.precision(),2)\n",
    "    tdd_knn['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    tdd_knn['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    tdd_knn['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    tdd_knn['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    tdd_knn['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    tdd_knn['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "        \n",
    "    print('KNN-', round(time.time() - start,2),end='| ') \n",
    "    \n",
    "     #pass all results in tdd_results.\n",
    "    tdd_results['tdd_lgr']=tdd_lgr\n",
    "    tdd_results['tdd_svm']=tdd_svm\n",
    "    tdd_results['tdd_rf']=tdd_rf\n",
    "    tdd_results['tdd_nb']=tdd_nb\n",
    "    tdd_results['tdd_mlp']=tdd_mlp\n",
    "    tdd_results['tdd_dt']=tdd_dt\n",
    "    tdd_results['tdd_knn']=tdd_knn\n",
    "\n",
    "    \n",
    "    return tdd_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7876d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2391b8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reweigh(random_seed,dataset_orig_train1,dataset_orig_test1,X_train1,y_train1,X_test1,y_test1,\n",
    "        protected_attribute,global_timestamp,folder_name,dataset_name):\n",
    "    \n",
    "    reweigh_lgr={}\n",
    "    reweigh_svm={}\n",
    "    reweigh_rf={}\n",
    "    reweigh_nb={}\n",
    "    reweigh_mlp={}\n",
    "    reweigh_dt={}\n",
    "    reweigh_knn={}\n",
    "    \n",
    "    reweigh_results={}\n",
    "    \n",
    "    dataset_orig_train=copy.deepcopy(dataset_orig_train1)\n",
    "    dataset_orig_test=copy.deepcopy(dataset_orig_test1)\n",
    "    X_train=copy.deepcopy(X_train1)\n",
    "    y_train=copy.deepcopy(y_train1)\n",
    "    X_test=copy.deepcopy(X_test1)\n",
    "    y_test=copy.deepcopy(y_test1)\n",
    "    \n",
    "    \n",
    "    sc = MinMaxScaler()\n",
    "    base=LogisticRegression()\n",
    "    privileged_groups = [{protected_attribute: 1}]\n",
    "    unprivileged_groups = [{protected_attribute: 0}]\n",
    "    RW = Reweighing(unprivileged_groups=unprivileged_groups,privileged_groups=privileged_groups)\n",
    "\n",
    "    dataset_orig = BinaryLabelDataset(df=dataset_orig_train, label_names=['Probability'], protected_attribute_names=[protected_attribute])\n",
    "    dataset_orig_train, dataset_orig_valid = dataset_orig.split([0.7],shuffle=True, seed=random_seed)\n",
    "    dataset_orig_test = BinaryLabelDataset(df=dataset_orig_test, label_names=['Probability'], protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    RW.fit(dataset_orig_train)\n",
    "    dataset_transf_train = RW.transform(dataset_orig_train)\n",
    "\n",
    "    # Train on original data\n",
    "    X_train = sc.fit_transform(dataset_orig_train.features)\n",
    "    y_train = dataset_orig_train.labels.ravel()\n",
    "    w_train = dataset_orig_train.instance_weights.ravel()\n",
    "\n",
    "    lmod = copy.deepcopy(base)\n",
    "    lmod.fit(X_train, y_train,sample_weight=dataset_orig_train.instance_weights)\n",
    "    y_train_pred = lmod.predict(X_train)\n",
    "\n",
    "    # positive class index\n",
    "    pos_ind = np.where(lmod.classes_ == dataset_orig_train.favorable_label)[0][0]\n",
    "\n",
    "    dataset_orig_train_pred = dataset_orig_train.copy()\n",
    "    dataset_orig_train_pred.labels = y_train_pred\n",
    "\n",
    "    dataset_orig_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "    X_valid = sc.transform(dataset_orig_valid_pred.features)\n",
    "    y_valid = dataset_orig_valid_pred.labels\n",
    "    dataset_orig_valid_pred.scores = lmod.predict_proba(X_valid)[:, pos_ind].reshape(-1, 1)\n",
    "\n",
    "    dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "    X_test = sc.transform(dataset_orig_test_pred.features)\n",
    "    y_test = dataset_orig_test_pred.labels\n",
    "    dataset_orig_test_pred.scores = lmod.predict_proba(X_test)[:, pos_ind].reshape(-1, 1)\n",
    "\n",
    "    # find optimal thresh\n",
    "    num_thresh = 100\n",
    "    ba_arr = np.zeros(num_thresh)\n",
    "    class_thresh_arr = np.linspace(0.01, 0.99, num_thresh)\n",
    "    for idx, class_thresh in enumerate(class_thresh_arr):\n",
    "        fav_inds = dataset_orig_valid_pred.scores > class_thresh\n",
    "        dataset_orig_valid_pred.labels[fav_inds] = dataset_orig_valid_pred.favorable_label\n",
    "        dataset_orig_valid_pred.labels[~fav_inds] = dataset_orig_valid_pred.unfavorable_label\n",
    "\n",
    "        classified_metric_orig_valid = ClassificationMetric(dataset_orig_valid,\n",
    "                                                            dataset_orig_valid_pred,\n",
    "                                                            unprivileged_groups=unprivileged_groups,\n",
    "                                                            privileged_groups=privileged_groups)\n",
    "\n",
    "        ba_arr[idx] = 0.5 * (classified_metric_orig_valid.true_positive_rate() + classified_metric_orig_valid.true_negative_rate())\n",
    "    best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
    "    best_class_thresh = class_thresh_arr[best_ind]\n",
    "\n",
    "    # train on transformed data\n",
    "    X_train = sc.fit_transform(dataset_transf_train.features)\n",
    "    y_train = dataset_transf_train.labels.ravel()\n",
    "    w_train = dataset_transf_train.instance_weights.ravel()\n",
    "\n",
    "    lmod = copy.deepcopy(base)\n",
    "    lmod.fit(X_train, y_train,\n",
    "             sample_weight=dataset_transf_train.instance_weights)\n",
    "    y_train_pred = lmod.predict(X_train)\n",
    "\n",
    "    dataset_transf_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "    X_test = sc.fit_transform(dataset_transf_test_pred.features)\n",
    "    y_test = dataset_transf_test_pred.labels\n",
    "    dataset_transf_test_pred.scores = lmod.predict_proba(X_test)[:, pos_ind].reshape(-1, 1)\n",
    "\n",
    "    for thresh in (class_thresh_arr):\n",
    "        if thresh == best_class_thresh:\n",
    "            fav_inds = dataset_transf_test_pred.scores > thresh\n",
    "            dataset_transf_test_pred.labels[fav_inds] = dataset_transf_test_pred.favorable_label\n",
    "            dataset_transf_test_pred.labels[~fav_inds] = dataset_transf_test_pred.unfavorable_label\n",
    "    df_test = dataset_orig_test.convert_to_dataframe()[0]\n",
    "    df_pred = dataset_transf_test_pred.convert_to_dataframe()[0]\n",
    "    df_train = dataset_orig_train.convert_to_dataframe()[0]\n",
    "\n",
    "    X_test = (df_test.loc[:, df_test.columns != 'Probability'])\n",
    "    X_train = (df_train.loc[:, df_train.columns != 'Probability'])\n",
    "    y_test = df_test[\"Probability\"]\n",
    "    y_train = df_train[\"Probability\"]\n",
    "    y_pred = df_pred[\"Probability\"]\n",
    "                                \n",
    "    \n",
    "      #-------------------------------------------------------------  \n",
    "    start = time.time()\n",
    "    \n",
    "       # --- LSR\n",
    "    clf = LogisticRegression(random_state=random_seed)\n",
    "    \n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "    \n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    \n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                                   unfavorable_label=0.0,\n",
    "                                   df=dataset_orig_test1,\n",
    "                                   label_names=['Probability'],\n",
    "                                   protected_attribute_names=[protected_attribute])\n",
    "    \n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "    \n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "    \n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "    \n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "    \n",
    "   \n",
    "    reweigh_lgr['recall']=round(class_metrics.recall(),2)\n",
    "    reweigh_lgr['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    reweigh_lgr['precision']=round(class_metrics.precision(),2)\n",
    "    reweigh_lgr['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    reweigh_lgr['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    reweigh_lgr['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    reweigh_lgr['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    reweigh_lgr['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    reweigh_lgr['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('LGR-', round(time.time() - start,2),end='| ')\n",
    "    \n",
    "        \n",
    "    \n",
    "    #--------------------------------------------------reweigh-SVM Classifier--------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "   \n",
    "    #classifier\n",
    "    clf=SVC(random_state=random_seed)\n",
    "    \n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test)\n",
    "    dataset_pred.labels = y_pred\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    reweigh_svm['recall']=round(class_metrics.recall(),2)\n",
    "    reweigh_svm['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    reweigh_svm['precision']=round(class_metrics.precision(),2)\n",
    "    reweigh_svm['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    reweigh_svm['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    reweigh_svm['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    reweigh_svm['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    reweigh_svm['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    reweigh_svm['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('SVM-', round(time.time() - start,2),end='| ')\n",
    "    \n",
    "\n",
    "    #======================================= FairGenerate - RF - START =========================================#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf=RandomForestClassifier(random_state=random_seed)   \n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "   \n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                               unfavorable_label=0.0,\n",
    "                               df=dataset_orig_test1,\n",
    "                               label_names=['Probability'],\n",
    "                               protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "\n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                   \n",
    "\n",
    "     \n",
    "    reweigh_rf['recall']=round(class_metrics.recall(),2)\n",
    "    reweigh_rf['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    reweigh_rf['precision']=round(class_metrics.precision(),2)\n",
    "    reweigh_rf['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    reweigh_rf['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    reweigh_rf['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    reweigh_rf['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    reweigh_rf['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    reweigh_rf['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    " \n",
    "    print('RF-', round(time.time() - start,2),end='|')\n",
    "    \n",
    "\n",
    "    \n",
    "    #reweigh-Naive Bayes Classifier------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf= GaussianNB()    \n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_pred.labels = y_pred\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    reweigh_nb['recall']=round(class_metrics.recall(),2)\n",
    "    reweigh_nb['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    reweigh_nb['precision']=round(class_metrics.precision(),2)\n",
    "    reweigh_nb['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    reweigh_nb['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    reweigh_nb['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    reweigh_nb['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    reweigh_nb['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    reweigh_nb['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "    print('NB-', round(time.time() - start,2),end='|')\n",
    "    \n",
    "    #reweigh-MLP Classifier--------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf= MLPClassifier(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_pred.labels = y_pred\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    reweigh_mlp['recall']=round(class_metrics.recall(),2)\n",
    "    reweigh_mlp['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    reweigh_mlp['precision']=round(class_metrics.precision(),2)\n",
    "    reweigh_mlp['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    reweigh_mlp['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    reweigh_mlp['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    reweigh_mlp['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    reweigh_mlp['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    reweigh_mlp['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "    \n",
    "        \n",
    "    print('MLP-', round(time.time() - start,2),end='| ')\n",
    "    \n",
    "    #reweigh-Decision Trees Classifier----------------------------------------------------------------------------#\n",
    "    \n",
    "    #======================================= FairGenerate - DT - START =========================================#\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "   \n",
    "    dataset_t = BinaryLabelDataset(favorable_label=1.0,\n",
    "                               unfavorable_label=0.0,\n",
    "                               df=dataset_orig_test1,\n",
    "                               label_names=['Probability'],\n",
    "                               protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_pred = dataset_t.copy()  \n",
    "    dataset_pred.labels = y_pred    \n",
    "    attr = dataset_t.protected_attribute_names[0]\n",
    "    idx = dataset_t.protected_attribute_names.index(attr)\n",
    "\n",
    "    privileged_groups = [{attr: dataset_pred.privileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    unprivileged_groups = [{attr: dataset_pred.unprivileged_protected_attributes[idx][0]}]\n",
    "\n",
    "    \n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)               \n",
    "    \n",
    "       \n",
    "    reweigh_dt['recall']=round(class_metrics.recall(),2)\n",
    "    reweigh_dt['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    reweigh_dt['precision']=round(class_metrics.precision(),2)\n",
    "    reweigh_dt['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    reweigh_dt['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    reweigh_dt['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    reweigh_dt['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    reweigh_dt['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    reweigh_dt['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "     \n",
    "    print('DT-',  round(time.time() - start,2),end='| ')\n",
    "    \n",
    "     \n",
    "\n",
    "    #reweigh-KNN Classifier---------------------------------------------------------------------------------------#\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    #classifier\n",
    "    clf=  KNeighborsClassifier()\n",
    "\n",
    "    #Model Fit\n",
    "    clf.fit(X_train, y_train) \n",
    "\n",
    "    #Model Predict\n",
    "    y_pred = clf.predict(X_test) \n",
    "    dataset_pred.labels = y_pred\n",
    "\n",
    "    class_metrics = ClassificationMetric(dataset_t, dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)             #class_metrics Object\n",
    "\n",
    "    b_metrics = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)                \n",
    "\n",
    "     \n",
    "    reweigh_knn['recall']=round(class_metrics.recall(),2)\n",
    "    reweigh_knn['far']=round(class_metrics.false_positive_rate(),2)\n",
    "    reweigh_knn['precision']=round(class_metrics.precision(),2)\n",
    "    reweigh_knn['accuracy']=round(class_metrics.accuracy(),2)\n",
    "    reweigh_knn['f1score']=round((2*class_metrics.recall()*class_metrics.precision())/(class_metrics.precision()+class_metrics.recall()),2)\n",
    "    reweigh_knn['aod']=round(np.abs(class_metrics.average_odds_difference()),2)\n",
    "    reweigh_knn['eod']=round(np.abs(class_metrics.equal_opportunity_difference()),2)\n",
    "    reweigh_knn['spd']=round(np.abs(class_metrics.statistical_parity_difference()),2)\n",
    "    reweigh_knn['di']=round(np.abs(1-class_metrics.disparate_impact()),2)\n",
    "        \n",
    "    print('KNN-', round(time.time() - start,2),end='| ') \n",
    "    \n",
    "     #pass all results in reweigh_results.\n",
    "    reweigh_results['reweigh_lgr']=reweigh_lgr\n",
    "    reweigh_results['reweigh_svm']=reweigh_svm\n",
    "    reweigh_results['reweigh_rf']=reweigh_rf\n",
    "    reweigh_results['reweigh_nb']=reweigh_nb\n",
    "    reweigh_results['reweigh_mlp']=reweigh_mlp\n",
    "    reweigh_results['reweigh_dt']=reweigh_dt\n",
    "    reweigh_results['reweigh_knn']=reweigh_knn\n",
    "\n",
    "    \n",
    "    return reweigh_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8463d588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b90a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It's because we have to test the different approaches using the same test set.\n",
    "def run(random_state,dataset_orig_train,dataset_orig_test,X_train,y_train,X_test,y_test,protected_attribute,time_stamp,folder_name,dataset_name):\n",
    "    \n",
    "    #--------------------------------------------Default Runner------------------------------------------#\n",
    "    print(\"{}: Default Running\".format(random_seed),end=\" |\")\n",
    "    #calling default logistic regression function.\n",
    "    start = time.time()\n",
    "    default_results=\\\n",
    "    default(random_state,dataset_orig_test,X_train,y_train,X_test,y_test,protected_attribute,folder_name)\n",
    "    print('Time:', round(time.time() - start,2))\n",
    "    print('----------------------------------------------')\n",
    "    \n",
    "    #------------------------------------------Fair-Generate--------------------------------------------#\n",
    "    print(\"{}: FairGenerate Running\".format(random_seed),end=\" | \")   \n",
    "    start = time.time()\n",
    "    fair_preprocessor_results =\\\n",
    "    fair_preprocessor(random_state,dataset_orig_train,dataset_orig_test,X_train,y_train,X_test,y_test,protected_attribute,time_stamp,folder_name,dataset_name)\n",
    "    print('Time:', round(time.time() - start,2))\n",
    "    print('----------------------------------------------')  \n",
    "    \n",
    "    #------------------------------------------Fair-SMOTE----------------------------------------------#\n",
    "    print(\"{}: FairSMOTE Running\".format(random_seed),end=\" | \")   \n",
    "    start = time.time()\n",
    "    fair_smote_results =\\\n",
    "    fair_smote(random_state,dataset_orig_train,dataset_orig_test,X_train,y_train,X_test,y_test,protected_attribute,time_stamp,folder_name,dataset_name)\n",
    "    print('Time:', round(time.time() - start,2))\n",
    "    print('----------------------------------------------')\n",
    "    \n",
    "    #------------------------------------------Fair-MASK-----------------------------------------------#\n",
    "    print(\"{}: FairMask Running\".format(random_seed),end=\" | \")   \n",
    "    start = time.time()\n",
    "    fair_mask_results=fair_mask(random_state,dataset_orig_test,X_train,y_train,X_test,y_test,protected_attribute,time_stamp,folder_name)\n",
    "    print('Time:', round(time.time() - start,2))\n",
    "    print('----------------------------------------------')\n",
    "    \n",
    "    #------------------------------------------TDD----------------------------------------------------#\n",
    "    print(\"{}: TDD Running\".format(random_seed),end=\" | \")   \n",
    "    start = time.time()\n",
    "    tdd_results=tdd(random_seed,dataset_orig_train,dataset_orig_test,X_train,y_train,X_test,y_test,protected_attribute,time_stamp,folder_name,dataset_name)\n",
    "    print('Time:', round(time.time() - start,2))\n",
    "    print('----------------------------------------------')\n",
    "        \n",
    "    #------------------------------------------Reweighing----------------------------------------------#\n",
    "    print(\"{}: Reweigh Running\".format(random_seed),end=\" | \")   \n",
    "    start = time.time()\n",
    "    reweigh_results=reweigh(random_seed,dataset_orig_train,dataset_orig_test,X_train,y_train,X_test,y_test,protected_attribute,time_stamp,folder_name,dataset_name)\n",
    "    print('Time:', round(time.time() - start,2))\n",
    "    print('----------------------------------------------')\n",
    "        \n",
    "    #------------------------------------------SMOTE Running---------------------------------------------#\n",
    "    print(\"{}: SMOTE Running\".format(random_seed),end=\" |\")\n",
    "    #calling default logistic regression function.\n",
    "    start = time.time()\n",
    "    smote_results=\\\n",
    "    smote_(random_state,dataset_orig_test,X_train,y_train,X_test,y_test,protected_attribute,folder_name)\n",
    "    print('Time:', round(time.time() - start,2))\n",
    "    print('----------------------------------------------')\n",
    "        \n",
    "    #----------------------------------------Random OverSampling------------------------------------------#\n",
    "    print(\"{}: Random OverSampling Running\".format(random_seed),end=\" |\")\n",
    "    #calling default logistic regression function.\n",
    "    start = time.time()\n",
    "    ros_results=\\\n",
    "    ros(random_state,dataset_orig_test,X_train,y_train,X_test,y_test,protected_attribute,folder_name)\n",
    "    print('Time:', round(time.time() - start,2))\n",
    "    print('----------------------------------------------')\n",
    "    \n",
    "    #-----------------------------------------Random UnderSampling------------------------------------------#\n",
    "    print(\"{}: Random UnderSampling Running\".format(random_seed),end=\" |\")\n",
    "    #calling default logistic regression function.\n",
    "    start = time.time()\n",
    "    rus_results=\\\n",
    "    rus(random_state,dataset_orig_test,X_train,y_train,X_test,y_test,protected_attribute,folder_name)\n",
    "    print('Time:', round(time.time() - start,2))\n",
    "    print('----------------------------------------------')\n",
    "    \n",
    "    #return all results.\n",
    "    return default_results,fair_smote_results,fair_preprocessor_results,fair_mask_results,tdd_results,reweigh_results,smote_results,rus_results,ros_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae39484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd12d7f3",
   "metadata": {},
   "source": [
    "## Driver Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0ddd54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Default Running |LGR- 0.02835| SVM- 0.05705| RF- 0.20839|NB- 0.00428|MLP- 2.9687| DT- 0.0136| KNN- 0.07069| Time: 3.35204\n",
      "----------------------------------------------\n",
      "0: FairGenerate Running | LGR- 0.05| SVM- 0.05| RF- 0.18|NB- 0.0|MLP- 2.61| DT- 0.01| KNN- 0.07| Time: 2.98813\n",
      "----------------------------------------------\n",
      "0: FairSMOTE Running | LGR- 0.13| SVM- 0.07| RF- 0.16|NB- 0.01|MLP- 2.24| DT- 0.01| KNN- 0.07| Time: 2.707\n",
      "----------------------------------------------\n",
      "0: FairMask Running | Time: 3.06163\n",
      "----------------------------------------------\n",
      "0: TDD Running | LGR- 0.08494| SVM- 0.05386| RF- 0.16846|NB- 0.00438|MLP- 2.94977| DT- 0.03776| KNN- 0.18916| Time: 3.50576\n",
      "----------------------------------------------\n",
      "0: Reweigh Running | LGR- 0.07134| SVM- 0.04603| RF- 0.35599|NB- 0.00773|MLP- 3.06131| DT- 0.01308| KNN- 0.0625| Time: 3.82493\n",
      "----------------------------------------------\n",
      "0: SMOTE Running |LGR- 0.02203| SVM- 0.04587| RF- 0.16837|NB- 0.00452|MLP- 1.90133| DT- 0.03671| KNN- 0.06447| Time: 2.25152\n",
      "----------------------------------------------\n",
      "0: Random OverSampling Running |LGR- 0.0321| SVM- 0.06872| RF- 0.17873|NB- 0.0043|MLP- 4.30399| DT- 0.01728| KNN- 0.09032| Time: 4.70074\n",
      "----------------------------------------------\n",
      "0: Random UnderSampling Running |LGR- 0.07662| SVM- 0.03769| RF- 0.29706|NB- 0.00501|MLP- 4.69209| DT- 0.03505| KNN- 0.12094| Time: 5.27626\n",
      "----------------------------------------------\n",
      "1: Default Running |LGR- 0.14783| SVM- 0.03945| RF- 0.30715|NB- 0.00799|MLP- 3.01752| DT- 0.0238| KNN- 0.05588| Time: 3.60065\n",
      "----------------------------------------------\n",
      "1: FairGenerate Running | LGR- 0.02| SVM- 0.05| RF- 0.21|NB- 0.01|MLP- 3.54| DT- 0.01| KNN- 0.12| Time: 4.05222\n",
      "----------------------------------------------\n",
      "1: FairSMOTE Running | LGR- 0.1| SVM- 0.08| RF- 0.3|NB- 0.01|MLP- 3.78| DT- 0.02| KNN- 0.18| Time: 4.50848\n",
      "----------------------------------------------\n",
      "1: FairMask Running | Time: 4.76506\n",
      "----------------------------------------------\n",
      "1: TDD Running | LGR- 0.28483| SVM- 0.05984| RF- 0.20161|NB- 0.00417|MLP- 1.39446| DT- 0.01549| KNN- 0.06472| Time: 2.05108\n",
      "----------------------------------------------\n",
      "1: Reweigh Running | LGR- 0.02019| SVM- 0.02605| RF- 0.16573|NB- 0.00427|MLP- 1.53005| DT- 0.01174| KNN- 0.06812| Time: 2.09725\n",
      "----------------------------------------------\n",
      "1: SMOTE Running |LGR- 0.02462| SVM- 0.04997| RF- 0.29681|NB- 0.00827|MLP- 2.26134| DT- 0.03418| KNN- 0.07075| Time: 2.75326\n",
      "----------------------------------------------\n",
      "1: Random OverSampling Running |LGR- 0.04836| SVM- 0.03793| RF- 0.34226|NB- 0.00824|MLP- 2.61179| DT- 0.03797| KNN- 0.10027| Time: 3.19611\n",
      "----------------------------------------------\n",
      "1: Random UnderSampling Running |LGR- 0.07212| SVM- 0.08465| RF- 0.30052|NB- 0.00701|MLP- 2.93531| DT- 0.01247| KNN- 0.08971| Time: 3.51406\n",
      "----------------------------------------------\n",
      "2: Default Running |LGR- 0.05244| SVM- 0.04749| RF- 0.15994|NB- 0.00379|MLP- 2.78607| DT- 0.03647| KNN- 0.0356| Time: 3.12489\n",
      "----------------------------------------------\n",
      "2: FairGenerate Running | LGR- 0.07| SVM- 0.09| RF- 0.34|NB- 0.01|MLP- 2.68| DT- 0.01| KNN- 0.09| Time: 3.3176\n",
      "----------------------------------------------\n",
      "2: FairSMOTE Running | LGR- 0.08| SVM- 0.04| RF- 0.29|NB- 0.01|MLP- 2.98| DT- 0.02| KNN- 0.05| Time: 3.49241\n",
      "----------------------------------------------\n",
      "2: FairMask Running | Time: 3.65359\n",
      "----------------------------------------------\n",
      "2: TDD Running | LGR- 0.0205| SVM- 0.04365| RF- 0.17454|NB- 0.00434|MLP- 2.60415| DT- 0.05015| KNN- 0.1046| Time: 3.02388\n",
      "----------------------------------------------\n",
      "2: Reweigh Running | LGR- 0.04204| SVM- 0.07371| RF- 0.29347|NB- 0.00719|MLP- 1.80585| DT- 0.01435| KNN- 0.07763| Time: 2.54676\n",
      "----------------------------------------------\n",
      "2: SMOTE Running |LGR- 0.0853| SVM- 0.06014| RF- 0.32896|NB- 0.00734|MLP- 2.29788| DT- 0.0136| KNN- 0.06591| Time: 2.88177\n",
      "----------------------------------------------\n",
      "2: Random OverSampling Running |LGR- 0.13445| SVM- 0.08363| RF- 0.15747|NB- 0.00418|MLP- 2.92308| DT- 0.04228| KNN- 0.04422| Time: 3.39373\n",
      "----------------------------------------------\n",
      "2: Random UnderSampling Running |LGR- 0.08453| SVM- 0.09795| RF- 0.31322|NB- 0.00789|MLP- 2.56302| DT- 0.02559| KNN- 0.12598| Time: 3.23338\n",
      "----------------------------------------------\n",
      "3: Default Running |LGR- 0.09326| SVM- 0.08986| RF- 0.25747|NB- 0.00721|MLP- 2.33456| DT- 0.02467| KNN- 0.05548| Time: 2.86544\n",
      "----------------------------------------------\n",
      "3: FairGenerate Running | LGR- 0.13| SVM- 0.05| RF- 0.17|NB- 0.01|MLP- 2.03| DT- 0.03| KNN- 0.15| Time: 2.57987\n",
      "----------------------------------------------\n",
      "3: FairSMOTE Running | LGR- 0.1| SVM- 0.09| RF- 0.3|NB- 0.01|MLP- 2.89| DT- 0.01| KNN- 0.11| Time: 3.52121\n",
      "----------------------------------------------\n",
      "3: FairMask Running | Time: 2.82819\n",
      "----------------------------------------------\n",
      "3: TDD Running | LGR- 0.05145| SVM- 0.045| RF- 0.34441|NB- 0.00807|MLP- 1.21454| DT- 0.01286| KNN- 0.03678| Time: 1.75299\n",
      "----------------------------------------------\n",
      "3: Reweigh Running | LGR- 0.0173| SVM- 0.05965| RF- 0.15575|NB- 0.00389|MLP- 1.34837| DT- 0.01268| KNN- 0.06815| Time: 1.76498\n",
      "----------------------------------------------\n",
      "3: SMOTE Running |LGR- 0.14888| SVM- 0.05224| RF- 0.1539|NB- 0.0061|MLP- 2.2335| DT- 0.02119| KNN- 0.12909| Time: 2.75465\n",
      "----------------------------------------------\n",
      "3: Random OverSampling Running |LGR- 0.10848| SVM- 0.07172| RF- 0.35327|NB- 0.00791|MLP- 3.09616| DT- 0.04215| KNN- 0.03499| Time: 3.7309\n",
      "----------------------------------------------\n",
      "3: Random UnderSampling Running |LGR- 0.18431| SVM- 0.0782| RF- 0.27434|NB- 0.00436|MLP- 1.94422| DT- 0.02251| KNN- 0.05863| Time: 2.6177\n",
      "----------------------------------------------\n",
      "4: Default Running |LGR- 0.08906| SVM- 0.06408| RF- 0.15461|NB- 0.00414|MLP- 2.55604| DT- 0.02519| KNN- 0.1372| Time: 3.03352\n",
      "----------------------------------------------\n",
      "4: FairGenerate Running | LGR- 0.04| SVM- 0.08| RF- 0.33|NB- 0.01|MLP- 2.51| DT- 0.02| KNN- 0.11| Time: 3.11306\n",
      "----------------------------------------------\n",
      "4: FairSMOTE Running | LGR- 0.03| SVM- 0.05| RF- 0.29|NB- 0.01|MLP- 2.04| DT- 0.02| KNN- 0.07| Time: 2.49971\n",
      "----------------------------------------------\n",
      "4: FairMask Running | Time: 3.01599\n",
      "----------------------------------------------\n",
      "4: TDD Running | LGR- 0.06965| SVM- 0.04161| RF- 0.17298|NB- 0.00569|MLP- 2.89129| DT- 0.02635| KNN- 0.03583| Time: 3.26352\n",
      "----------------------------------------------\n",
      "4: Reweigh Running | LGR- 0.02867| SVM- 0.04238| RF- 0.32441|NB- 0.00808|MLP- 1.63446| DT- 0.01147| KNN- 0.09938| Time: 2.36748\n",
      "----------------------------------------------\n",
      "4: SMOTE Running |LGR- 0.01813| SVM- 0.0432| RF- 0.2993|NB- 0.00619|MLP- 2.05201| DT- 0.0408| KNN- 0.06612| Time: 2.58436\n",
      "----------------------------------------------\n",
      "4: Random OverSampling Running |LGR- 0.02934| SVM- 0.04444| RF- 0.21785|NB- 0.00431|MLP- 1.24287| DT- 0.01504| KNN- 0.02552| Time: 1.58409\n",
      "----------------------------------------------\n",
      "4: Random UnderSampling Running |LGR- 0.03925| SVM- 0.03431| RF- 0.16598|NB- 0.00403|MLP- 2.5019| DT- 0.03337| KNN- 0.07055| Time: 2.85876\n",
      "----------------------------------------------\n",
      "5: Default Running |LGR- 0.1145| SVM- 0.0914| RF- 0.31105|NB- 0.00702|MLP- 2.58881| DT- 0.0392| KNN- 0.16487| Time: 3.31785\n",
      "----------------------------------------------\n",
      "5: FairGenerate Running | LGR- 0.15| SVM- 0.04| RF- 0.3|NB- 0.01|MLP- 2.15| DT- 0.02| KNN- 0.06| Time: 2.77288\n",
      "----------------------------------------------\n",
      "5: FairSMOTE Running | LGR- 0.12| SVM- 0.08| RF- 0.16|NB- 0.0|MLP- 1.91| DT- 0.01| KNN- 0.07| Time: 2.35396\n",
      "----------------------------------------------\n",
      "5: FairMask Running | Time: 3.66765\n",
      "----------------------------------------------\n",
      "5: TDD Running | LGR- 0.03125| SVM- 0.06643| RF- 0.32407|NB- 0.00823|MLP- 2.3664| DT- 0.03383| KNN- 0.11072| Time: 2.97687\n",
      "----------------------------------------------\n",
      "5: Reweigh Running | LGR- 0.02639| SVM- 0.02507| RF- 0.32528|NB- 0.00809|MLP- 1.6996| DT- 0.01485| KNN- 0.06446| Time: 2.33884\n",
      "----------------------------------------------\n",
      "5: SMOTE Running |LGR- 0.09775| SVM- 0.0478| RF- 0.16291|NB- 0.00388|MLP- 1.45106| DT- 0.01642| KNN- 0.04768| Time: 1.83598\n",
      "----------------------------------------------\n",
      "5: Random OverSampling Running |LGR- 0.02135| SVM- 0.04213| RF- 0.17547|NB- 0.00778|MLP- 3.01296| DT- 0.02751| KNN- 0.04873| Time: 3.34539\n",
      "----------------------------------------------\n",
      "5: Random UnderSampling Running |LGR- 0.04167| SVM- 0.06344| RF- 0.33228|NB- 0.00793|MLP- 2.71135| DT- 0.01346| KNN- 0.066| Time: 3.25344\n",
      "----------------------------------------------\n",
      "6: Default Running |LGR- 0.05095| SVM- 0.04425| RF- 0.16574|NB- 0.00405|MLP- 2.47019| DT- 0.02012| KNN- 0.03381| Time: 2.79001\n",
      "----------------------------------------------\n",
      "6: FairGenerate Running | LGR- 0.05| SVM- 0.05| RF- 0.29|NB- 0.01|MLP- 2.7| DT- 0.01| KNN- 0.06| Time: 3.24096\n",
      "----------------------------------------------\n",
      "6: FairSMOTE Running | LGR- 0.04| SVM- 0.04| RF- 0.33|NB- 0.0|MLP- 2.13| DT- 0.01| KNN- 0.07| Time: 2.64362\n",
      "----------------------------------------------\n",
      "6: FairMask Running | Time: 4.23145\n",
      "----------------------------------------------\n",
      "6: TDD Running | LGR- 0.01992| SVM- 0.0354| RF- 0.31206|NB- 0.00798|MLP- 2.68186| DT- 0.04092| KNN- 0.10186| Time: 3.231\n",
      "----------------------------------------------\n",
      "6: Reweigh Running | LGR- 0.06053| SVM- 0.04486| RF- 0.31847|NB- 0.00746|MLP- 1.51216| DT- 0.01936| KNN- 0.07105| Time: 2.24927\n",
      "----------------------------------------------\n",
      "6: SMOTE Running |LGR- 0.01393| SVM- 0.03472| RF- 0.24482|NB- 0.00398|MLP- 3.07709| DT- 0.02596| KNN- 0.08536| Time: 3.50953\n",
      "----------------------------------------------\n",
      "6: Random OverSampling Running |LGR- 0.02612| SVM- 0.06757| RF- 0.26094|NB- 0.00683|MLP- 1.64124| DT- 0.01263| KNN- 0.11744| Time: 2.13971\n",
      "----------------------------------------------\n",
      "6: Random UnderSampling Running |LGR- 0.02048| SVM- 0.03363| RF- 0.26216|NB- 0.00587|MLP- 1.60617| DT- 0.0397| KNN- 0.09623| Time: 2.07411\n",
      "----------------------------------------------\n",
      "7: Default Running |LGR- 0.09036| SVM- 0.08466| RF- 0.33259|NB- 0.00825|MLP- 2.53082| DT- 0.04426| KNN- 0.04427| Time: 3.13603\n",
      "----------------------------------------------\n",
      "7: FairGenerate Running | LGR- 0.09| SVM- 0.04| RF- 0.18|NB- 0.0|MLP- 2.7| DT- 0.01| KNN- 0.1| Time: 3.14428\n",
      "----------------------------------------------\n",
      "7: FairSMOTE Running | LGR- 0.06| SVM- 0.05| RF- 0.35|NB- 0.01|MLP- 4.04| DT- 0.03| KNN- 0.05| Time: 4.68928\n",
      "----------------------------------------------\n",
      "7: FairMask Running | Time: 2.43202\n",
      "----------------------------------------------\n",
      "7: TDD Running | LGR- 0.07438| SVM- 0.06854| RF- 0.16269|NB- 0.00404|MLP- 2.8823| DT- 0.037| KNN- 0.03465| Time: 3.28759\n",
      "----------------------------------------------\n",
      "7: Reweigh Running | LGR- 0.04962| SVM- 0.06016| RF- 0.27003|NB- 0.00701|MLP- 1.88473| DT- 0.01423| KNN- 0.09312| Time: 2.67019\n",
      "----------------------------------------------\n",
      "7: SMOTE Running |LGR- 0.03735| SVM- 0.05081| RF- 0.2895|NB- 0.00719|MLP- 2.36672| DT- 0.01258| KNN- 0.0676| Time: 2.90455\n",
      "----------------------------------------------\n",
      "7: Random OverSampling Running |LGR- 0.16514| SVM- 0.03911| RF- 0.17532|NB- 0.00426|MLP- 2.69474| DT- 0.03685| KNN- 0.12803| Time: 3.25283\n",
      "----------------------------------------------\n",
      "7: Random UnderSampling Running |LGR- 0.14223| SVM- 0.05368| RF- 0.25883|NB- 0.00688|MLP- 2.77128| DT- 0.02432| KNN- 0.11506| Time: 3.38264\n",
      "----------------------------------------------\n",
      "8: Default Running |LGR- 0.08159| SVM- 0.09709| RF- 0.31023|NB- 0.00874|MLP- 3.35093| DT- 0.02602| KNN- 0.14288| Time: 4.02101\n",
      "----------------------------------------------\n",
      "8: FairGenerate Running | LGR- 0.06| SVM- 0.05| RF- 0.31|NB- 0.0|MLP- 2.49| DT- 0.01| KNN- 0.08| Time: 3.04543\n",
      "----------------------------------------------\n",
      "8: FairSMOTE Running | LGR- 0.14| SVM- 0.11| RF- 0.32|NB- 0.01|MLP- 4.62| DT- 0.04| KNN- 0.05| Time: 5.49907\n",
      "----------------------------------------------\n",
      "8: FairMask Running | Time: 6.05199\n",
      "----------------------------------------------\n",
      "8: TDD Running | LGR- 0.03419| SVM- 0.04151| RF- 0.35609|NB- 0.00794|MLP- 1.79407| DT- 0.02161| KNN- 0.05971| Time: 2.34885\n",
      "----------------------------------------------\n",
      "8: Reweigh Running | LGR- 0.02031| SVM- 0.05315| RF- 0.15606|NB- 0.00422|MLP- 1.86274| DT- 0.01415| KNN- 0.08234| Time: 2.40743\n",
      "----------------------------------------------\n",
      "8: SMOTE Running |LGR- 0.05492| SVM- 0.07335| RF- 0.16838|NB- 0.00397|MLP- 5.17559| DT- 0.05785| KNN- 0.08846| Time: 5.66212\n",
      "----------------------------------------------\n",
      "8: Random OverSampling Running |LGR- 0.14204| SVM- 0.0742| RF- 0.33429|NB- 0.00788|MLP- 3.64058| DT- 0.01376| KNN- 0.06629| Time: 4.29053\n",
      "----------------------------------------------\n",
      "8: Random UnderSampling Running |LGR- 0.10127| SVM- 0.06022| RF- 0.15491|NB- 0.00375|MLP- 2.6615| DT- 0.02411| KNN- 0.05211| Time: 3.0646\n",
      "----------------------------------------------\n",
      "9: Default Running |LGR- 0.09971| SVM- 0.08418| RF- 0.35843|NB- 0.0084|MLP- 1.86322| DT- 0.01417| KNN- 0.06294| Time: 2.49663\n",
      "----------------------------------------------\n",
      "9: FairGenerate Running | LGR- 0.08| SVM- 0.07| RF- 0.15|NB- 0.0|MLP- 4.68| DT- 0.01| KNN- 0.09| Time: 5.11714\n",
      "----------------------------------------------\n",
      "9: FairSMOTE Running | LGR- 0.04| SVM- 0.04| RF- 0.3|NB- 0.01|MLP- 2.3| DT- 0.02| KNN- 0.1| Time: 2.82358\n",
      "----------------------------------------------\n",
      "9: FairMask Running | Time: 3.30054\n",
      "----------------------------------------------\n",
      "9: TDD Running | LGR- 0.05633| SVM- 0.03565| RF- 0.2191|NB- 0.00542|MLP- 5.41181| DT- 0.03607| KNN- 0.12253| Time: 5.90809\n",
      "----------------------------------------------\n",
      "9: Reweigh Running | LGR- 0.02276| SVM- 0.02815| RF- 0.31049|NB- 0.00775|MLP- 2.65501| DT- 0.02682| KNN- 0.11349| Time: 3.45618\n",
      "----------------------------------------------\n",
      "9: SMOTE Running |LGR- 0.10232| SVM- 0.0823| RF- 0.33383|NB- 0.00829|MLP- 4.2711| DT- 0.03887| KNN- 0.06835| Time: 4.96046\n",
      "----------------------------------------------\n",
      "9: Random OverSampling Running |LGR- 0.03463| SVM- 0.07196| RF- 0.23402|NB- 0.00679|MLP- 5.68737| DT- 0.03672| KNN- 0.04955| Time: 6.12868\n",
      "----------------------------------------------\n",
      "9: Random UnderSampling Running |LGR- 0.06629| SVM- 0.07253| RF- 0.28662|NB- 0.00764|MLP- 3.0407| DT- 0.01253| KNN- 0.07103| Time: 3.57272\n",
      "----------------------------------------------\n",
      "10: Default Running |LGR- 0.13422| SVM- 0.04697| RF- 0.17756|NB- 0.00487|MLP- 4.81664| DT- 0.02741| KNN- 0.0598| Time: 5.26885\n",
      "----------------------------------------------\n",
      "10: FairGenerate Running | LGR- 0.09| SVM- 0.07| RF- 0.26|NB- 0.01|MLP- 5.62| DT- 0.02| KNN- 0.16| Time: 6.26045\n",
      "----------------------------------------------\n",
      "10: FairSMOTE Running | LGR- 0.08| SVM- 0.09| RF- 0.36|NB- 0.01|MLP- 2.88| DT- 0.01| KNN- 0.07| Time: 3.52027\n",
      "----------------------------------------------\n",
      "10: FairMask Running | Time: 4.04248\n",
      "----------------------------------------------\n",
      "10: TDD Running | LGR- 0.08201| SVM- 0.07396| RF- 0.36286|NB- 0.00824|MLP- 4.67373| DT- 0.0128| KNN- 0.07495| Time: 5.32454\n",
      "----------------------------------------------\n",
      "10: Reweigh Running | LGR- 0.09747| SVM- 0.05036| RF- 0.19318|NB- 0.00409|MLP- 2.22995| DT- 0.02932| KNN- 0.05585| Time: 2.86767\n",
      "----------------------------------------------\n",
      "10: SMOTE Running |LGR- 0.12418| SVM- 0.04969| RF- 0.1646|NB- 0.00481|MLP- 3.55261| DT- 0.02776| KNN- 0.06516| Time: 3.99713\n",
      "----------------------------------------------\n",
      "10: Random OverSampling Running |LGR- 0.07027| SVM- 0.10232| RF- 0.38071|NB- 0.00884|MLP- 4.62232| DT- 0.03337| KNN- 0.11773| Time: 5.34922\n",
      "----------------------------------------------\n",
      "10: Random UnderSampling Running |LGR- 0.06372| SVM- 0.04402| RF- 0.32317|NB- 0.00798|MLP- 1.55769| DT- 0.01446| KNN- 0.06485| Time: 2.08582\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for random_seed in random_state:\n",
    "    \n",
    "    dataset_orig_train=pd.read_csv('generated_data/'+folder_name+'/'+str(time_stamp)+'/dataset_orig_train_'+str(random_seed)+'.csv')\n",
    "    dataset_orig_test=pd.read_csv('generated_data/'+folder_name+'/'+str(time_stamp)+'/dataset_orig_test_'+str(random_seed)+'.csv')\n",
    "    \n",
    "    X_train, y_train = dataset_orig_train.loc[:, dataset_orig_train.columns != 'Probability'],dataset_orig_train['Probability']\n",
    "    X_test, y_test = dataset_orig_test.loc[:, dataset_orig_test.columns != 'Probability'],dataset_orig_test['Probability']\n",
    "    \n",
    "    #calling default,fair-generate,fair-smote\n",
    "    default_results,fair_smote_results,fair_preprocessor_results,fair_mask_results,\\\n",
    "    tdd_results,reweigh_results,smote_results,rus_results,ros_results=\\\n",
    "    run(random_seed,dataset_orig_train,dataset_orig_test,X_train, y_train,X_test,y_test,protected_attribute,time_stamp,folder_name,dataset_name)   \n",
    "    \n",
    "    \n",
    "    #***********************************************************************************************#\n",
    "    #storing results of Default Classifier - Logistic Regression, Support Vector Machine, Random Forest\n",
    "    default_lgr_recall.append(default_results['default_lgr']['recall'])\n",
    "    default_lgr_far.append(default_results['default_lgr']['far'])\n",
    "    default_lgr_precision.append(default_results['default_lgr']['precision'])\n",
    "    default_lgr_accuracy.append(default_results['default_lgr']['accuracy'])\n",
    "    default_lgr_f1score.append(default_results['default_lgr']['f1score'])\n",
    "    default_lgr_aod.append(default_results['default_lgr']['aod'])\n",
    "    default_lgr_eod.append(default_results['default_lgr']['eod'])\n",
    "    default_lgr_spd.append(default_results['default_lgr']['spd'])\n",
    "    default_lgr_di.append(default_results['default_lgr']['di'])\n",
    "    \n",
    "    default_svm_recall.append(default_results['default_svm']['recall'])\n",
    "    default_svm_far.append(default_results['default_svm']['far'])\n",
    "    default_svm_precision.append(default_results['default_svm']['precision'])\n",
    "    default_svm_accuracy.append(default_results['default_svm']['accuracy'])\n",
    "    default_svm_f1score.append(default_results['default_svm']['f1score'])\n",
    "    default_svm_aod.append(default_results['default_svm']['aod'])\n",
    "    default_svm_eod.append(default_results['default_svm']['eod'])\n",
    "    default_svm_spd.append(default_results['default_svm']['spd'])\n",
    "    default_svm_di.append(default_results['default_svm']['di'])\n",
    "    \n",
    "    default_rf_recall.append(default_results['default_rf']['recall'])\n",
    "    default_rf_far.append(default_results['default_rf']['far'])\n",
    "    default_rf_precision.append(default_results['default_rf']['precision'])\n",
    "    default_rf_accuracy.append(default_results['default_rf']['accuracy'])\n",
    "    default_rf_f1score.append(default_results['default_rf']['f1score'])\n",
    "    default_rf_aod.append(default_results['default_rf']['aod'])\n",
    "    default_rf_eod.append(default_results['default_rf']['eod'])\n",
    "    default_rf_spd.append(default_results['default_rf']['spd'])\n",
    "    default_rf_di.append(default_results['default_rf']['di'])\n",
    "    \n",
    "    default_nb_recall.append(default_results['default_nb']['recall'])\n",
    "    default_nb_far.append(default_results['default_nb']['far'])\n",
    "    default_nb_precision.append(default_results['default_nb']['precision'])\n",
    "    default_nb_accuracy.append(default_results['default_nb']['accuracy'])\n",
    "    default_nb_f1score.append(default_results['default_nb']['f1score'])\n",
    "    default_nb_aod.append(default_results['default_nb']['aod'])\n",
    "    default_nb_eod.append(default_results['default_nb']['eod'])\n",
    "    default_nb_spd.append(default_results['default_nb']['spd'])\n",
    "    default_nb_di.append(default_results['default_nb']['di'])\n",
    "    \n",
    "    default_mlp_recall.append(default_results['default_mlp']['recall'])\n",
    "    default_mlp_far.append(default_results['default_mlp']['far'])\n",
    "    default_mlp_precision.append(default_results['default_mlp']['precision'])\n",
    "    default_mlp_accuracy.append(default_results['default_mlp']['accuracy'])\n",
    "    default_mlp_f1score.append(default_results['default_mlp']['f1score'])\n",
    "    default_mlp_aod.append(default_results['default_mlp']['aod'])\n",
    "    default_mlp_eod.append(default_results['default_mlp']['eod'])\n",
    "    default_mlp_spd.append(default_results['default_mlp']['spd'])\n",
    "    default_mlp_di.append(default_results['default_mlp']['di'])\n",
    "    \n",
    "    default_dt_recall.append(default_results['default_dt']['recall'])\n",
    "    default_dt_far.append(default_results['default_dt']['far'])\n",
    "    default_dt_precision.append(default_results['default_dt']['precision'])\n",
    "    default_dt_accuracy.append(default_results['default_dt']['accuracy'])\n",
    "    default_dt_f1score.append(default_results['default_dt']['f1score'])\n",
    "    default_dt_aod.append(default_results['default_dt']['aod'])\n",
    "    default_dt_eod.append(default_results['default_dt']['eod'])\n",
    "    default_dt_spd.append(default_results['default_dt']['spd'])\n",
    "    default_dt_di.append(default_results['default_dt']['di'])\n",
    "    \n",
    "    default_knn_recall.append(default_results['default_knn']['recall'])\n",
    "    default_knn_far.append(default_results['default_knn']['far'])\n",
    "    default_knn_precision.append(default_results['default_knn']['precision'])\n",
    "    default_knn_accuracy.append(default_results['default_knn']['accuracy'])\n",
    "    default_knn_f1score.append(default_results['default_knn']['f1score'])\n",
    "    default_knn_aod.append(default_results['default_knn']['aod'])\n",
    "    default_knn_eod.append(default_results['default_knn']['eod'])\n",
    "    default_knn_spd.append(default_results['default_knn']['spd'])\n",
    "    default_knn_di.append(default_results['default_knn']['di'])\n",
    "   \n",
    "    #***********************************************************************************************#\n",
    "    #storing results of FairSMOTE approach, Classifier - Logistic Regression, Support Vector Machine, Random Forest\n",
    "    fair_smote_lgr_recall.append(fair_smote_results['fair_smote_lgr']['recall'])\n",
    "    fair_smote_lgr_far.append(fair_smote_results['fair_smote_lgr']['far'])\n",
    "    fair_smote_lgr_precision.append(fair_smote_results['fair_smote_lgr']['precision'])\n",
    "    fair_smote_lgr_accuracy.append(fair_smote_results['fair_smote_lgr']['accuracy'])\n",
    "    fair_smote_lgr_f1score.append(fair_smote_results['fair_smote_lgr']['f1score'])\n",
    "    fair_smote_lgr_aod.append(fair_smote_results['fair_smote_lgr']['aod'])\n",
    "    fair_smote_lgr_eod.append(fair_smote_results['fair_smote_lgr']['eod'])\n",
    "    fair_smote_lgr_spd.append(fair_smote_results['fair_smote_lgr']['spd'])\n",
    "    fair_smote_lgr_di.append(fair_smote_results['fair_smote_lgr']['di'])\n",
    "\n",
    "    fair_smote_svm_recall.append(fair_smote_results['fair_smote_svm']['recall'])\n",
    "    fair_smote_svm_far.append(fair_smote_results['fair_smote_svm']['far'])\n",
    "    fair_smote_svm_precision.append(fair_smote_results['fair_smote_svm']['precision'])\n",
    "    fair_smote_svm_accuracy.append(fair_smote_results['fair_smote_svm']['accuracy'])\n",
    "    fair_smote_svm_f1score.append(fair_smote_results['fair_smote_svm']['f1score'])\n",
    "    fair_smote_svm_aod.append(fair_smote_results['fair_smote_svm']['aod'])\n",
    "    fair_smote_svm_eod.append(fair_smote_results['fair_smote_svm']['eod'])\n",
    "    fair_smote_svm_spd.append(fair_smote_results['fair_smote_svm']['spd'])\n",
    "    fair_smote_svm_di.append(fair_smote_results['fair_smote_svm']['di'])\n",
    "\n",
    "    fair_smote_rf_recall.append(fair_smote_results['fair_smote_rf']['recall'])\n",
    "    fair_smote_rf_far.append(fair_smote_results['fair_smote_rf']['far'])\n",
    "    fair_smote_rf_precision.append(fair_smote_results['fair_smote_rf']['precision'])\n",
    "    fair_smote_rf_accuracy.append(fair_smote_results['fair_smote_rf']['accuracy'])\n",
    "    fair_smote_rf_f1score.append(fair_smote_results['fair_smote_rf']['f1score'])\n",
    "    fair_smote_rf_aod.append(fair_smote_results['fair_smote_rf']['aod'])\n",
    "    fair_smote_rf_eod.append(fair_smote_results['fair_smote_rf']['eod'])\n",
    "    fair_smote_rf_spd.append(fair_smote_results['fair_smote_rf']['spd'])\n",
    "    fair_smote_rf_di.append(fair_smote_results['fair_smote_rf']['di'])\n",
    "\n",
    "    fair_smote_nb_recall.append(fair_smote_results['fair_smote_nb']['recall'])\n",
    "    fair_smote_nb_far.append(fair_smote_results['fair_smote_nb']['far'])\n",
    "    fair_smote_nb_precision.append(fair_smote_results['fair_smote_nb']['precision'])\n",
    "    fair_smote_nb_accuracy.append(fair_smote_results['fair_smote_nb']['accuracy'])\n",
    "    fair_smote_nb_f1score.append(fair_smote_results['fair_smote_nb']['f1score'])\n",
    "    fair_smote_nb_aod.append(fair_smote_results['fair_smote_nb']['aod'])\n",
    "    fair_smote_nb_eod.append(fair_smote_results['fair_smote_nb']['eod'])\n",
    "    fair_smote_nb_spd.append(fair_smote_results['fair_smote_nb']['spd'])\n",
    "    fair_smote_nb_di.append(fair_smote_results['fair_smote_nb']['di'])\n",
    "\n",
    "    fair_smote_mlp_recall.append(fair_smote_results['fair_smote_mlp']['recall'])\n",
    "    fair_smote_mlp_far.append(fair_smote_results['fair_smote_mlp']['far'])\n",
    "    fair_smote_mlp_precision.append(fair_smote_results['fair_smote_mlp']['precision'])\n",
    "    fair_smote_mlp_accuracy.append(fair_smote_results['fair_smote_mlp']['accuracy'])\n",
    "    fair_smote_mlp_f1score.append(fair_smote_results['fair_smote_mlp']['f1score'])\n",
    "    fair_smote_mlp_aod.append(fair_smote_results['fair_smote_mlp']['aod'])\n",
    "    fair_smote_mlp_eod.append(fair_smote_results['fair_smote_mlp']['eod'])\n",
    "    fair_smote_mlp_spd.append(fair_smote_results['fair_smote_mlp']['spd'])\n",
    "    fair_smote_mlp_di.append(fair_smote_results['fair_smote_mlp']['di'])\n",
    "\n",
    "    fair_smote_dt_recall.append(fair_smote_results['fair_smote_dt']['recall'])\n",
    "    fair_smote_dt_far.append(fair_smote_results['fair_smote_dt']['far'])\n",
    "    fair_smote_dt_precision.append(fair_smote_results['fair_smote_dt']['precision'])\n",
    "    fair_smote_dt_accuracy.append(fair_smote_results['fair_smote_dt']['accuracy'])\n",
    "    fair_smote_dt_f1score.append(fair_smote_results['fair_smote_dt']['f1score'])\n",
    "    fair_smote_dt_aod.append(fair_smote_results['fair_smote_dt']['aod'])\n",
    "    fair_smote_dt_eod.append(fair_smote_results['fair_smote_dt']['eod'])\n",
    "    fair_smote_dt_spd.append(fair_smote_results['fair_smote_dt']['spd'])\n",
    "    fair_smote_dt_di.append(fair_smote_results['fair_smote_dt']['di'])\n",
    "\n",
    "    fair_smote_knn_recall.append(fair_smote_results['fair_smote_knn']['recall'])\n",
    "    fair_smote_knn_far.append(fair_smote_results['fair_smote_knn']['far'])\n",
    "    fair_smote_knn_precision.append(fair_smote_results['fair_smote_knn']['precision'])\n",
    "    fair_smote_knn_accuracy.append(fair_smote_results['fair_smote_knn']['accuracy'])\n",
    "    fair_smote_knn_f1score.append(fair_smote_results['fair_smote_knn']['f1score'])\n",
    "    fair_smote_knn_aod.append(fair_smote_results['fair_smote_knn']['aod'])\n",
    "    fair_smote_knn_eod.append(fair_smote_results['fair_smote_knn']['eod'])\n",
    "    fair_smote_knn_spd.append(fair_smote_results['fair_smote_knn']['spd'])\n",
    "    fair_smote_knn_di.append(fair_smote_results['fair_smote_knn']['di'])\n",
    "\n",
    "#***********************************************************************************************#\n",
    "# Storing results of FairGenerate approach, Classifier - Logistic Regression, Support Vector Machine, \n",
    "# Random Forest, Naive Bayes, Multi Layer Perceptron, Decision Tree, K Nearest Neighbours.\n",
    "#***********************************************************************************************#\n",
    "    \n",
    "    fair_preprocessor_lgr_recall.append(fair_preprocessor_results['fair_preprocessor_lgr']['recall'])\n",
    "    fair_preprocessor_lgr_far.append(fair_preprocessor_results['fair_preprocessor_lgr']['far'])\n",
    "    fair_preprocessor_lgr_precision.append(fair_preprocessor_results['fair_preprocessor_lgr']['precision'])\n",
    "    fair_preprocessor_lgr_accuracy.append(fair_preprocessor_results['fair_preprocessor_lgr']['accuracy'])\n",
    "    fair_preprocessor_lgr_f1score.append(fair_preprocessor_results['fair_preprocessor_lgr']['f1score'])\n",
    "    fair_preprocessor_lgr_aod.append(fair_preprocessor_results['fair_preprocessor_lgr']['aod'])\n",
    "    fair_preprocessor_lgr_eod.append(fair_preprocessor_results['fair_preprocessor_lgr']['eod'])\n",
    "    fair_preprocessor_lgr_spd.append(fair_preprocessor_results['fair_preprocessor_lgr']['spd'])\n",
    "    fair_preprocessor_lgr_di.append(fair_preprocessor_results['fair_preprocessor_lgr']['di'])\n",
    "\n",
    "    fair_preprocessor_svm_recall.append(fair_preprocessor_results['fair_preprocessor_svm']['recall'])\n",
    "    fair_preprocessor_svm_far.append(fair_preprocessor_results['fair_preprocessor_svm']['far'])\n",
    "    fair_preprocessor_svm_precision.append(fair_preprocessor_results['fair_preprocessor_svm']['precision'])\n",
    "    fair_preprocessor_svm_accuracy.append(fair_preprocessor_results['fair_preprocessor_svm']['accuracy'])\n",
    "    fair_preprocessor_svm_f1score.append(fair_preprocessor_results['fair_preprocessor_svm']['f1score'])\n",
    "    fair_preprocessor_svm_aod.append(fair_preprocessor_results['fair_preprocessor_svm']['aod'])\n",
    "    fair_preprocessor_svm_eod.append(fair_preprocessor_results['fair_preprocessor_svm']['eod'])\n",
    "    fair_preprocessor_svm_spd.append(fair_preprocessor_results['fair_preprocessor_svm']['spd'])\n",
    "    fair_preprocessor_svm_di.append(fair_preprocessor_results['fair_preprocessor_svm']['di'])\n",
    "\n",
    "    fair_preprocessor_rf_recall.append(fair_preprocessor_results['fair_preprocessor_rf']['recall'])\n",
    "    fair_preprocessor_rf_far.append(fair_preprocessor_results['fair_preprocessor_rf']['far'])\n",
    "    fair_preprocessor_rf_precision.append(fair_preprocessor_results['fair_preprocessor_rf']['precision'])\n",
    "    fair_preprocessor_rf_accuracy.append(fair_preprocessor_results['fair_preprocessor_rf']['accuracy'])\n",
    "    fair_preprocessor_rf_f1score.append(fair_preprocessor_results['fair_preprocessor_rf']['f1score'])\n",
    "    fair_preprocessor_rf_aod.append(fair_preprocessor_results['fair_preprocessor_rf']['aod'])\n",
    "    fair_preprocessor_rf_eod.append(fair_preprocessor_results['fair_preprocessor_rf']['eod'])\n",
    "    fair_preprocessor_rf_spd.append(fair_preprocessor_results['fair_preprocessor_rf']['spd'])\n",
    "    fair_preprocessor_rf_di.append(fair_preprocessor_results['fair_preprocessor_rf']['di'])\n",
    "\n",
    "    fair_preprocessor_nb_recall.append(fair_preprocessor_results['fair_preprocessor_nb']['recall'])\n",
    "    fair_preprocessor_nb_far.append(fair_preprocessor_results['fair_preprocessor_nb']['far'])\n",
    "    fair_preprocessor_nb_precision.append(fair_preprocessor_results['fair_preprocessor_nb']['precision'])\n",
    "    fair_preprocessor_nb_accuracy.append(fair_preprocessor_results['fair_preprocessor_nb']['accuracy'])\n",
    "    fair_preprocessor_nb_f1score.append(fair_preprocessor_results['fair_preprocessor_nb']['f1score'])\n",
    "    fair_preprocessor_nb_aod.append(fair_preprocessor_results['fair_preprocessor_nb']['aod'])\n",
    "    fair_preprocessor_nb_eod.append(fair_preprocessor_results['fair_preprocessor_nb']['eod'])\n",
    "    fair_preprocessor_nb_spd.append(fair_preprocessor_results['fair_preprocessor_nb']['spd'])\n",
    "    fair_preprocessor_nb_di.append(fair_preprocessor_results['fair_preprocessor_nb']['di'])\n",
    "\n",
    "    fair_preprocessor_mlp_recall.append(fair_preprocessor_results['fair_preprocessor_mlp']['recall'])\n",
    "    fair_preprocessor_mlp_far.append(fair_preprocessor_results['fair_preprocessor_mlp']['far'])\n",
    "    fair_preprocessor_mlp_precision.append(fair_preprocessor_results['fair_preprocessor_mlp']['precision'])\n",
    "    fair_preprocessor_mlp_accuracy.append(fair_preprocessor_results['fair_preprocessor_mlp']['accuracy'])\n",
    "    fair_preprocessor_mlp_f1score.append(fair_preprocessor_results['fair_preprocessor_mlp']['f1score'])\n",
    "    fair_preprocessor_mlp_aod.append(fair_preprocessor_results['fair_preprocessor_mlp']['aod'])\n",
    "    fair_preprocessor_mlp_eod.append(fair_preprocessor_results['fair_preprocessor_mlp']['eod'])\n",
    "    fair_preprocessor_mlp_spd.append(fair_preprocessor_results['fair_preprocessor_mlp']['spd'])\n",
    "    fair_preprocessor_mlp_di.append(fair_preprocessor_results['fair_preprocessor_mlp']['di'])\n",
    "\n",
    "    fair_preprocessor_dt_recall.append(fair_preprocessor_results['fair_preprocessor_dt']['recall'])\n",
    "    fair_preprocessor_dt_far.append(fair_preprocessor_results['fair_preprocessor_dt']['far'])\n",
    "    fair_preprocessor_dt_precision.append(fair_preprocessor_results['fair_preprocessor_dt']['precision'])\n",
    "    fair_preprocessor_dt_accuracy.append(fair_preprocessor_results['fair_preprocessor_dt']['accuracy'])\n",
    "    fair_preprocessor_dt_f1score.append(fair_preprocessor_results['fair_preprocessor_dt']['f1score'])\n",
    "    fair_preprocessor_dt_aod.append(fair_preprocessor_results['fair_preprocessor_dt']['aod'])\n",
    "    fair_preprocessor_dt_eod.append(fair_preprocessor_results['fair_preprocessor_dt']['eod'])\n",
    "    fair_preprocessor_dt_spd.append(fair_preprocessor_results['fair_preprocessor_dt']['spd'])\n",
    "    fair_preprocessor_dt_di.append(fair_preprocessor_results['fair_preprocessor_dt']['di'])\n",
    "\n",
    "    fair_preprocessor_knn_recall.append(fair_preprocessor_results['fair_preprocessor_knn']['recall'])\n",
    "    fair_preprocessor_knn_far.append(fair_preprocessor_results['fair_preprocessor_knn']['far'])\n",
    "    fair_preprocessor_knn_precision.append(fair_preprocessor_results['fair_preprocessor_knn']['precision'])\n",
    "    fair_preprocessor_knn_accuracy.append(fair_preprocessor_results['fair_preprocessor_knn']['accuracy'])\n",
    "    fair_preprocessor_knn_f1score.append(fair_preprocessor_results['fair_preprocessor_knn']['f1score'])\n",
    "    fair_preprocessor_knn_aod.append(fair_preprocessor_results['fair_preprocessor_knn']['aod'])\n",
    "    fair_preprocessor_knn_eod.append(fair_preprocessor_results['fair_preprocessor_knn']['eod'])\n",
    "    fair_preprocessor_knn_spd.append(fair_preprocessor_results['fair_preprocessor_knn']['spd'])\n",
    "    fair_preprocessor_knn_di.append(fair_preprocessor_results['fair_preprocessor_knn']['di'])\n",
    "\n",
    " #storing results of FairMASK approach, Classifier - Logistic Regression, Support Vector Machine, Random Forest\n",
    "\n",
    "    fair_mask_lgr_recall.append(fair_mask_results['fair_mask_lgr']['recall'])\n",
    "    fair_mask_lgr_far.append(fair_mask_results['fair_mask_lgr']['far'])\n",
    "    fair_mask_lgr_precision.append(fair_mask_results['fair_mask_lgr']['precision'])\n",
    "    fair_mask_lgr_accuracy.append(fair_mask_results['fair_mask_lgr']['accuracy'])\n",
    "    fair_mask_lgr_f1score.append(fair_mask_results['fair_mask_lgr']['f1score'])\n",
    "    fair_mask_lgr_aod.append(fair_mask_results['fair_mask_lgr']['aod'])\n",
    "    fair_mask_lgr_eod.append(fair_mask_results['fair_mask_lgr']['eod'])\n",
    "    fair_mask_lgr_spd.append(fair_mask_results['fair_mask_lgr']['spd'])\n",
    "    fair_mask_lgr_di.append(fair_mask_results['fair_mask_lgr']['di'])\n",
    "    \n",
    "    fair_mask_svm_recall.append(fair_mask_results['fair_mask_svm']['recall'])\n",
    "    fair_mask_svm_far.append(fair_mask_results['fair_mask_svm']['far'])\n",
    "    fair_mask_svm_precision.append(fair_mask_results['fair_mask_svm']['precision'])\n",
    "    fair_mask_svm_accuracy.append(fair_mask_results['fair_mask_svm']['accuracy'])\n",
    "    fair_mask_svm_f1score.append(fair_mask_results['fair_mask_svm']['f1score'])\n",
    "    fair_mask_svm_aod.append(fair_mask_results['fair_mask_svm']['aod'])\n",
    "    fair_mask_svm_eod.append(fair_mask_results['fair_mask_svm']['eod'])\n",
    "    fair_mask_svm_spd.append(fair_mask_results['fair_mask_svm']['spd'])\n",
    "    fair_mask_svm_di.append(fair_mask_results['fair_mask_svm']['di'])\n",
    "    \n",
    "    fair_mask_rf_recall.append(fair_mask_results['fair_mask_rf']['recall'])\n",
    "    fair_mask_rf_far.append(fair_mask_results['fair_mask_rf']['far'])\n",
    "    fair_mask_rf_precision.append(fair_mask_results['fair_mask_rf']['precision'])\n",
    "    fair_mask_rf_accuracy.append(fair_mask_results['fair_mask_rf']['accuracy'])\n",
    "    fair_mask_rf_f1score.append(fair_mask_results['fair_mask_rf']['f1score'])\n",
    "    fair_mask_rf_aod.append(fair_mask_results['fair_mask_rf']['aod'])\n",
    "    fair_mask_rf_eod.append(fair_mask_results['fair_mask_rf']['eod'])\n",
    "    fair_mask_rf_spd.append(fair_mask_results['fair_mask_rf']['spd'])\n",
    "    fair_mask_rf_di.append(fair_mask_results['fair_mask_rf']['di'])\n",
    "    \n",
    "    fair_mask_nb_recall.append(fair_mask_results['fair_mask_nb']['recall'])\n",
    "    fair_mask_nb_far.append(fair_mask_results['fair_mask_nb']['far'])\n",
    "    fair_mask_nb_precision.append(fair_mask_results['fair_mask_nb']['precision'])\n",
    "    fair_mask_nb_accuracy.append(fair_mask_results['fair_mask_nb']['accuracy'])\n",
    "    fair_mask_nb_f1score.append(fair_mask_results['fair_mask_nb']['f1score'])\n",
    "    fair_mask_nb_aod.append(fair_mask_results['fair_mask_nb']['aod'])\n",
    "    fair_mask_nb_eod.append(fair_mask_results['fair_mask_nb']['eod'])\n",
    "    fair_mask_nb_spd.append(fair_mask_results['fair_mask_nb']['spd'])\n",
    "    fair_mask_nb_di.append(fair_mask_results['fair_mask_nb']['di'])\n",
    "    \n",
    "    fair_mask_mlp_recall.append(fair_mask_results['fair_mask_mlp']['recall'])\n",
    "    fair_mask_mlp_far.append(fair_mask_results['fair_mask_mlp']['far'])\n",
    "    fair_mask_mlp_precision.append(fair_mask_results['fair_mask_mlp']['precision'])\n",
    "    fair_mask_mlp_accuracy.append(fair_mask_results['fair_mask_mlp']['accuracy'])\n",
    "    fair_mask_mlp_f1score.append(fair_mask_results['fair_mask_mlp']['f1score'])\n",
    "    fair_mask_mlp_aod.append(fair_mask_results['fair_mask_mlp']['aod'])\n",
    "    fair_mask_mlp_eod.append(fair_mask_results['fair_mask_mlp']['eod'])\n",
    "    fair_mask_mlp_spd.append(fair_mask_results['fair_mask_mlp']['spd'])\n",
    "    fair_mask_mlp_di.append(fair_mask_results['fair_mask_mlp']['di'])\n",
    "    \n",
    "    fair_mask_dt_recall.append(fair_mask_results['fair_mask_dt']['recall'])\n",
    "    fair_mask_dt_far.append(fair_mask_results['fair_mask_dt']['far'])\n",
    "    fair_mask_dt_precision.append(fair_mask_results['fair_mask_dt']['precision'])\n",
    "    fair_mask_dt_accuracy.append(fair_mask_results['fair_mask_dt']['accuracy'])\n",
    "    fair_mask_dt_f1score.append(fair_mask_results['fair_mask_dt']['f1score'])\n",
    "    fair_mask_dt_aod.append(fair_mask_results['fair_mask_dt']['aod'])\n",
    "    fair_mask_dt_eod.append(fair_mask_results['fair_mask_dt']['eod'])\n",
    "    fair_mask_dt_spd.append(fair_mask_results['fair_mask_dt']['spd'])\n",
    "    fair_mask_dt_di.append(fair_mask_results['fair_mask_dt']['di'])\n",
    "    \n",
    "    \n",
    "    fair_mask_knn_recall.append(fair_mask_results['fair_mask_knn']['recall'])\n",
    "    fair_mask_knn_far.append(fair_mask_results['fair_mask_knn']['far'])\n",
    "    fair_mask_knn_precision.append(fair_mask_results['fair_mask_knn']['precision'])\n",
    "    fair_mask_knn_accuracy.append(fair_mask_results['fair_mask_knn']['accuracy'])\n",
    "    fair_mask_knn_f1score.append(fair_mask_results['fair_mask_knn']['f1score'])\n",
    "    fair_mask_knn_aod.append(fair_mask_results['fair_mask_knn']['aod'])\n",
    "    fair_mask_knn_eod.append(fair_mask_results['fair_mask_knn']['eod'])\n",
    "    fair_mask_knn_spd.append(fair_mask_results['fair_mask_knn']['spd'])\n",
    "    fair_mask_knn_di.append(fair_mask_results['fair_mask_knn']['di'])\n",
    "\n",
    "\n",
    "    \n",
    "    #***********************************************************************************************#\n",
    "    #storing results of tdd Classifier - Logistic Regression, Support Vector Machine, Random Forest\n",
    "    tdd_lgr_recall.append(tdd_results['tdd_lgr']['recall'])\n",
    "    tdd_lgr_far.append(tdd_results['tdd_lgr']['far'])\n",
    "    tdd_lgr_precision.append(tdd_results['tdd_lgr']['precision'])\n",
    "    tdd_lgr_accuracy.append(tdd_results['tdd_lgr']['accuracy'])\n",
    "    tdd_lgr_f1score.append(tdd_results['tdd_lgr']['f1score'])\n",
    "    tdd_lgr_aod.append(tdd_results['tdd_lgr']['aod'])\n",
    "    tdd_lgr_eod.append(tdd_results['tdd_lgr']['eod'])\n",
    "    tdd_lgr_spd.append(tdd_results['tdd_lgr']['spd'])\n",
    "    tdd_lgr_di.append(tdd_results['tdd_lgr']['di'])\n",
    "    \n",
    "    tdd_svm_recall.append(tdd_results['tdd_svm']['recall'])\n",
    "    tdd_svm_far.append(tdd_results['tdd_svm']['far'])\n",
    "    tdd_svm_precision.append(tdd_results['tdd_svm']['precision'])\n",
    "    tdd_svm_accuracy.append(tdd_results['tdd_svm']['accuracy'])\n",
    "    tdd_svm_f1score.append(tdd_results['tdd_svm']['f1score'])\n",
    "    tdd_svm_aod.append(tdd_results['tdd_svm']['aod'])\n",
    "    tdd_svm_eod.append(tdd_results['tdd_svm']['eod'])\n",
    "    tdd_svm_spd.append(tdd_results['tdd_svm']['spd'])\n",
    "    tdd_svm_di.append(tdd_results['tdd_svm']['di'])\n",
    "    \n",
    "    tdd_rf_recall.append(tdd_results['tdd_rf']['recall'])\n",
    "    tdd_rf_far.append(tdd_results['tdd_rf']['far'])\n",
    "    tdd_rf_precision.append(tdd_results['tdd_rf']['precision'])\n",
    "    tdd_rf_accuracy.append(tdd_results['tdd_rf']['accuracy'])\n",
    "    tdd_rf_f1score.append(tdd_results['tdd_rf']['f1score'])\n",
    "    tdd_rf_aod.append(tdd_results['tdd_rf']['aod'])\n",
    "    tdd_rf_eod.append(tdd_results['tdd_rf']['eod'])\n",
    "    tdd_rf_spd.append(tdd_results['tdd_rf']['spd'])\n",
    "    tdd_rf_di.append(tdd_results['tdd_rf']['di'])\n",
    "    \n",
    "    tdd_nb_recall.append(tdd_results['tdd_nb']['recall'])\n",
    "    tdd_nb_far.append(tdd_results['tdd_nb']['far'])\n",
    "    tdd_nb_precision.append(tdd_results['tdd_nb']['precision'])\n",
    "    tdd_nb_accuracy.append(tdd_results['tdd_nb']['accuracy'])\n",
    "    tdd_nb_f1score.append(tdd_results['tdd_nb']['f1score'])\n",
    "    tdd_nb_aod.append(tdd_results['tdd_nb']['aod'])\n",
    "    tdd_nb_eod.append(tdd_results['tdd_nb']['eod'])\n",
    "    tdd_nb_spd.append(tdd_results['tdd_nb']['spd'])\n",
    "    tdd_nb_di.append(tdd_results['tdd_nb']['di'])\n",
    "    \n",
    "    tdd_mlp_recall.append(tdd_results['tdd_mlp']['recall'])\n",
    "    tdd_mlp_far.append(tdd_results['tdd_mlp']['far'])\n",
    "    tdd_mlp_precision.append(tdd_results['tdd_mlp']['precision'])\n",
    "    tdd_mlp_accuracy.append(tdd_results['tdd_mlp']['accuracy'])\n",
    "    tdd_mlp_f1score.append(tdd_results['tdd_mlp']['f1score'])\n",
    "    tdd_mlp_aod.append(tdd_results['tdd_mlp']['aod'])\n",
    "    tdd_mlp_eod.append(tdd_results['tdd_mlp']['eod'])\n",
    "    tdd_mlp_spd.append(tdd_results['tdd_mlp']['spd'])\n",
    "    tdd_mlp_di.append(tdd_results['tdd_mlp']['di'])\n",
    "    \n",
    "    tdd_dt_recall.append(tdd_results['tdd_dt']['recall'])\n",
    "    tdd_dt_far.append(tdd_results['tdd_dt']['far'])\n",
    "    tdd_dt_precision.append(tdd_results['tdd_dt']['precision'])\n",
    "    tdd_dt_accuracy.append(tdd_results['tdd_dt']['accuracy'])\n",
    "    tdd_dt_f1score.append(tdd_results['tdd_dt']['f1score'])\n",
    "    tdd_dt_aod.append(tdd_results['tdd_dt']['aod'])\n",
    "    tdd_dt_eod.append(tdd_results['tdd_dt']['eod'])\n",
    "    tdd_dt_spd.append(tdd_results['tdd_dt']['spd'])\n",
    "    tdd_dt_di.append(tdd_results['tdd_dt']['di'])\n",
    "    \n",
    "    tdd_knn_recall.append(tdd_results['tdd_knn']['recall'])\n",
    "    tdd_knn_far.append(tdd_results['tdd_knn']['far'])\n",
    "    tdd_knn_precision.append(tdd_results['tdd_knn']['precision'])\n",
    "    tdd_knn_accuracy.append(tdd_results['tdd_knn']['accuracy'])\n",
    "    tdd_knn_f1score.append(tdd_results['tdd_knn']['f1score'])\n",
    "    tdd_knn_aod.append(tdd_results['tdd_knn']['aod'])\n",
    "    tdd_knn_eod.append(tdd_results['tdd_knn']['eod'])\n",
    "    tdd_knn_spd.append(tdd_results['tdd_knn']['spd'])\n",
    "    tdd_knn_di.append(tdd_results['tdd_knn']['di'])\n",
    "   \n",
    "\n",
    "    #***********************************************************************************************#\n",
    "    #storing results of reweigh Classifier - Logistic Regression, Support Vector Machine, Random Forest\n",
    "    reweigh_lgr_recall.append(reweigh_results['reweigh_lgr']['recall'])\n",
    "    reweigh_lgr_far.append(reweigh_results['reweigh_lgr']['far'])\n",
    "    reweigh_lgr_precision.append(reweigh_results['reweigh_lgr']['precision'])\n",
    "    reweigh_lgr_accuracy.append(reweigh_results['reweigh_lgr']['accuracy'])\n",
    "    reweigh_lgr_f1score.append(reweigh_results['reweigh_lgr']['f1score'])\n",
    "    reweigh_lgr_aod.append(reweigh_results['reweigh_lgr']['aod'])\n",
    "    reweigh_lgr_eod.append(reweigh_results['reweigh_lgr']['eod'])\n",
    "    reweigh_lgr_spd.append(reweigh_results['reweigh_lgr']['spd'])\n",
    "    reweigh_lgr_di.append(reweigh_results['reweigh_lgr']['di'])\n",
    "    \n",
    "    reweigh_svm_recall.append(reweigh_results['reweigh_svm']['recall'])\n",
    "    reweigh_svm_far.append(reweigh_results['reweigh_svm']['far'])\n",
    "    reweigh_svm_precision.append(reweigh_results['reweigh_svm']['precision'])\n",
    "    reweigh_svm_accuracy.append(reweigh_results['reweigh_svm']['accuracy'])\n",
    "    reweigh_svm_f1score.append(reweigh_results['reweigh_svm']['f1score'])\n",
    "    reweigh_svm_aod.append(reweigh_results['reweigh_svm']['aod'])\n",
    "    reweigh_svm_eod.append(reweigh_results['reweigh_svm']['eod'])\n",
    "    reweigh_svm_spd.append(reweigh_results['reweigh_svm']['spd'])\n",
    "    reweigh_svm_di.append(reweigh_results['reweigh_svm']['di'])\n",
    "    \n",
    "    reweigh_rf_recall.append(reweigh_results['reweigh_rf']['recall'])\n",
    "    reweigh_rf_far.append(reweigh_results['reweigh_rf']['far'])\n",
    "    reweigh_rf_precision.append(reweigh_results['reweigh_rf']['precision'])\n",
    "    reweigh_rf_accuracy.append(reweigh_results['reweigh_rf']['accuracy'])\n",
    "    reweigh_rf_f1score.append(reweigh_results['reweigh_rf']['f1score'])\n",
    "    reweigh_rf_aod.append(reweigh_results['reweigh_rf']['aod'])\n",
    "    reweigh_rf_eod.append(reweigh_results['reweigh_rf']['eod'])\n",
    "    reweigh_rf_spd.append(reweigh_results['reweigh_rf']['spd'])\n",
    "    reweigh_rf_di.append(reweigh_results['reweigh_rf']['di'])\n",
    "    \n",
    "    reweigh_nb_recall.append(reweigh_results['reweigh_nb']['recall'])\n",
    "    reweigh_nb_far.append(reweigh_results['reweigh_nb']['far'])\n",
    "    reweigh_nb_precision.append(reweigh_results['reweigh_nb']['precision'])\n",
    "    reweigh_nb_accuracy.append(reweigh_results['reweigh_nb']['accuracy'])\n",
    "    reweigh_nb_f1score.append(reweigh_results['reweigh_nb']['f1score'])\n",
    "    reweigh_nb_aod.append(reweigh_results['reweigh_nb']['aod'])\n",
    "    reweigh_nb_eod.append(reweigh_results['reweigh_nb']['eod'])\n",
    "    reweigh_nb_spd.append(reweigh_results['reweigh_nb']['spd'])\n",
    "    reweigh_nb_di.append(reweigh_results['reweigh_nb']['di'])\n",
    "    \n",
    "    reweigh_mlp_recall.append(reweigh_results['reweigh_mlp']['recall'])\n",
    "    reweigh_mlp_far.append(reweigh_results['reweigh_mlp']['far'])\n",
    "    reweigh_mlp_precision.append(reweigh_results['reweigh_mlp']['precision'])\n",
    "    reweigh_mlp_accuracy.append(reweigh_results['reweigh_mlp']['accuracy'])\n",
    "    reweigh_mlp_f1score.append(reweigh_results['reweigh_mlp']['f1score'])\n",
    "    reweigh_mlp_aod.append(reweigh_results['reweigh_mlp']['aod'])\n",
    "    reweigh_mlp_eod.append(reweigh_results['reweigh_mlp']['eod'])\n",
    "    reweigh_mlp_spd.append(reweigh_results['reweigh_mlp']['spd'])\n",
    "    reweigh_mlp_di.append(reweigh_results['reweigh_mlp']['di'])\n",
    "    \n",
    "    reweigh_dt_recall.append(reweigh_results['reweigh_dt']['recall'])\n",
    "    reweigh_dt_far.append(reweigh_results['reweigh_dt']['far'])\n",
    "    reweigh_dt_precision.append(reweigh_results['reweigh_dt']['precision'])\n",
    "    reweigh_dt_accuracy.append(reweigh_results['reweigh_dt']['accuracy'])\n",
    "    reweigh_dt_f1score.append(reweigh_results['reweigh_dt']['f1score'])\n",
    "    reweigh_dt_aod.append(reweigh_results['reweigh_dt']['aod'])\n",
    "    reweigh_dt_eod.append(reweigh_results['reweigh_dt']['eod'])\n",
    "    reweigh_dt_spd.append(reweigh_results['reweigh_dt']['spd'])\n",
    "    reweigh_dt_di.append(reweigh_results['reweigh_dt']['di'])\n",
    "    \n",
    "    reweigh_knn_recall.append(reweigh_results['reweigh_knn']['recall'])\n",
    "    reweigh_knn_far.append(reweigh_results['reweigh_knn']['far'])\n",
    "    reweigh_knn_precision.append(reweigh_results['reweigh_knn']['precision'])\n",
    "    reweigh_knn_accuracy.append(reweigh_results['reweigh_knn']['accuracy'])\n",
    "    reweigh_knn_f1score.append(reweigh_results['reweigh_knn']['f1score'])\n",
    "    reweigh_knn_aod.append(reweigh_results['reweigh_knn']['aod'])\n",
    "    reweigh_knn_eod.append(reweigh_results['reweigh_knn']['eod'])\n",
    "    reweigh_knn_spd.append(reweigh_results['reweigh_knn']['spd'])\n",
    "    reweigh_knn_di.append(reweigh_results['reweigh_knn']['di'])\n",
    "     \n",
    "   \n",
    "    #***********************************************************************************************#\n",
    "    #storing results of smote Classifier - Logistic Regression, Support Vector Machine, Random Forest\n",
    "    \n",
    "    smote_lgr_recall.append(smote_results['smote_lgr']['recall'])\n",
    "    smote_lgr_far.append(smote_results['smote_lgr']['far'])\n",
    "    smote_lgr_precision.append(smote_results['smote_lgr']['precision'])\n",
    "    smote_lgr_accuracy.append(smote_results['smote_lgr']['accuracy'])\n",
    "    smote_lgr_f1score.append(smote_results['smote_lgr']['f1score'])\n",
    "    smote_lgr_aod.append(smote_results['smote_lgr']['aod'])\n",
    "    smote_lgr_eod.append(smote_results['smote_lgr']['eod'])\n",
    "    smote_lgr_spd.append(smote_results['smote_lgr']['spd'])\n",
    "    smote_lgr_di.append(smote_results['smote_lgr']['di'])\n",
    "    \n",
    "    smote_svm_recall.append(smote_results['smote_svm']['recall'])\n",
    "    smote_svm_far.append(smote_results['smote_svm']['far'])\n",
    "    smote_svm_precision.append(smote_results['smote_svm']['precision'])\n",
    "    smote_svm_accuracy.append(smote_results['smote_svm']['accuracy'])\n",
    "    smote_svm_f1score.append(smote_results['smote_svm']['f1score'])\n",
    "    smote_svm_aod.append(smote_results['smote_svm']['aod'])\n",
    "    smote_svm_eod.append(smote_results['smote_svm']['eod'])\n",
    "    smote_svm_spd.append(smote_results['smote_svm']['spd'])\n",
    "    smote_svm_di.append(smote_results['smote_svm']['di'])\n",
    "    \n",
    "    smote_rf_recall.append(smote_results['smote_rf']['recall'])\n",
    "    smote_rf_far.append(smote_results['smote_rf']['far'])\n",
    "    smote_rf_precision.append(smote_results['smote_rf']['precision'])\n",
    "    smote_rf_accuracy.append(smote_results['smote_rf']['accuracy'])\n",
    "    smote_rf_f1score.append(smote_results['smote_rf']['f1score'])\n",
    "    smote_rf_aod.append(smote_results['smote_rf']['aod'])\n",
    "    smote_rf_eod.append(smote_results['smote_rf']['eod'])\n",
    "    smote_rf_spd.append(smote_results['smote_rf']['spd'])\n",
    "    smote_rf_di.append(smote_results['smote_rf']['di'])\n",
    "    \n",
    "    smote_nb_recall.append(smote_results['smote_nb']['recall'])\n",
    "    smote_nb_far.append(smote_results['smote_nb']['far'])\n",
    "    smote_nb_precision.append(smote_results['smote_nb']['precision'])\n",
    "    smote_nb_accuracy.append(smote_results['smote_nb']['accuracy'])\n",
    "    smote_nb_f1score.append(smote_results['smote_nb']['f1score'])\n",
    "    smote_nb_aod.append(smote_results['smote_nb']['aod'])\n",
    "    smote_nb_eod.append(smote_results['smote_nb']['eod'])\n",
    "    smote_nb_spd.append(smote_results['smote_nb']['spd'])\n",
    "    smote_nb_di.append(smote_results['smote_nb']['di'])\n",
    "    \n",
    "    smote_mlp_recall.append(smote_results['smote_mlp']['recall'])\n",
    "    smote_mlp_far.append(smote_results['smote_mlp']['far'])\n",
    "    smote_mlp_precision.append(smote_results['smote_mlp']['precision'])\n",
    "    smote_mlp_accuracy.append(smote_results['smote_mlp']['accuracy'])\n",
    "    smote_mlp_f1score.append(smote_results['smote_mlp']['f1score'])\n",
    "    smote_mlp_aod.append(smote_results['smote_mlp']['aod'])\n",
    "    smote_mlp_eod.append(smote_results['smote_mlp']['eod'])\n",
    "    smote_mlp_spd.append(smote_results['smote_mlp']['spd'])\n",
    "    smote_mlp_di.append(smote_results['smote_mlp']['di'])\n",
    "    \n",
    "    smote_dt_recall.append(smote_results['smote_dt']['recall'])\n",
    "    smote_dt_far.append(smote_results['smote_dt']['far'])\n",
    "    smote_dt_precision.append(smote_results['smote_dt']['precision'])\n",
    "    smote_dt_accuracy.append(smote_results['smote_dt']['accuracy'])\n",
    "    smote_dt_f1score.append(smote_results['smote_dt']['f1score'])\n",
    "    smote_dt_aod.append(smote_results['smote_dt']['aod'])\n",
    "    smote_dt_eod.append(smote_results['smote_dt']['eod'])\n",
    "    smote_dt_spd.append(smote_results['smote_dt']['spd'])\n",
    "    smote_dt_di.append(smote_results['smote_dt']['di'])\n",
    "    \n",
    "    smote_knn_recall.append(smote_results['smote_knn']['recall'])\n",
    "    smote_knn_far.append(smote_results['smote_knn']['far'])\n",
    "    smote_knn_precision.append(smote_results['smote_knn']['precision'])\n",
    "    smote_knn_accuracy.append(smote_results['smote_knn']['accuracy'])\n",
    "    smote_knn_f1score.append(smote_results['smote_knn']['f1score'])\n",
    "    smote_knn_aod.append(smote_results['smote_knn']['aod'])\n",
    "    smote_knn_eod.append(smote_results['smote_knn']['eod'])\n",
    "    smote_knn_spd.append(smote_results['smote_knn']['spd'])\n",
    "    smote_knn_di.append(smote_results['smote_knn']['di'])\n",
    "    \n",
    "    \n",
    "    #***********************************************************************************************#\n",
    "    #storing results of rus Classifier - Logistic Regression, Support Vector Machine, Random Forest\n",
    "    rus_lgr_recall.append(rus_results['rus_lgr']['recall'])\n",
    "    rus_lgr_far.append(rus_results['rus_lgr']['far'])\n",
    "    rus_lgr_precision.append(rus_results['rus_lgr']['precision'])\n",
    "    rus_lgr_accuracy.append(rus_results['rus_lgr']['accuracy'])\n",
    "    rus_lgr_f1score.append(rus_results['rus_lgr']['f1score'])\n",
    "    rus_lgr_aod.append(rus_results['rus_lgr']['aod'])\n",
    "    rus_lgr_eod.append(rus_results['rus_lgr']['eod'])\n",
    "    rus_lgr_spd.append(rus_results['rus_lgr']['spd'])\n",
    "    rus_lgr_di.append(rus_results['rus_lgr']['di'])\n",
    "    \n",
    "    rus_svm_recall.append(rus_results['rus_svm']['recall'])\n",
    "    rus_svm_far.append(rus_results['rus_svm']['far'])\n",
    "    rus_svm_precision.append(rus_results['rus_svm']['precision'])\n",
    "    rus_svm_accuracy.append(rus_results['rus_svm']['accuracy'])\n",
    "    rus_svm_f1score.append(rus_results['rus_svm']['f1score'])\n",
    "    rus_svm_aod.append(rus_results['rus_svm']['aod'])\n",
    "    rus_svm_eod.append(rus_results['rus_svm']['eod'])\n",
    "    rus_svm_spd.append(rus_results['rus_svm']['spd'])\n",
    "    rus_svm_di.append(rus_results['rus_svm']['di'])\n",
    "    \n",
    "    rus_rf_recall.append(rus_results['rus_rf']['recall'])\n",
    "    rus_rf_far.append(rus_results['rus_rf']['far'])\n",
    "    rus_rf_precision.append(rus_results['rus_rf']['precision'])\n",
    "    rus_rf_accuracy.append(rus_results['rus_rf']['accuracy'])\n",
    "    rus_rf_f1score.append(rus_results['rus_rf']['f1score'])\n",
    "    rus_rf_aod.append(rus_results['rus_rf']['aod'])\n",
    "    rus_rf_eod.append(rus_results['rus_rf']['eod'])\n",
    "    rus_rf_spd.append(rus_results['rus_rf']['spd'])\n",
    "    rus_rf_di.append(rus_results['rus_rf']['di'])\n",
    "    \n",
    "    rus_nb_recall.append(rus_results['rus_nb']['recall'])\n",
    "    rus_nb_far.append(rus_results['rus_nb']['far'])\n",
    "    rus_nb_precision.append(rus_results['rus_nb']['precision'])\n",
    "    rus_nb_accuracy.append(rus_results['rus_nb']['accuracy'])\n",
    "    rus_nb_f1score.append(rus_results['rus_nb']['f1score'])\n",
    "    rus_nb_aod.append(rus_results['rus_nb']['aod'])\n",
    "    rus_nb_eod.append(rus_results['rus_nb']['eod'])\n",
    "    rus_nb_spd.append(rus_results['rus_nb']['spd'])\n",
    "    rus_nb_di.append(rus_results['rus_nb']['di'])\n",
    "    \n",
    "    rus_mlp_recall.append(rus_results['rus_mlp']['recall'])\n",
    "    rus_mlp_far.append(rus_results['rus_mlp']['far'])\n",
    "    rus_mlp_precision.append(rus_results['rus_mlp']['precision'])\n",
    "    rus_mlp_accuracy.append(rus_results['rus_mlp']['accuracy'])\n",
    "    rus_mlp_f1score.append(rus_results['rus_mlp']['f1score'])\n",
    "    rus_mlp_aod.append(rus_results['rus_mlp']['aod'])\n",
    "    rus_mlp_eod.append(rus_results['rus_mlp']['eod'])\n",
    "    rus_mlp_spd.append(rus_results['rus_mlp']['spd'])\n",
    "    rus_mlp_di.append(rus_results['rus_mlp']['di'])\n",
    "    \n",
    "    rus_dt_recall.append(rus_results['rus_dt']['recall'])\n",
    "    rus_dt_far.append(rus_results['rus_dt']['far'])\n",
    "    rus_dt_precision.append(rus_results['rus_dt']['precision'])\n",
    "    rus_dt_accuracy.append(rus_results['rus_dt']['accuracy'])\n",
    "    rus_dt_f1score.append(rus_results['rus_dt']['f1score'])\n",
    "    rus_dt_aod.append(rus_results['rus_dt']['aod'])\n",
    "    rus_dt_eod.append(rus_results['rus_dt']['eod'])\n",
    "    rus_dt_spd.append(rus_results['rus_dt']['spd'])\n",
    "    rus_dt_di.append(rus_results['rus_dt']['di'])\n",
    "    \n",
    "    rus_knn_recall.append(rus_results['rus_knn']['recall'])\n",
    "    rus_knn_far.append(rus_results['rus_knn']['far'])\n",
    "    rus_knn_precision.append(rus_results['rus_knn']['precision'])\n",
    "    rus_knn_accuracy.append(rus_results['rus_knn']['accuracy'])\n",
    "    rus_knn_f1score.append(rus_results['rus_knn']['f1score'])\n",
    "    rus_knn_aod.append(rus_results['rus_knn']['aod'])\n",
    "    rus_knn_eod.append(rus_results['rus_knn']['eod'])\n",
    "    rus_knn_spd.append(rus_results['rus_knn']['spd'])\n",
    "    rus_knn_di.append(rus_results['rus_knn']['di'])\n",
    "    \n",
    "    #***********************************************************************************************#\n",
    "    #storing results of ros Classifier - Logistic Regression, Support Vector Machine, Random Forest\n",
    "    #***********************************************************************************************#\n",
    "    \n",
    "    ros_lgr_recall.append(ros_results['ros_lgr']['recall'])\n",
    "    ros_lgr_far.append(ros_results['ros_lgr']['far'])\n",
    "    ros_lgr_precision.append(ros_results['ros_lgr']['precision'])\n",
    "    ros_lgr_accuracy.append(ros_results['ros_lgr']['accuracy'])\n",
    "    ros_lgr_f1score.append(ros_results['ros_lgr']['f1score'])\n",
    "    ros_lgr_aod.append(ros_results['ros_lgr']['aod'])\n",
    "    ros_lgr_eod.append(ros_results['ros_lgr']['eod'])\n",
    "    ros_lgr_spd.append(ros_results['ros_lgr']['spd'])\n",
    "    ros_lgr_di.append(ros_results['ros_lgr']['di'])\n",
    "    \n",
    "    ros_svm_recall.append(ros_results['ros_svm']['recall'])\n",
    "    ros_svm_far.append(ros_results['ros_svm']['far'])\n",
    "    ros_svm_precision.append(ros_results['ros_svm']['precision'])\n",
    "    ros_svm_accuracy.append(ros_results['ros_svm']['accuracy'])\n",
    "    ros_svm_f1score.append(ros_results['ros_svm']['f1score'])\n",
    "    ros_svm_aod.append(ros_results['ros_svm']['aod'])\n",
    "    ros_svm_eod.append(ros_results['ros_svm']['eod'])\n",
    "    ros_svm_spd.append(ros_results['ros_svm']['spd'])\n",
    "    ros_svm_di.append(ros_results['ros_svm']['di'])\n",
    "    \n",
    "    ros_rf_recall.append(ros_results['ros_rf']['recall'])\n",
    "    ros_rf_far.append(ros_results['ros_rf']['far'])\n",
    "    ros_rf_precision.append(ros_results['ros_rf']['precision'])\n",
    "    ros_rf_accuracy.append(ros_results['ros_rf']['accuracy'])\n",
    "    ros_rf_f1score.append(ros_results['ros_rf']['f1score'])\n",
    "    ros_rf_aod.append(ros_results['ros_rf']['aod'])\n",
    "    ros_rf_eod.append(ros_results['ros_rf']['eod'])\n",
    "    ros_rf_spd.append(ros_results['ros_rf']['spd'])\n",
    "    ros_rf_di.append(ros_results['ros_rf']['di'])\n",
    "    \n",
    "    ros_nb_recall.append(ros_results['ros_nb']['recall'])\n",
    "    ros_nb_far.append(ros_results['ros_nb']['far'])\n",
    "    ros_nb_precision.append(ros_results['ros_nb']['precision'])\n",
    "    ros_nb_accuracy.append(ros_results['ros_nb']['accuracy'])\n",
    "    ros_nb_f1score.append(ros_results['ros_nb']['f1score'])\n",
    "    ros_nb_aod.append(ros_results['ros_nb']['aod'])\n",
    "    ros_nb_eod.append(ros_results['ros_nb']['eod'])\n",
    "    ros_nb_spd.append(ros_results['ros_nb']['spd'])\n",
    "    ros_nb_di.append(ros_results['ros_nb']['di'])\n",
    "    \n",
    "    ros_mlp_recall.append(ros_results['ros_mlp']['recall'])\n",
    "    ros_mlp_far.append(ros_results['ros_mlp']['far'])\n",
    "    ros_mlp_precision.append(ros_results['ros_mlp']['precision'])\n",
    "    ros_mlp_accuracy.append(ros_results['ros_mlp']['accuracy'])\n",
    "    ros_mlp_f1score.append(ros_results['ros_mlp']['f1score'])\n",
    "    ros_mlp_aod.append(ros_results['ros_mlp']['aod'])\n",
    "    ros_mlp_eod.append(ros_results['ros_mlp']['eod'])\n",
    "    ros_mlp_spd.append(ros_results['ros_mlp']['spd'])\n",
    "    ros_mlp_di.append(ros_results['ros_mlp']['di'])\n",
    "    \n",
    "    ros_dt_recall.append(ros_results['ros_dt']['recall'])\n",
    "    ros_dt_far.append(ros_results['ros_dt']['far'])\n",
    "    ros_dt_precision.append(ros_results['ros_dt']['precision'])\n",
    "    ros_dt_accuracy.append(ros_results['ros_dt']['accuracy'])\n",
    "    ros_dt_f1score.append(ros_results['ros_dt']['f1score'])\n",
    "    ros_dt_aod.append(ros_results['ros_dt']['aod'])\n",
    "    ros_dt_eod.append(ros_results['ros_dt']['eod'])\n",
    "    ros_dt_spd.append(ros_results['ros_dt']['spd'])\n",
    "    ros_dt_di.append(ros_results['ros_dt']['di'])\n",
    "    \n",
    "    ros_knn_recall.append(ros_results['ros_knn']['recall'])\n",
    "    ros_knn_far.append(ros_results['ros_knn']['far'])\n",
    "    ros_knn_precision.append(ros_results['ros_knn']['precision'])\n",
    "    ros_knn_accuracy.append(ros_results['ros_knn']['accuracy'])\n",
    "    ros_knn_f1score.append(ros_results['ros_knn']['f1score'])\n",
    "    ros_knn_aod.append(ros_results['ros_knn']['aod'])\n",
    "    ros_knn_eod.append(ros_results['ros_knn']['eod'])\n",
    "    ros_knn_spd.append(ros_results['ros_knn']['spd'])\n",
    "    ros_knn_di.append(ros_results['ros_knn']['di'])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a5bbce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1855eb09",
   "metadata": {},
   "source": [
    "## Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d531dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4148c456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of 10 times :: Learner - Random Forest\n",
      "****************************************************************************************************\n",
      "Default_Recall  0.89 | FairSMOTE_Recall 0.89 | FairMask_Recall 0.88 | FairGenerate_Recall 0.89 | TDD_Recall 0.9 | Reweigh_Recall 0.89 |\n",
      "\n",
      "Default_FalseAlarm  0.05 | FairSMOTE_FalseAlarm 0.05 | FairMask_FalseAlarm 0.13 | FairGenerate_FalseAlarm 0.05 | TDD_FalseAlarm 0.05 | Reweigh_FalseAlarm 0.05 |\n",
      "\n",
      "Default_precision  0.94 | FairSMOTE_precision 0.94 | FairMask_precision 0.86 | FairGenerate_precision 0.94 | TDD_precision 0.94 | Reweigh_precision 0.94 |\n",
      "\n",
      "Default_accuracy  0.92 | FairSMOTE_accuracy 0.92 | FairMask_accuracy 0.88 | FairGenerate_accuracy 0.92 | TDD_accuracy 0.92 | Reweigh_accuracy 0.92 |\n",
      "\n",
      "Default_f1score  0.92 | FairSMOTE_f1score 0.92 | FairMask_f1score 0.87 | FairGenerate_f1score 0.92 | TDD_f1score 0.92 | Reweigh_f1score 0.92 |\n",
      "****************************************************************************************************\n",
      "Default_aod  0.02 | FairSMOTE_aod 0.02 | FairMask_aod 0.02 | FairGenerate_aod 0.03 | TDD_aod 0.02 | Reweigh_aod 0.03 |\n",
      "\n",
      "Default_eod  0.05 | FairSMOTE_eod 0.05 | FairMask_eod 0.05 | FairGenerate_eod 0.05 | TDD_eod 0.05 | Reweigh_eod 0.04 |\n",
      "\n",
      "Default_spd  0.06 | FairSMOTE_spd 0.06 | FairMask_spd 0.04 | FairGenerate_spd 0.09 | TDD_spd 0.07 | Reweigh_spd 0.07 |\n",
      "\n",
      "Default_di  0.12 | FairSMOTE_di 0.14 | FairMask_di 0.1 | FairGenerate_di 0.23 | TDD_di 0.17 | Reweigh_di 0.16 |\n"
     ]
    }
   ],
   "source": [
    "print(\"Median of 10 times :: Learner - Random Forest\")\n",
    "\n",
    "print(\"*\"*100)\n",
    "\n",
    "print(\"Default_Recall \",np.round(np.median(default_rf_recall),2),\"|\",\n",
    "      \"FairSMOTE_Recall\",np.round(np.median(fair_smote_rf_recall),2),\"|\",\n",
    "      \"FairMask_Recall\",np.round(np.median(fair_mask_rf_recall),2),\"|\",\n",
    "     \"FairGenerate_Recall\",np.round(np.median(fair_preprocessor_rf_recall),2),\"|\",\n",
    "     \"TDD_Recall\",np.round(np.median(tdd_rf_recall),2),\"|\",\n",
    "      \"Reweigh_Recall\",np.round(np.median(reweigh_rf_recall),2),\"|\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Default_FalseAlarm \",np.round(np.median(default_rf_far),2),\"|\",\n",
    "      \"FairSMOTE_FalseAlarm\",np.round(np.median(fair_smote_rf_far),2),\"|\",\n",
    "      \"FairMask_FalseAlarm\",np.round(np.median(fair_mask_rf_far),2),\"|\",\n",
    "     \"FairGenerate_FalseAlarm\",np.round(np.median(fair_preprocessor_rf_far),2),\"|\",\n",
    "     \"TDD_FalseAlarm\",np.round(np.median(tdd_rf_far),2),\"|\",\n",
    "     \"Reweigh_FalseAlarm\",np.round(np.median(reweigh_rf_far),2),\"|\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Default_precision \",np.round(np.median(default_rf_precision),2),\"|\",\n",
    "      \"FairSMOTE_precision\",np.round(np.median(fair_smote_rf_precision),2),\"|\",\n",
    "      \"FairMask_precision\",np.round(np.median(fair_mask_rf_precision),2),\"|\",\n",
    "     \"FairGenerate_precision\",np.round(np.median(fair_preprocessor_rf_precision),2),\"|\",\n",
    "     \"TDD_precision\",np.round(np.median(tdd_rf_precision),2),\"|\",\n",
    "      \"Reweigh_precision\",np.round(np.median(reweigh_rf_precision),2),\"|\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Default_accuracy \",np.round(np.median(default_rf_accuracy),2),\"|\",\n",
    "      \"FairSMOTE_accuracy\",np.round(np.median(fair_smote_rf_accuracy),2),\"|\",\n",
    "      \"FairMask_accuracy\",np.round(np.median(fair_mask_rf_accuracy),2),\"|\",\n",
    "     \"FairGenerate_accuracy\",np.round(np.median(fair_preprocessor_rf_accuracy),2),\"|\",\n",
    "     \"TDD_accuracy\",np.round(np.median(tdd_rf_accuracy),2),\"|\",\n",
    "    \"Reweigh_accuracy\",np.round(np.median(reweigh_rf_accuracy),2),\"|\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Default_f1score \",np.round(np.median(default_rf_f1score),2),\"|\",\n",
    "      \"FairSMOTE_f1score\",np.round(np.median(fair_smote_rf_f1score),2),\"|\",\n",
    "      \"FairMask_f1score\",np.round(np.median(fair_mask_rf_f1score),2),\"|\",\n",
    "     \"FairGenerate_f1score\",np.round(np.median(fair_preprocessor_rf_f1score),2),\"|\",\n",
    "     \"TDD_f1score\",np.round(np.median(tdd_rf_f1score),2),\"|\",\n",
    "     \"Reweigh_f1score\",np.round(np.median(reweigh_rf_f1score),2),\"|\")\n",
    "\n",
    "print(\"*\"*100)\n",
    "\n",
    "print(\"Default_aod \",np.round(np.median(default_rf_aod),2),\"|\",\n",
    "      \"FairSMOTE_aod\",np.round(np.median(fair_smote_rf_aod),2),\"|\",\n",
    "      \"FairMask_aod\",np.round(np.median(fair_mask_rf_aod),2),\"|\",\n",
    "     \"FairGenerate_aod\",np.round(np.median(fair_preprocessor_rf_aod),2),\"|\",\n",
    "     \"TDD_aod\",np.round(np.median(tdd_rf_aod),2),\"|\",\n",
    "     \"Reweigh_aod\",np.round(np.median(reweigh_rf_aod),2),\"|\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Default_eod \",np.round(np.median(default_rf_eod),2),\"|\",\n",
    "      \"FairSMOTE_eod\",np.round(np.median(fair_smote_rf_eod),2),\"|\",\n",
    "      \"FairMask_eod\",np.round(np.median(fair_mask_rf_eod),2),\"|\",\n",
    "     \"FairGenerate_eod\",np.round(np.median(fair_preprocessor_rf_eod),2),\"|\",\n",
    "     \"TDD_eod\",np.round(np.median(tdd_rf_eod),2),\"|\",\n",
    "     \"Reweigh_eod\",np.round(np.median(reweigh_rf_eod),2),\"|\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Default_spd \",np.round(np.median(default_rf_spd),2),\"|\",\n",
    "      \"FairSMOTE_spd\",np.round(np.median(fair_smote_rf_spd),2),\"|\",\n",
    "      \"FairMask_spd\",np.round(np.median(fair_mask_rf_spd),2),\"|\",\n",
    "     \"FairGenerate_spd\",np.round(np.median(fair_preprocessor_rf_spd),2),\"|\",\n",
    "     \"TDD_spd\",np.round(np.median(tdd_rf_spd),2),\"|\",\n",
    "      \"Reweigh_spd\",np.round(np.median(reweigh_rf_spd),2),\"|\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Default_di \",np.round(np.median(default_rf_di),2),\"|\",\n",
    "      \"FairSMOTE_di\",np.round(np.median(fair_smote_rf_di),2),\"|\",\n",
    "      \"FairMask_di\",np.round(np.median(fair_mask_rf_di),2),\"|\",\n",
    "     \"FairGenerate_di\",np.round(np.median(fair_preprocessor_rf_di),2),\"|\",\n",
    "     \"TDD_di\",np.round(np.median(tdd_rf_di),2),\"|\",\n",
    "     \"Reweigh_di\",np.round(np.median(reweigh_rf_di),2),\"|\")\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e3eae077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Balancing Technique\n",
      "Median of 10 times :: Learner - Random Forest\n",
      "****************************************************************************************************\n",
      "Default_Recall  0.89 | RUS_Recall 0.89 | ROS_Recall 0.9 | SMOTE_Recall 0.9 | FairGenerate_Recall 0.89\n",
      "\n",
      "Default_FalseAlarm  0.05 | RUS_FalseAlarm 0.05 | ROS_FalseAlarm 0.06 | SMOTE_FalseAlarm 0.05 | FairGenerate_FalseAlarm 0.05\n",
      "\n",
      "Default_precision  0.94 | RUS_precision 0.94 | ROS_precision 0.93 | SMOTE_precision 0.94 | FairGenerate_precision 0.94\n",
      "\n",
      "Default_accuracy  0.92 | RUS_accuracy 0.92 | ROS_accuracy 0.92 | SMOTE_accuracy 0.92 | FairGenerate_accuracy 0.92 |\n",
      "\n",
      "Default_f1score  0.92 | RUS_f1score 0.92 | ROS_f1score 0.92 | SMOTE_f1score 0.92 | FairGenerate_f1score 0.92 |\n",
      "****************************************************************************************************\n",
      "Default_aod  0.02 | RUS_aod 0.03 | ROS_aod 0.03 | SMOTE_aod 0.02 | FairGenerate_aod 0.03 |\n",
      "\n",
      "Default_eod  0.05 | RUS_eod 0.04 | ROS_eod 0.06 | SMOTE_eod 0.05 | FairGenerate_eod 0.05 |\n",
      "\n",
      "Default_spd  0.06 | RUS_spd 0.08 | ROS_spd 0.08 | SMOTE_spd 0.07 | FairGenerate_spd 0.09 |\n",
      "\n",
      "Default_di  0.12 | RUS_di 0.2 | ROS_di 0.19 | SMOTE_di 0.15 | FairGenerate_di 0.23 |\n"
     ]
    }
   ],
   "source": [
    "print(\"Class Balancing Technique\")\n",
    "print(\"Median of 10 times :: Learner - Random Forest\")\n",
    "\n",
    "print(\"*\"*100)\n",
    "\n",
    "print(\"Default_Recall \",np.round(np.median(default_rf_recall),2),\"|\",\n",
    "      \"RUS_Recall\",np.round(np.median(rus_rf_recall),2),\"|\",\n",
    "      \"ROS_Recall\",np.round(np.median(ros_rf_recall),2),\"|\",\n",
    "     \"SMOTE_Recall\",np.round(np.median(smote_rf_recall),2),\"|\",\n",
    "     \"FairGenerate_Recall\",np.round(np.median(fair_preprocessor_rf_recall),2))\n",
    "    \n",
    "print()\n",
    "\n",
    "print(\"Default_FalseAlarm \",np.round(np.median(default_rf_far),2),\"|\",\n",
    "      \"RUS_FalseAlarm\",np.round(np.median(rus_rf_far),2),\"|\",\n",
    "      \"ROS_FalseAlarm\",np.round(np.median(ros_rf_far),2),\"|\",\n",
    "     \"SMOTE_FalseAlarm\",np.round(np.median(smote_rf_far),2),\"|\",\n",
    "     \"FairGenerate_FalseAlarm\",np.round(np.median(fair_preprocessor_rf_far),2))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Default_precision \",np.round(np.median(default_rf_precision),2),\"|\",\n",
    "      \"RUS_precision\",np.round(np.median(rus_rf_precision),2),\"|\",\n",
    "      \"ROS_precision\",np.round(np.median(ros_rf_precision),2),\"|\",\n",
    "     \"SMOTE_precision\",np.round(np.median(smote_rf_precision),2),\"|\",\n",
    "     \"FairGenerate_precision\",np.round(np.median(fair_preprocessor_rf_precision),2))\n",
    "      \n",
    "      \n",
    "print()\n",
    "\n",
    "print(\"Default_accuracy \",np.round(np.median(default_rf_accuracy),2),\"|\",\n",
    "      \"RUS_accuracy\",np.round(np.median(rus_rf_accuracy),2),\"|\",\n",
    "      \"ROS_accuracy\",np.round(np.median(ros_rf_accuracy),2),\"|\",\n",
    "     \"SMOTE_accuracy\",np.round(np.median(smote_rf_accuracy),2),\"|\",\n",
    "     \"FairGenerate_accuracy\",np.round(np.median(fair_preprocessor_rf_accuracy),2),\"|\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Default_f1score \",np.round(np.median(default_rf_f1score),2),\"|\",\n",
    "      \"RUS_f1score\",np.round(np.median(rus_rf_f1score),2),\"|\",\n",
    "      \"ROS_f1score\",np.round(np.median(ros_rf_f1score),2),\"|\",\n",
    "     \"SMOTE_f1score\",np.round(np.median(smote_rf_f1score),2),\"|\",\n",
    "     \"FairGenerate_f1score\",np.round(np.median(fair_preprocessor_rf_f1score),2),\"|\")\n",
    "\n",
    "print(\"*\"*100)\n",
    "\n",
    "print(\"Default_aod \",np.round(np.median(default_rf_aod),2),\"|\",\n",
    "      \"RUS_aod\",np.round(np.median(rus_rf_aod),2),\"|\",\n",
    "      \"ROS_aod\",np.round(np.median(ros_rf_aod),2),\"|\",\n",
    "     \"SMOTE_aod\",np.round(np.median(smote_rf_aod),2),\"|\",\n",
    "     \"FairGenerate_aod\",np.round(np.median(fair_preprocessor_rf_aod),2),\"|\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Default_eod \",np.round(np.median(default_rf_eod),2),\"|\",\n",
    "      \"RUS_eod\",np.round(np.median(rus_rf_eod),2),\"|\",\n",
    "      \"ROS_eod\",np.round(np.median(ros_rf_eod),2),\"|\",\n",
    "     \"SMOTE_eod\",np.round(np.median(smote_rf_eod),2),\"|\",\n",
    "     \"FairGenerate_eod\",np.round(np.median(fair_preprocessor_rf_eod),2),\"|\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Default_spd \",np.round(np.median(default_rf_spd),2),\"|\",\n",
    "      \"RUS_spd\",np.round(np.median(rus_rf_spd),2),\"|\",\n",
    "      \"ROS_spd\",np.round(np.median(ros_rf_spd),2),\"|\",\n",
    "     \"SMOTE_spd\",np.round(np.median(smote_rf_spd),2),\"|\",\n",
    "     \"FairGenerate_spd\",np.round(np.median(fair_preprocessor_rf_spd),2),\"|\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Default_di \",np.round(np.median(default_rf_di),2),\"|\",\n",
    "      \"RUS_di\",np.round(np.median(rus_rf_di),2),\"|\",\n",
    "      \"ROS_di\",np.round(np.median(ros_rf_di),2),\"|\",\n",
    "     \"SMOTE_di\",np.round(np.median(smote_rf_di),2),\"|\",\n",
    "     \"FairGenerate_di\",np.round(np.median(fair_preprocessor_rf_di),2),\"|\")\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbb865d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd2caf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create folder to store StatisticalTest\n",
    "\n",
    "stats_folder=\"StatisticalTest/\"+folder_name+\"/\"+str(time_stamp)\n",
    "\n",
    "if not os.path.exists(stats_folder):\n",
    "    os.makedirs(stats_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851e1acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71af5a66",
   "metadata": {},
   "source": [
    "## Storing Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6f9404b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Logistic Regression : Recall------------------------\n",
      "-----------------------Logistic Regression : False Alarm------------------------\n",
      "-----------------------Logistic Regression : Precision------------------------\n",
      "-----------------------Logistic Regression : Accuracy------------------------\n",
      "-----------------------Logistic Regression : F1Score------------------------\n",
      "-----------------------Logistic Regression : AOD------------------------\n",
      "-----------------------Logistic Regression : EOD------------------------\n",
      "-----------------------Logistic Regression : SPD------------------------\n",
      "-----------------------Logistic Regression : DI------------------------\n",
      "-----------------------Support Vector Machine : Recall------------------------\n",
      "-----------------------Support Vector Machine : False Alarm------------------------\n",
      "-----------------------Support Vector Machine : Precision------------------------\n",
      "-----------------------Support Vector Machine : Accuracy------------------------\n",
      "-----------------------Support Vector Machine : F1Score------------------------\n",
      "-----------------------Support Vector Machine : AOD------------------------\n",
      "-----------------------Support Vector Machine : EOD------------------------\n",
      "-----------------------Support Vector Machine : SPD------------------------\n",
      "-----------------------Support Vector Machine : DI------------------------\n",
      "-----------------------Random Forest : Recall------------------------\n",
      "-----------------------Random Forest : False Alarm------------------------\n",
      "-----------------------Random Forest : Precision------------------------\n",
      "-----------------------Random Forest : Accuracy------------------------\n",
      "-----------------------Random Forest : F1Score------------------------\n",
      "-----------------------Random Forest : AOD------------------------\n",
      "-----------------------Random Forest : EOD------------------------\n",
      "-----------------------Random Forest : SPD------------------------\n",
      "-----------------------Random Forest : DI------------------------\n",
      "-----------------------Multi_Layer_Perceptron : Recall------------------------\n",
      "-----------------------Multi_Layer_Perceptron : False Alarm------------------------\n",
      "-----------------------Multi_Layer_Perceptron : Precision------------------------\n",
      "-----------------------Multi_Layer_Perceptron : Accuracy------------------------\n",
      "-----------------------Multi_Layer_Perceptron : F1Score------------------------\n",
      "-----------------------Multi_Layer_Perceptron : AOD------------------------\n",
      "-----------------------Multi_Layer_Perceptron : EOD------------------------\n",
      "-----------------------Multi_Layer_Perceptron : SPD------------------------\n",
      "-----------------------Multi_Layer_Perceptron : DI------------------------\n",
      "-----------------------Decision Trees : Recall------------------------\n",
      "-----------------------Decision Trees : False Alarm------------------------\n",
      "-----------------------Decision Trees : Precision------------------------\n",
      "-----------------------Decision Trees : Accuracy------------------------\n",
      "-----------------------Decision Trees : F1Score------------------------\n",
      "-----------------------Decision Trees : AOD------------------------\n",
      "-----------------------Decision Trees : EOD------------------------\n",
      "-----------------------Decision Trees : SPD------------------------\n",
      "-----------------------Decision Trees : DI------------------------\n",
      "-----------------------Naive Bayes : Recall------------------------\n",
      "-----------------------Naive Bayes : False Alarm------------------------\n",
      "-----------------------Naive Bayes : Precision------------------------\n",
      "-----------------------Naive Bayes : Accuracy------------------------\n",
      "-----------------------Naive Bayes : F1Score------------------------\n",
      "-----------------------Naive Bayes : AOD------------------------\n",
      "-----------------------Naive Bayes : EOD------------------------\n",
      "-----------------------Naive Bayes : SPD------------------------\n",
      "-----------------------Naive Bayes : DI------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------Logistic Regression : Recall------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_lgr_recall']=fair_preprocessor_lgr_recall\n",
    "value['fair_smote_lgr_recall']=fair_smote_lgr_recall\n",
    "value['default_lgr_recall']=default_lgr_recall\n",
    "value['fair_mask_lgr_recall']=fair_mask_lgr_recall\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/lgr_recall.txt',\"w\")\n",
    "path_lgr_recall='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/lgr_recall.txt'\n",
    "\n",
    "file.write('default_lgr_recall\\n')\n",
    "for i in default_lgr_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_lgr_recall\\n')\n",
    "for i in fair_smote_lgr_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_lgr_recall\\n')\n",
    "for i in fair_preprocessor_lgr_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_lgr_recall\\n')\n",
    "for i in fair_mask_lgr_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_lgr_recall\\n')\n",
    "for i in tdd_lgr_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_lgr_recall\\n')\n",
    "for i in reweigh_lgr_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Logistic Regression : False Alarm------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_lgr_far']=fair_preprocessor_lgr_far\n",
    "value['fair_smote_lgr_far']=fair_smote_lgr_far\n",
    "value['default_lgr_far']=default_lgr_far\n",
    "value['fair_mask_lgr_far']=fair_mask_lgr_far\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/lgr_far.txt',\"w\")\n",
    "path_lgr_far='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/lgr_far.txt'\n",
    "\n",
    "file.write('default_lgr_far\\n')\n",
    "for i in default_lgr_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_lgr_far\\n')\n",
    "for i in fair_smote_lgr_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_lgr_far\\n')\n",
    "for i in fair_preprocessor_lgr_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_lgr_far\\n')\n",
    "for i in fair_mask_lgr_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_lgr_far\\n')\n",
    "for i in reweigh_lgr_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.write('tdd_lgr_far\\n')\n",
    "for i in tdd_lgr_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Logistic Regression : Precision------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_lgr_precision']=fair_preprocessor_lgr_precision\n",
    "value['fair_smote_lgr_precision']=fair_smote_lgr_precision\n",
    "value['default_lgr_precision']=default_lgr_precision\n",
    "value['fair_mask_lgr_precision']=fair_mask_lgr_precision\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/lgr_precision.txt',\"w\")\n",
    "path_lgr_precision='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/lgr_precision.txt'\n",
    "\n",
    "file.write('default_lgr_precision\\n')\n",
    "for i in default_lgr_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_lgr_precision\\n')\n",
    "for i in fair_smote_lgr_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_lgr_precision\\n')\n",
    "for i in fair_preprocessor_lgr_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_lgr_precision\\n')\n",
    "for i in fair_mask_lgr_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_lgr_precision\\n')\n",
    "for i in tdd_lgr_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_lgr_precision\\n')\n",
    "for i in reweigh_lgr_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Logistic Regression : Accuracy------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_lgr_accuracy']=fair_preprocessor_lgr_accuracy\n",
    "value['fair_smote_lgr_accuracy']=fair_smote_lgr_accuracy\n",
    "value['default_lgr_accuracy']=default_lgr_accuracy\n",
    "value['fair_mask_lgr_accuracy']=fair_mask_lgr_accuracy\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/lgr_accuracy.txt',\"w\")\n",
    "path_lgr_accuracy='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/lgr_accuracy.txt'\n",
    "\n",
    "file.write('default_lgr_accuracy\\n')\n",
    "for i in default_lgr_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_lgr_accuracy\\n')\n",
    "for i in fair_smote_lgr_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_lgr_accuracy\\n')\n",
    "for i in fair_preprocessor_lgr_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_lgr_accuracy\\n')\n",
    "for i in fair_mask_lgr_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_lgr_accuracy\\n')\n",
    "for i in reweigh_lgr_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_lgr_accuracy\\n')\n",
    "for i in tdd_lgr_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Logistic Regression : F1Score------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_lgr_f1score']=fair_preprocessor_lgr_f1score\n",
    "value['fair_smote_lgr_f1score']=fair_smote_lgr_f1score\n",
    "value['default_lgr_f1score']=default_lgr_f1score\n",
    "value['fair_mask_lgr_f1score']=fair_mask_lgr_f1score\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/lgr_f1score.txt',\"w\")\n",
    "path_lgr_f1score='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/lgr_f1score.txt'\n",
    "\n",
    "\n",
    "file.write('default_lgr_f1score\\n')\n",
    "for i in default_lgr_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_lgr_f1score\\n')\n",
    "for i in fair_smote_lgr_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_lgr_f1score\\n')\n",
    "for i in fair_preprocessor_lgr_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_lgr_f1score\\n')\n",
    "for i in fair_mask_lgr_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_lgr_f1score\\n')\n",
    "for i in reweigh_lgr_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_lgr_f1score\\n')\n",
    "for i in tdd_lgr_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Logistic Regression : AOD------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "\n",
    "fair_preprocessor_lgr_aod=np.abs(fair_preprocessor_lgr_aod)\n",
    "fair_smote_lgr_aod=np.abs(fair_smote_lgr_aod)\n",
    "default_lgr_aod=np.abs(default_lgr_aod)\n",
    "fair_mask_lgr_aod=np.abs(fair_mask_lgr_aod)\n",
    "\n",
    "value['fair_preprocessor_lgr_aod']=fair_preprocessor_lgr_aod\n",
    "value['fair_smote_lgr_aod']=fair_smote_lgr_aod\n",
    "value['default_lgr_aod']=default_lgr_aod\n",
    "value['fair_mask_lgr_aod']=fair_mask_lgr_aod\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/lgr_aod.txt',\"w\")\n",
    "path_lgr_aod='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/lgr_aod.txt'\n",
    "\n",
    "\n",
    "file.write('default_lgr_aod\\n')\n",
    "for i in default_lgr_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_lgr_aod\\n')\n",
    "for i in fair_smote_lgr_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_lgr_aod\\n')\n",
    "for i in fair_preprocessor_lgr_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_lgr_aod\\n')\n",
    "for i in fair_mask_lgr_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_lgr_aod\\n')\n",
    "for i in reweigh_lgr_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_lgr_aod\\n')\n",
    "for i in tdd_lgr_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Logistic Regression : EOD------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "\n",
    "fair_preprocessor_lgr_eod=np.abs(fair_preprocessor_lgr_eod)\n",
    "fair_smote_lgr_eod=np.abs(fair_smote_lgr_eod)\n",
    "default_lgr_eod=np.abs(default_lgr_eod)\n",
    "fair_mask_lgr_eod=np.abs(fair_mask_lgr_eod)\n",
    "\n",
    "value['fair_preprocessor_lgr_eod']=fair_preprocessor_lgr_eod\n",
    "value['fair_smote_lgr_eod']=fair_smote_lgr_eod\n",
    "value['default_lgr_eod']=default_lgr_eod\n",
    "value['fair_mask_lgr_eod']=fair_mask_lgr_eod\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/lgr_eod.txt',\"w\")\n",
    "path_lgr_eod='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/lgr_eod.txt'\n",
    "\n",
    "\n",
    "file.write('default_lgr_eod\\n')\n",
    "for i in default_lgr_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_lgr_eod\\n')\n",
    "for i in fair_smote_lgr_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_lgr_eod\\n')\n",
    "for i in fair_preprocessor_lgr_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_lgr_eod\\n')\n",
    "for i in fair_mask_lgr_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_lgr_eod\\n')\n",
    "for i in reweigh_lgr_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_lgr_eod\\n')\n",
    "for i in tdd_lgr_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "\n",
    "print(\"-----------------------Logistic Regression : SPD------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_lgr_spd']=fair_preprocessor_lgr_spd\n",
    "value['fair_smote_lgr_spd']=fair_smote_lgr_spd\n",
    "value['default_lgr_spd']=default_lgr_spd\n",
    "value['fair_mask_lgr_spd']=fair_mask_lgr_spd\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/lgr_spd.txt',\"w\")\n",
    "path_lgr_spd='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/lgr_spd.txt'\n",
    "\n",
    "\n",
    "file.write('default_lgr_spd\\n')\n",
    "for i in default_lgr_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_lgr_spd\\n')\n",
    "for i in fair_smote_lgr_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_lgr_spd\\n')\n",
    "for i in fair_preprocessor_lgr_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_lgr_spd\\n')\n",
    "for i in fair_mask_lgr_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_lgr_spd\\n')\n",
    "for i in reweigh_lgr_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_lgr_spd\\n')\n",
    "for i in tdd_lgr_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Logistic Regression : DI------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "fair_preprocessor_lgr_di=np.abs(fair_preprocessor_lgr_di)\n",
    "fair_smote_lgr_di=np.abs(fair_smote_lgr_di)\n",
    "default_lgr_di=np.abs(default_lgr_di)\n",
    "fair_mask_lgr_di=np.abs(fair_mask_lgr_di)\n",
    "\n",
    "value['fair_preprocessor_lgr_di']=fair_preprocessor_lgr_di\n",
    "value['fair_smote_lgr_di']=fair_smote_lgr_di\n",
    "value['default_lgr_di']=default_lgr_di\n",
    "value['fair_mask_lgr_di']=fair_mask_lgr_di\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/lgr_di.txt',\"w\")\n",
    "path_lgr_di='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/lgr_di.txt'\n",
    "\n",
    "\n",
    "file.write('default_lgr_di\\n')\n",
    "for i in default_lgr_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_lgr_di\\n')\n",
    "for i in fair_smote_lgr_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_lgr_di\\n')\n",
    "for i in fair_preprocessor_lgr_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_lgr_di\\n')\n",
    "for i in fair_mask_lgr_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_lgr_di\\n')\n",
    "for i in reweigh_lgr_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_lgr_di\\n')\n",
    "for i in tdd_lgr_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "\n",
    "#-------------------------------------------------#\n",
    "\n",
    "print(\"-----------------------Support Vector Machine : Recall------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_svm_recall']=fair_preprocessor_svm_recall\n",
    "value['fair_smote_svm_recall']=fair_smote_svm_recall\n",
    "value['default_svm_recall']=default_svm_recall\n",
    "value['fair_mask_svm_recall']=fair_mask_svm_recall\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/svm_recall.txt',\"w\")\n",
    "path_svm_recall='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/svm_recall.txt'\n",
    "\n",
    "file.write('default_svm_recall\\n')\n",
    "for i in default_svm_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_svm_recall\\n')\n",
    "for i in fair_smote_svm_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_svm_recall\\n')\n",
    "for i in fair_preprocessor_svm_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_svm_recall\\n')\n",
    "for i in fair_mask_svm_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_svm_recall\\n')\n",
    "for i in tdd_svm_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_svm_recall\\n')\n",
    "for i in reweigh_svm_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Support Vector Machine : False Alarm------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_svm_far']=fair_preprocessor_svm_far\n",
    "value['fair_smote_svm_far']=fair_smote_svm_far\n",
    "value['default_svm_far']=default_svm_far\n",
    "value['fair_mask_svm_far']=fair_mask_svm_far\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/svm_far.txt',\"w\")\n",
    "path_svm_far='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/svm_far.txt'\n",
    "\n",
    "file.write('default_svm_far\\n')\n",
    "for i in default_svm_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_svm_far\\n')\n",
    "for i in fair_smote_svm_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_svm_far\\n')\n",
    "for i in fair_preprocessor_svm_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_svm_far\\n')\n",
    "for i in fair_mask_svm_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_svm_far\\n')\n",
    "for i in reweigh_svm_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.write('tdd_svm_far\\n')\n",
    "for i in tdd_svm_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Support Vector Machine : Precision------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_svm_precision']=fair_preprocessor_svm_precision\n",
    "value['fair_smote_svm_precision']=fair_smote_svm_precision\n",
    "value['default_svm_precision']=default_svm_precision\n",
    "value['fair_mask_svm_precision']=fair_mask_svm_precision\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/svm_precision.txt',\"w\")\n",
    "path_svm_precision='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/svm_precision.txt'\n",
    "\n",
    "file.write('default_svm_precision\\n')\n",
    "for i in default_svm_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_svm_precision\\n')\n",
    "for i in fair_smote_svm_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_svm_precision\\n')\n",
    "for i in fair_preprocessor_svm_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_svm_precision\\n')\n",
    "for i in fair_mask_svm_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_svm_precision\\n')\n",
    "for i in tdd_svm_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_svm_precision\\n')\n",
    "for i in reweigh_svm_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Support Vector Machine : Accuracy------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_svm_accuracy']=fair_preprocessor_svm_accuracy\n",
    "value['fair_smote_svm_accuracy']=fair_smote_svm_accuracy\n",
    "value['default_svm_accuracy']=default_svm_accuracy\n",
    "value['fair_mask_svm_accuracy']=fair_mask_svm_accuracy\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/svm_accuracy.txt',\"w\")\n",
    "path_svm_accuracy='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/svm_accuracy.txt'\n",
    "\n",
    "file.write('default_svm_accuracy\\n')\n",
    "for i in default_svm_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_svm_accuracy\\n')\n",
    "for i in fair_smote_svm_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_svm_accuracy\\n')\n",
    "for i in fair_preprocessor_svm_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_svm_accuracy\\n')\n",
    "for i in fair_mask_svm_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_svm_accuracy\\n')\n",
    "for i in reweigh_svm_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_svm_accuracy\\n')\n",
    "for i in tdd_svm_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Support Vector Machine : F1Score------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_svm_f1score']=fair_preprocessor_svm_f1score\n",
    "value['fair_smote_svm_f1score']=fair_smote_svm_f1score\n",
    "value['default_svm_f1score']=default_svm_f1score\n",
    "value['fair_mask_svm_f1score']=fair_mask_svm_f1score\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/svm_f1score.txt',\"w\")\n",
    "path_svm_f1score='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/svm_f1score.txt'\n",
    "\n",
    "\n",
    "file.write('default_svm_f1score\\n')\n",
    "for i in default_svm_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_svm_f1score\\n')\n",
    "for i in fair_smote_svm_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_svm_f1score\\n')\n",
    "for i in fair_preprocessor_svm_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_svm_f1score\\n')\n",
    "for i in fair_mask_svm_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_svm_f1score\\n')\n",
    "for i in reweigh_svm_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_svm_f1score\\n')\n",
    "for i in tdd_svm_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Support Vector Machine : AOD------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "\n",
    "fair_preprocessor_svm_aod=np.abs(fair_preprocessor_svm_aod)\n",
    "fair_smote_svm_aod=np.abs(fair_smote_svm_aod)\n",
    "default_svm_aod=np.abs(default_svm_aod)\n",
    "fair_mask_svm_aod=np.abs(fair_mask_svm_aod)\n",
    "\n",
    "value['fair_preprocessor_svm_aod']=fair_preprocessor_svm_aod\n",
    "value['fair_smote_svm_aod']=fair_smote_svm_aod\n",
    "value['default_svm_aod']=default_svm_aod\n",
    "value['fair_mask_svm_aod']=fair_mask_svm_aod\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/svm_aod.txt',\"w\")\n",
    "path_svm_aod='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/svm_aod.txt'\n",
    "\n",
    "\n",
    "file.write('default_svm_aod\\n')\n",
    "for i in default_svm_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_svm_aod\\n')\n",
    "for i in fair_smote_svm_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_svm_aod\\n')\n",
    "for i in fair_preprocessor_svm_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_svm_aod\\n')\n",
    "for i in fair_mask_svm_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_svm_aod\\n')\n",
    "for i in reweigh_svm_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_svm_aod\\n')\n",
    "for i in tdd_svm_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Support Vector Machine : EOD------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "\n",
    "fair_preprocessor_svm_eod=np.abs(fair_preprocessor_svm_eod)\n",
    "fair_smote_svm_eod=np.abs(fair_smote_svm_eod)\n",
    "default_svm_eod=np.abs(default_svm_eod)\n",
    "fair_mask_svm_eod=np.abs(fair_mask_svm_eod)\n",
    "\n",
    "value['fair_preprocessor_svm_eod']=fair_preprocessor_svm_eod\n",
    "value['fair_smote_svm_eod']=fair_smote_svm_eod\n",
    "value['default_svm_eod']=default_svm_eod\n",
    "value['fair_mask_svm_eod']=fair_mask_svm_eod\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/svm_eod.txt',\"w\")\n",
    "path_svm_eod='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/svm_eod.txt'\n",
    "\n",
    "\n",
    "file.write('default_svm_eod\\n')\n",
    "for i in default_svm_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_svm_eod\\n')\n",
    "for i in fair_smote_svm_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_svm_eod\\n')\n",
    "for i in fair_preprocessor_svm_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_svm_eod\\n')\n",
    "for i in fair_mask_svm_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_svm_eod\\n')\n",
    "for i in reweigh_svm_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_svm_eod\\n')\n",
    "for i in tdd_svm_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "\n",
    "print(\"-----------------------Support Vector Machine : SPD------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_svm_spd']=fair_preprocessor_svm_spd\n",
    "value['fair_smote_svm_spd']=fair_smote_svm_spd\n",
    "value['default_svm_spd']=default_svm_spd\n",
    "value['fair_mask_svm_spd']=fair_mask_svm_spd\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/svm_spd.txt',\"w\")\n",
    "path_svm_spd='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/svm_spd.txt'\n",
    "\n",
    "\n",
    "file.write('default_svm_spd\\n')\n",
    "for i in default_svm_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_svm_spd\\n')\n",
    "for i in fair_smote_svm_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_svm_spd\\n')\n",
    "for i in fair_preprocessor_svm_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_svm_spd\\n')\n",
    "for i in fair_mask_svm_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_svm_spd\\n')\n",
    "for i in reweigh_svm_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_svm_spd\\n')\n",
    "for i in tdd_svm_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Support Vector Machine : DI------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "fair_preprocessor_svm_di=np.abs(fair_preprocessor_svm_di)\n",
    "fair_smote_svm_di=np.abs(fair_smote_svm_di)\n",
    "default_svm_di=np.abs(default_svm_di)\n",
    "fair_mask_svm_di=np.abs(fair_mask_svm_di)\n",
    "\n",
    "value['fair_preprocessor_svm_di']=fair_preprocessor_svm_di\n",
    "value['fair_smote_svm_di']=fair_smote_svm_di\n",
    "value['default_svm_di']=default_svm_di\n",
    "value['fair_mask_svm_di']=fair_mask_svm_di\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/svm_di.txt',\"w\")\n",
    "path_svm_di='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/svm_di.txt'\n",
    "\n",
    "\n",
    "file.write('default_svm_di\\n')\n",
    "for i in default_svm_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_svm_di\\n')\n",
    "for i in fair_smote_svm_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_svm_di\\n')\n",
    "for i in fair_preprocessor_svm_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_svm_di\\n')\n",
    "for i in fair_mask_svm_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_svm_di\\n')\n",
    "for i in reweigh_svm_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_svm_di\\n')\n",
    "for i in tdd_svm_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "print(\"-----------------------Random Forest : Recall------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_rf_recall']=fair_preprocessor_rf_recall\n",
    "value['fair_smote_rf_recall']=fair_smote_rf_recall\n",
    "value['default_rf_recall']=default_rf_recall\n",
    "value['fair_mask_rf_recall']=fair_mask_rf_recall\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/rf_recall.txt',\"w\")\n",
    "path_rf_recall='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/rf_recall.txt'\n",
    "\n",
    "file.write('default_rf_recall\\n')\n",
    "for i in default_rf_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_rf_recall\\n')\n",
    "for i in fair_smote_rf_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_rf_recall\\n')\n",
    "for i in fair_preprocessor_rf_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_rf_recall\\n')\n",
    "for i in fair_mask_rf_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_rf_recall\\n')\n",
    "for i in tdd_rf_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_rf_recall\\n')\n",
    "for i in reweigh_rf_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Random Forest : False Alarm------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_rf_far']=fair_preprocessor_rf_far\n",
    "value['fair_smote_rf_far']=fair_smote_rf_far\n",
    "value['default_rf_far']=default_rf_far\n",
    "value['fair_mask_rf_far']=fair_mask_rf_far\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/rf_far.txt',\"w\")\n",
    "path_rf_far='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/rf_far.txt'\n",
    "\n",
    "file.write('default_rf_far\\n')\n",
    "for i in default_rf_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_rf_far\\n')\n",
    "for i in fair_smote_rf_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_rf_far\\n')\n",
    "for i in fair_preprocessor_rf_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_rf_far\\n')\n",
    "for i in fair_mask_rf_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_rf_far\\n')\n",
    "for i in reweigh_rf_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.write('tdd_rf_far\\n')\n",
    "for i in tdd_rf_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Random Forest : Precision------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_rf_precision']=fair_preprocessor_rf_precision\n",
    "value['fair_smote_rf_precision']=fair_smote_rf_precision\n",
    "value['default_rf_precision']=default_rf_precision\n",
    "value['fair_mask_rf_precision']=fair_mask_rf_precision\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/rf_precision.txt',\"w\")\n",
    "path_rf_precision='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/rf_precision.txt'\n",
    "\n",
    "file.write('default_rf_precision\\n')\n",
    "for i in default_rf_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_rf_precision\\n')\n",
    "for i in fair_smote_rf_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_rf_precision\\n')\n",
    "for i in fair_preprocessor_rf_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_rf_precision\\n')\n",
    "for i in fair_mask_rf_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_rf_precision\\n')\n",
    "for i in tdd_rf_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_rf_precision\\n')\n",
    "for i in reweigh_rf_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Random Forest : Accuracy------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_rf_accuracy']=fair_preprocessor_rf_accuracy\n",
    "value['fair_smote_rf_accuracy']=fair_smote_rf_accuracy\n",
    "value['default_rf_accuracy']=default_rf_accuracy\n",
    "value['fair_mask_rf_accuracy']=fair_mask_rf_accuracy\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/rf_accuracy.txt',\"w\")\n",
    "path_rf_accuracy='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/rf_accuracy.txt'\n",
    "\n",
    "file.write('default_rf_accuracy\\n')\n",
    "for i in default_rf_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_rf_accuracy\\n')\n",
    "for i in fair_smote_rf_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_rf_accuracy\\n')\n",
    "for i in fair_preprocessor_rf_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_rf_accuracy\\n')\n",
    "for i in fair_mask_rf_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_rf_accuracy\\n')\n",
    "for i in reweigh_rf_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_rf_accuracy\\n')\n",
    "for i in tdd_rf_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Random Forest : F1Score------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_rf_f1score']=fair_preprocessor_rf_f1score\n",
    "value['fair_smote_rf_f1score']=fair_smote_rf_f1score\n",
    "value['default_rf_f1score']=default_rf_f1score\n",
    "value['fair_mask_rf_f1score']=fair_mask_rf_f1score\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/rf_f1score.txt',\"w\")\n",
    "path_rf_f1score='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/rf_f1score.txt'\n",
    "\n",
    "\n",
    "file.write('default_rf_f1score\\n')\n",
    "for i in default_rf_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_rf_f1score\\n')\n",
    "for i in fair_smote_rf_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_rf_f1score\\n')\n",
    "for i in fair_preprocessor_rf_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_rf_f1score\\n')\n",
    "for i in fair_mask_rf_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_rf_f1score\\n')\n",
    "for i in reweigh_rf_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_rf_f1score\\n')\n",
    "for i in tdd_rf_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Random Forest : AOD------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "\n",
    "fair_preprocessor_rf_aod=np.abs(fair_preprocessor_rf_aod)\n",
    "fair_smote_rf_aod=np.abs(fair_smote_rf_aod)\n",
    "default_rf_aod=np.abs(default_rf_aod)\n",
    "fair_mask_rf_aod=np.abs(fair_mask_rf_aod)\n",
    "\n",
    "value['fair_preprocessor_rf_aod']=fair_preprocessor_rf_aod\n",
    "value['fair_smote_rf_aod']=fair_smote_rf_aod\n",
    "value['default_rf_aod']=default_rf_aod\n",
    "value['fair_mask_rf_aod']=fair_mask_rf_aod\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/rf_aod.txt',\"w\")\n",
    "path_rf_aod='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/rf_aod.txt'\n",
    "\n",
    "\n",
    "file.write('default_rf_aod\\n')\n",
    "for i in default_rf_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_rf_aod\\n')\n",
    "for i in fair_smote_rf_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_rf_aod\\n')\n",
    "for i in fair_preprocessor_rf_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_rf_aod\\n')\n",
    "for i in fair_mask_rf_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_rf_aod\\n')\n",
    "for i in reweigh_rf_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_rf_aod\\n')\n",
    "for i in tdd_rf_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Random Forest : EOD------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "\n",
    "fair_preprocessor_rf_eod=np.abs(fair_preprocessor_rf_eod)\n",
    "fair_smote_rf_eod=np.abs(fair_smote_rf_eod)\n",
    "default_rf_eod=np.abs(default_rf_eod)\n",
    "fair_mask_rf_eod=np.abs(fair_mask_rf_eod)\n",
    "\n",
    "value['fair_preprocessor_rf_eod']=fair_preprocessor_rf_eod\n",
    "value['fair_smote_rf_eod']=fair_smote_rf_eod\n",
    "value['default_rf_eod']=default_rf_eod\n",
    "value['fair_mask_rf_eod']=fair_mask_rf_eod\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/rf_eod.txt',\"w\")\n",
    "path_rf_eod='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/rf_eod.txt'\n",
    "\n",
    "\n",
    "file.write('default_rf_eod\\n')\n",
    "for i in default_rf_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_rf_eod\\n')\n",
    "for i in fair_smote_rf_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_rf_eod\\n')\n",
    "for i in fair_preprocessor_rf_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_rf_eod\\n')\n",
    "for i in fair_mask_rf_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_rf_eod\\n')\n",
    "for i in reweigh_rf_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_rf_eod\\n')\n",
    "for i in tdd_rf_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "\n",
    "print(\"-----------------------Random Forest : SPD------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_rf_spd']=fair_preprocessor_rf_spd\n",
    "value['fair_smote_rf_spd']=fair_smote_rf_spd\n",
    "value['default_rf_spd']=default_rf_spd\n",
    "value['fair_mask_rf_spd']=fair_mask_rf_spd\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/rf_spd.txt',\"w\")\n",
    "path_rf_spd='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/rf_spd.txt'\n",
    "\n",
    "\n",
    "file.write('default_rf_spd\\n')\n",
    "for i in default_rf_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_rf_spd\\n')\n",
    "for i in fair_smote_rf_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_rf_spd\\n')\n",
    "for i in fair_preprocessor_rf_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_rf_spd\\n')\n",
    "for i in fair_mask_rf_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_rf_spd\\n')\n",
    "for i in reweigh_rf_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_rf_spd\\n')\n",
    "for i in tdd_rf_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Random Forest : DI------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "fair_preprocessor_rf_di=np.abs(fair_preprocessor_rf_di)\n",
    "fair_smote_rf_di=np.abs(fair_smote_rf_di)\n",
    "default_rf_di=np.abs(default_rf_di)\n",
    "fair_mask_rf_di=np.abs(fair_mask_rf_di)\n",
    "\n",
    "value['fair_preprocessor_rf_di']=fair_preprocessor_rf_di\n",
    "value['fair_smote_rf_di']=fair_smote_rf_di\n",
    "value['default_rf_di']=default_rf_di\n",
    "value['fair_mask_rf_di']=fair_mask_rf_di\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/rf_di.txt',\"w\")\n",
    "path_rf_di='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/rf_di.txt'\n",
    "\n",
    "\n",
    "file.write('default_rf_di\\n')\n",
    "for i in default_rf_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_rf_di\\n')\n",
    "for i in fair_smote_rf_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_rf_di\\n')\n",
    "for i in fair_preprocessor_rf_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_rf_di\\n')\n",
    "for i in fair_mask_rf_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_rf_di\\n')\n",
    "for i in reweigh_rf_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_rf_di\\n')\n",
    "for i in tdd_rf_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "#--------------------------------------\n",
    "\n",
    "print(\"-----------------------Multi_Layer_Perceptron : Recall------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_mlp_recall']=fair_preprocessor_mlp_recall\n",
    "value['fair_smote_mlp_recall']=fair_smote_mlp_recall\n",
    "value['default_mlp_recall']=default_mlp_recall\n",
    "value['fair_mask_mlp_recall']=fair_mask_mlp_recall\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/mlp_recall.txt',\"w\")\n",
    "path_mlp_recall='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/mlp_recall.txt'\n",
    "\n",
    "file.write('default_mlp_recall\\n')\n",
    "for i in default_mlp_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_mlp_recall\\n')\n",
    "for i in fair_smote_mlp_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_mlp_recall\\n')\n",
    "for i in fair_preprocessor_mlp_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_mlp_recall\\n')\n",
    "for i in fair_mask_mlp_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_mlp_recall\\n')\n",
    "for i in tdd_mlp_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_mlp_recall\\n')\n",
    "for i in reweigh_mlp_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Multi_Layer_Perceptron : False Alarm------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_mlp_far']=fair_preprocessor_mlp_far\n",
    "value['fair_smote_mlp_far']=fair_smote_mlp_far\n",
    "value['default_mlp_far']=default_mlp_far\n",
    "value['fair_mask_mlp_far']=fair_mask_mlp_far\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/mlp_far.txt',\"w\")\n",
    "path_mlp_far='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/mlp_far.txt'\n",
    "\n",
    "file.write('default_mlp_far\\n')\n",
    "for i in default_mlp_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_mlp_far\\n')\n",
    "for i in fair_smote_mlp_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_mlp_far\\n')\n",
    "for i in fair_preprocessor_mlp_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_mlp_far\\n')\n",
    "for i in fair_mask_mlp_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_mlp_far\\n')\n",
    "for i in reweigh_mlp_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.write('tdd_mlp_far\\n')\n",
    "for i in tdd_mlp_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Multi_Layer_Perceptron : Precision------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_mlp_precision']=fair_preprocessor_mlp_precision\n",
    "value['fair_smote_mlp_precision']=fair_smote_mlp_precision\n",
    "value['default_mlp_precision']=default_mlp_precision\n",
    "value['fair_mask_mlp_precision']=fair_mask_mlp_precision\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/mlp_precision.txt',\"w\")\n",
    "path_mlp_precision='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/mlp_precision.txt'\n",
    "\n",
    "file.write('default_mlp_precision\\n')\n",
    "for i in default_mlp_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_mlp_precision\\n')\n",
    "for i in fair_smote_mlp_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_mlp_precision\\n')\n",
    "for i in fair_preprocessor_mlp_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_mlp_precision\\n')\n",
    "for i in fair_mask_mlp_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_mlp_precision\\n')\n",
    "for i in tdd_mlp_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_mlp_precision\\n')\n",
    "for i in reweigh_mlp_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Multi_Layer_Perceptron : Accuracy------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_mlp_accuracy']=fair_preprocessor_mlp_accuracy\n",
    "value['fair_smote_mlp_accuracy']=fair_smote_mlp_accuracy\n",
    "value['default_mlp_accuracy']=default_mlp_accuracy\n",
    "value['fair_mask_mlp_accuracy']=fair_mask_mlp_accuracy\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/mlp_accuracy.txt',\"w\")\n",
    "path_mlp_accuracy='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/mlp_accuracy.txt'\n",
    "\n",
    "file.write('default_mlp_accuracy\\n')\n",
    "for i in default_mlp_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_mlp_accuracy\\n')\n",
    "for i in fair_smote_mlp_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_mlp_accuracy\\n')\n",
    "for i in fair_preprocessor_mlp_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_mlp_accuracy\\n')\n",
    "for i in fair_mask_mlp_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_mlp_accuracy\\n')\n",
    "for i in reweigh_mlp_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_mlp_accuracy\\n')\n",
    "for i in tdd_mlp_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Multi_Layer_Perceptron : F1Score------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_mlp_f1score']=fair_preprocessor_mlp_f1score\n",
    "value['fair_smote_mlp_f1score']=fair_smote_mlp_f1score\n",
    "value['default_mlp_f1score']=default_mlp_f1score\n",
    "value['fair_mask_mlp_f1score']=fair_mask_mlp_f1score\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/mlp_f1score.txt',\"w\")\n",
    "path_mlp_f1score='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/mlp_f1score.txt'\n",
    "\n",
    "\n",
    "file.write('default_mlp_f1score\\n')\n",
    "for i in default_mlp_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_mlp_f1score\\n')\n",
    "for i in fair_smote_mlp_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_mlp_f1score\\n')\n",
    "for i in fair_preprocessor_mlp_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_mlp_f1score\\n')\n",
    "for i in fair_mask_mlp_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_mlp_f1score\\n')\n",
    "for i in reweigh_mlp_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_mlp_f1score\\n')\n",
    "for i in tdd_mlp_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Multi_Layer_Perceptron : AOD------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "\n",
    "fair_preprocessor_mlp_aod=np.abs(fair_preprocessor_mlp_aod)\n",
    "fair_smote_mlp_aod=np.abs(fair_smote_mlp_aod)\n",
    "default_mlp_aod=np.abs(default_mlp_aod)\n",
    "fair_mask_mlp_aod=np.abs(fair_mask_mlp_aod)\n",
    "\n",
    "value['fair_preprocessor_mlp_aod']=fair_preprocessor_mlp_aod\n",
    "value['fair_smote_mlp_aod']=fair_smote_mlp_aod\n",
    "value['default_mlp_aod']=default_mlp_aod\n",
    "value['fair_mask_mlp_aod']=fair_mask_mlp_aod\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/mlp_aod.txt',\"w\")\n",
    "path_mlp_aod='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/mlp_aod.txt'\n",
    "\n",
    "\n",
    "file.write('default_mlp_aod\\n')\n",
    "for i in default_mlp_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_mlp_aod\\n')\n",
    "for i in fair_smote_mlp_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_mlp_aod\\n')\n",
    "for i in fair_preprocessor_mlp_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_mlp_aod\\n')\n",
    "for i in fair_mask_mlp_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_mlp_aod\\n')\n",
    "for i in reweigh_mlp_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_mlp_aod\\n')\n",
    "for i in tdd_mlp_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Multi_Layer_Perceptron : EOD------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "\n",
    "fair_preprocessor_mlp_eod=np.abs(fair_preprocessor_mlp_eod)\n",
    "fair_smote_mlp_eod=np.abs(fair_smote_mlp_eod)\n",
    "default_mlp_eod=np.abs(default_mlp_eod)\n",
    "fair_mask_mlp_eod=np.abs(fair_mask_mlp_eod)\n",
    "\n",
    "value['fair_preprocessor_mlp_eod']=fair_preprocessor_mlp_eod\n",
    "value['fair_smote_mlp_eod']=fair_smote_mlp_eod\n",
    "value['default_mlp_eod']=default_mlp_eod\n",
    "value['fair_mask_mlp_eod']=fair_mask_mlp_eod\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/mlp_eod.txt',\"w\")\n",
    "path_mlp_eod='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/mlp_eod.txt'\n",
    "\n",
    "\n",
    "file.write('default_mlp_eod\\n')\n",
    "for i in default_mlp_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_mlp_eod\\n')\n",
    "for i in fair_smote_mlp_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_mlp_eod\\n')\n",
    "for i in fair_preprocessor_mlp_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_mlp_eod\\n')\n",
    "for i in fair_mask_mlp_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_mlp_eod\\n')\n",
    "for i in reweigh_mlp_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_mlp_eod\\n')\n",
    "for i in tdd_mlp_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "\n",
    "print(\"-----------------------Multi_Layer_Perceptron : SPD------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_mlp_spd']=fair_preprocessor_mlp_spd\n",
    "value['fair_smote_mlp_spd']=fair_smote_mlp_spd\n",
    "value['default_mlp_spd']=default_mlp_spd\n",
    "value['fair_mask_mlp_spd']=fair_mask_mlp_spd\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/mlp_spd.txt',\"w\")\n",
    "path_mlp_spd='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/mlp_spd.txt'\n",
    "\n",
    "\n",
    "file.write('default_mlp_spd\\n')\n",
    "for i in default_mlp_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_mlp_spd\\n')\n",
    "for i in fair_smote_mlp_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_mlp_spd\\n')\n",
    "for i in fair_preprocessor_mlp_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_mlp_spd\\n')\n",
    "for i in fair_mask_mlp_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_mlp_spd\\n')\n",
    "for i in reweigh_mlp_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_mlp_spd\\n')\n",
    "for i in tdd_mlp_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Multi_Layer_Perceptron : DI------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "fair_preprocessor_mlp_di=np.abs(fair_preprocessor_mlp_di)\n",
    "fair_smote_mlp_di=np.abs(fair_smote_mlp_di)\n",
    "default_mlp_di=np.abs(default_mlp_di)\n",
    "fair_mask_mlp_di=np.abs(fair_mask_mlp_di)\n",
    "\n",
    "value['fair_preprocessor_mlp_di']=fair_preprocessor_mlp_di\n",
    "value['fair_smote_mlp_di']=fair_smote_mlp_di\n",
    "value['default_mlp_di']=default_mlp_di\n",
    "value['fair_mask_mlp_di']=fair_mask_mlp_di\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/mlp_di.txt',\"w\")\n",
    "path_mlp_di='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/mlp_di.txt'\n",
    "\n",
    "\n",
    "file.write('default_mlp_di\\n')\n",
    "for i in default_mlp_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_mlp_di\\n')\n",
    "for i in fair_smote_mlp_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_mlp_di\\n')\n",
    "for i in fair_preprocessor_mlp_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_mlp_di\\n')\n",
    "for i in fair_mask_mlp_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_mlp_di\\n')\n",
    "for i in reweigh_mlp_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_mlp_di\\n')\n",
    "for i in tdd_mlp_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "#-----------------------\n",
    "\n",
    "print(\"-----------------------Decision Trees : Recall------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_dt_recall']=fair_preprocessor_dt_recall\n",
    "value['fair_smote_dt_recall']=fair_smote_dt_recall\n",
    "value['default_dt_recall']=default_dt_recall\n",
    "value['fair_mask_dt_recall']=fair_mask_dt_recall\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/dt_recall.txt',\"w\")\n",
    "path_dt_recall='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/dt_recall.txt'\n",
    "\n",
    "file.write('default_dt_recall\\n')\n",
    "for i in default_dt_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_dt_recall\\n')\n",
    "for i in fair_smote_dt_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_dt_recall\\n')\n",
    "for i in fair_preprocessor_dt_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_dt_recall\\n')\n",
    "for i in fair_mask_dt_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_dt_recall\\n')\n",
    "for i in tdd_dt_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_dt_recall\\n')\n",
    "for i in reweigh_dt_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Decision Trees : False Alarm------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_dt_far']=fair_preprocessor_dt_far\n",
    "value['fair_smote_dt_far']=fair_smote_dt_far\n",
    "value['default_dt_far']=default_dt_far\n",
    "value['fair_mask_dt_far']=fair_mask_dt_far\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/dt_far.txt',\"w\")\n",
    "path_dt_far='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/dt_far.txt'\n",
    "\n",
    "file.write('default_dt_far\\n')\n",
    "for i in default_dt_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_dt_far\\n')\n",
    "for i in fair_smote_dt_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_dt_far\\n')\n",
    "for i in fair_preprocessor_dt_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_dt_far\\n')\n",
    "for i in fair_mask_dt_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_dt_far\\n')\n",
    "for i in reweigh_dt_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.write('tdd_dt_far\\n')\n",
    "for i in tdd_dt_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Decision Trees : Precision------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_dt_precision']=fair_preprocessor_dt_precision\n",
    "value['fair_smote_dt_precision']=fair_smote_dt_precision\n",
    "value['default_dt_precision']=default_dt_precision\n",
    "value['fair_mask_dt_precision']=fair_mask_dt_precision\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/dt_precision.txt',\"w\")\n",
    "path_dt_precision='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/dt_precision.txt'\n",
    "\n",
    "file.write('default_dt_precision\\n')\n",
    "for i in default_dt_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_dt_precision\\n')\n",
    "for i in fair_smote_dt_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_dt_precision\\n')\n",
    "for i in fair_preprocessor_dt_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_dt_precision\\n')\n",
    "for i in fair_mask_dt_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_dt_precision\\n')\n",
    "for i in tdd_dt_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_dt_precision\\n')\n",
    "for i in reweigh_dt_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Decision Trees : Accuracy------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_dt_accuracy']=fair_preprocessor_dt_accuracy\n",
    "value['fair_smote_dt_accuracy']=fair_smote_dt_accuracy\n",
    "value['default_dt_accuracy']=default_dt_accuracy\n",
    "value['fair_mask_dt_accuracy']=fair_mask_dt_accuracy\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/dt_accuracy.txt',\"w\")\n",
    "path_dt_accuracy='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/dt_accuracy.txt'\n",
    "\n",
    "file.write('default_dt_accuracy\\n')\n",
    "for i in default_dt_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_dt_accuracy\\n')\n",
    "for i in fair_smote_dt_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_dt_accuracy\\n')\n",
    "for i in fair_preprocessor_dt_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_dt_accuracy\\n')\n",
    "for i in fair_mask_dt_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_dt_accuracy\\n')\n",
    "for i in reweigh_dt_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_dt_accuracy\\n')\n",
    "for i in tdd_dt_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Decision Trees : F1Score------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_dt_f1score']=fair_preprocessor_dt_f1score\n",
    "value['fair_smote_dt_f1score']=fair_smote_dt_f1score\n",
    "value['default_dt_f1score']=default_dt_f1score\n",
    "value['fair_mask_dt_f1score']=fair_mask_dt_f1score\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/dt_f1score.txt',\"w\")\n",
    "path_dt_f1score='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/dt_f1score.txt'\n",
    "\n",
    "\n",
    "file.write('default_dt_f1score\\n')\n",
    "for i in default_dt_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_dt_f1score\\n')\n",
    "for i in fair_smote_dt_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_dt_f1score\\n')\n",
    "for i in fair_preprocessor_dt_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_dt_f1score\\n')\n",
    "for i in fair_mask_dt_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_dt_f1score\\n')\n",
    "for i in reweigh_dt_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_dt_f1score\\n')\n",
    "for i in tdd_dt_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Decision Trees : AOD------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "\n",
    "fair_preprocessor_dt_aod=np.abs(fair_preprocessor_dt_aod)\n",
    "fair_smote_dt_aod=np.abs(fair_smote_dt_aod)\n",
    "default_dt_aod=np.abs(default_dt_aod)\n",
    "fair_mask_dt_aod=np.abs(fair_mask_dt_aod)\n",
    "\n",
    "value['fair_preprocessor_dt_aod']=fair_preprocessor_dt_aod\n",
    "value['fair_smote_dt_aod']=fair_smote_dt_aod\n",
    "value['default_dt_aod']=default_dt_aod\n",
    "value['fair_mask_dt_aod']=fair_mask_dt_aod\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/dt_aod.txt',\"w\")\n",
    "path_dt_aod='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/dt_aod.txt'\n",
    "\n",
    "\n",
    "file.write('default_dt_aod\\n')\n",
    "for i in default_dt_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_dt_aod\\n')\n",
    "for i in fair_smote_dt_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_dt_aod\\n')\n",
    "for i in fair_preprocessor_dt_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_dt_aod\\n')\n",
    "for i in fair_mask_dt_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_dt_aod\\n')\n",
    "for i in reweigh_dt_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_dt_aod\\n')\n",
    "for i in tdd_dt_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Decision Trees : EOD------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "\n",
    "fair_preprocessor_dt_eod=np.abs(fair_preprocessor_dt_eod)\n",
    "fair_smote_dt_eod=np.abs(fair_smote_dt_eod)\n",
    "default_dt_eod=np.abs(default_dt_eod)\n",
    "fair_mask_dt_eod=np.abs(fair_mask_dt_eod)\n",
    "\n",
    "value['fair_preprocessor_dt_eod']=fair_preprocessor_dt_eod\n",
    "value['fair_smote_dt_eod']=fair_smote_dt_eod\n",
    "value['default_dt_eod']=default_dt_eod\n",
    "value['fair_mask_dt_eod']=fair_mask_dt_eod\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/dt_eod.txt',\"w\")\n",
    "path_dt_eod='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/dt_eod.txt'\n",
    "\n",
    "\n",
    "file.write('default_dt_eod\\n')\n",
    "for i in default_dt_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_dt_eod\\n')\n",
    "for i in fair_smote_dt_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_dt_eod\\n')\n",
    "for i in fair_preprocessor_dt_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_dt_eod\\n')\n",
    "for i in fair_mask_dt_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_dt_eod\\n')\n",
    "for i in reweigh_dt_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_dt_eod\\n')\n",
    "for i in tdd_dt_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "\n",
    "print(\"-----------------------Decision Trees : SPD------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_dt_spd']=fair_preprocessor_dt_spd\n",
    "value['fair_smote_dt_spd']=fair_smote_dt_spd\n",
    "value['default_dt_spd']=default_dt_spd\n",
    "value['fair_mask_dt_spd']=fair_mask_dt_spd\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/dt_spd.txt',\"w\")\n",
    "path_dt_spd='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/dt_spd.txt'\n",
    "\n",
    "\n",
    "file.write('default_dt_spd\\n')\n",
    "for i in default_dt_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_dt_spd\\n')\n",
    "for i in fair_smote_dt_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_dt_spd\\n')\n",
    "for i in fair_preprocessor_dt_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_dt_spd\\n')\n",
    "for i in fair_mask_dt_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_dt_spd\\n')\n",
    "for i in reweigh_dt_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_dt_spd\\n')\n",
    "for i in tdd_dt_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Decision Trees : DI------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "fair_preprocessor_dt_di=np.abs(fair_preprocessor_dt_di)\n",
    "fair_smote_dt_di=np.abs(fair_smote_dt_di)\n",
    "default_dt_di=np.abs(default_dt_di)\n",
    "fair_mask_dt_di=np.abs(fair_mask_dt_di)\n",
    "\n",
    "value['fair_preprocessor_dt_di']=fair_preprocessor_dt_di\n",
    "value['fair_smote_dt_di']=fair_smote_dt_di\n",
    "value['default_dt_di']=default_dt_di\n",
    "value['fair_mask_dt_di']=fair_mask_dt_di\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/dt_di.txt',\"w\")\n",
    "path_dt_di='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/dt_di.txt'\n",
    "\n",
    "\n",
    "file.write('default_dt_di\\n')\n",
    "for i in default_dt_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_dt_di\\n')\n",
    "for i in fair_smote_dt_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_dt_di\\n')\n",
    "for i in fair_preprocessor_dt_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_dt_di\\n')\n",
    "for i in fair_mask_dt_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_dt_di\\n')\n",
    "for i in reweigh_dt_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_dt_di\\n')\n",
    "for i in tdd_dt_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "#----------------------------\n",
    "\n",
    "print(\"-----------------------Naive Bayes : Recall------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_nb_recall']=fair_preprocessor_nb_recall\n",
    "value['fair_smote_nb_recall']=fair_smote_nb_recall\n",
    "value['default_nb_recall']=default_nb_recall\n",
    "value['fair_mask_nb_recall']=fair_mask_nb_recall\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/nb_recall.txt',\"w\")\n",
    "path_nb_recall='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/nb_recall.txt'\n",
    "\n",
    "file.write('default_nb_recall\\n')\n",
    "for i in default_nb_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_nb_recall\\n')\n",
    "for i in fair_smote_nb_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_nb_recall\\n')\n",
    "for i in fair_preprocessor_nb_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_nb_recall\\n')\n",
    "for i in fair_mask_nb_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_nb_recall\\n')\n",
    "for i in tdd_nb_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_nb_recall\\n')\n",
    "for i in reweigh_nb_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Naive Bayes : False Alarm------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_nb_far']=fair_preprocessor_nb_far\n",
    "value['fair_smote_nb_far']=fair_smote_nb_far\n",
    "value['default_nb_far']=default_nb_far\n",
    "value['fair_mask_nb_far']=fair_mask_nb_far\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/nb_far.txt',\"w\")\n",
    "path_nb_far='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/nb_far.txt'\n",
    "\n",
    "file.write('default_nb_far\\n')\n",
    "for i in default_nb_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_nb_far\\n')\n",
    "for i in fair_smote_nb_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_nb_far\\n')\n",
    "for i in fair_preprocessor_nb_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_nb_far\\n')\n",
    "for i in fair_mask_nb_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_nb_far\\n')\n",
    "for i in reweigh_nb_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.write('tdd_nb_far\\n')\n",
    "for i in tdd_nb_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Naive Bayes : Precision------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_nb_precision']=fair_preprocessor_nb_precision\n",
    "value['fair_smote_nb_precision']=fair_smote_nb_precision\n",
    "value['default_nb_precision']=default_nb_precision\n",
    "value['fair_mask_nb_precision']=fair_mask_nb_precision\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/nb_precision.txt',\"w\")\n",
    "path_nb_precision='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/nb_precision.txt'\n",
    "\n",
    "file.write('default_nb_precision\\n')\n",
    "for i in default_nb_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_nb_precision\\n')\n",
    "for i in fair_smote_nb_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_nb_precision\\n')\n",
    "for i in fair_preprocessor_nb_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_nb_precision\\n')\n",
    "for i in fair_mask_nb_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_nb_precision\\n')\n",
    "for i in tdd_nb_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_nb_precision\\n')\n",
    "for i in reweigh_nb_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Naive Bayes : Accuracy------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_nb_accuracy']=fair_preprocessor_nb_accuracy\n",
    "value['fair_smote_nb_accuracy']=fair_smote_nb_accuracy\n",
    "value['default_nb_accuracy']=default_nb_accuracy\n",
    "value['fair_mask_nb_accuracy']=fair_mask_nb_accuracy\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/nb_accuracy.txt',\"w\")\n",
    "path_nb_accuracy='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/nb_accuracy.txt'\n",
    "\n",
    "file.write('default_nb_accuracy\\n')\n",
    "for i in default_nb_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_nb_accuracy\\n')\n",
    "for i in fair_smote_nb_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_nb_accuracy\\n')\n",
    "for i in fair_preprocessor_nb_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_nb_accuracy\\n')\n",
    "for i in fair_mask_nb_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_nb_accuracy\\n')\n",
    "for i in reweigh_nb_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_nb_accuracy\\n')\n",
    "for i in tdd_nb_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Naive Bayes : F1Score------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_nb_f1score']=fair_preprocessor_nb_f1score\n",
    "value['fair_smote_nb_f1score']=fair_smote_nb_f1score\n",
    "value['default_nb_f1score']=default_nb_f1score\n",
    "value['fair_mask_nb_f1score']=fair_mask_nb_f1score\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/nb_f1score.txt',\"w\")\n",
    "path_nb_f1score='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/nb_f1score.txt'\n",
    "\n",
    "\n",
    "file.write('default_nb_f1score\\n')\n",
    "for i in default_nb_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_nb_f1score\\n')\n",
    "for i in fair_smote_nb_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_nb_f1score\\n')\n",
    "for i in fair_preprocessor_nb_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_nb_f1score\\n')\n",
    "for i in fair_mask_nb_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_nb_f1score\\n')\n",
    "for i in reweigh_nb_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_nb_f1score\\n')\n",
    "for i in tdd_nb_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Naive Bayes : AOD------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "\n",
    "fair_preprocessor_nb_aod=np.abs(fair_preprocessor_nb_aod)\n",
    "fair_smote_nb_aod=np.abs(fair_smote_nb_aod)\n",
    "default_nb_aod=np.abs(default_nb_aod)\n",
    "fair_mask_nb_aod=np.abs(fair_mask_nb_aod)\n",
    "\n",
    "value['fair_preprocessor_nb_aod']=fair_preprocessor_nb_aod\n",
    "value['fair_smote_nb_aod']=fair_smote_nb_aod\n",
    "value['default_nb_aod']=default_nb_aod\n",
    "value['fair_mask_nb_aod']=fair_mask_nb_aod\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/nb_aod.txt',\"w\")\n",
    "path_nb_aod='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/nb_aod.txt'\n",
    "\n",
    "\n",
    "file.write('default_nb_aod\\n')\n",
    "for i in default_nb_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_nb_aod\\n')\n",
    "for i in fair_smote_nb_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_nb_aod\\n')\n",
    "for i in fair_preprocessor_nb_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_nb_aod\\n')\n",
    "for i in fair_mask_nb_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_nb_aod\\n')\n",
    "for i in reweigh_nb_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_nb_aod\\n')\n",
    "for i in tdd_nb_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Naive Bayes : EOD------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "\n",
    "fair_preprocessor_nb_eod=np.abs(fair_preprocessor_nb_eod)\n",
    "fair_smote_nb_eod=np.abs(fair_smote_nb_eod)\n",
    "default_nb_eod=np.abs(default_nb_eod)\n",
    "fair_mask_nb_eod=np.abs(fair_mask_nb_eod)\n",
    "\n",
    "value['fair_preprocessor_nb_eod']=fair_preprocessor_nb_eod\n",
    "value['fair_smote_nb_eod']=fair_smote_nb_eod\n",
    "value['default_nb_eod']=default_nb_eod\n",
    "value['fair_mask_nb_eod']=fair_mask_nb_eod\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/nb_eod.txt',\"w\")\n",
    "path_nb_eod='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/nb_eod.txt'\n",
    "\n",
    "\n",
    "file.write('default_nb_eod\\n')\n",
    "for i in default_nb_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_nb_eod\\n')\n",
    "for i in fair_smote_nb_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_nb_eod\\n')\n",
    "for i in fair_preprocessor_nb_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_nb_eod\\n')\n",
    "for i in fair_mask_nb_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_nb_eod\\n')\n",
    "for i in reweigh_nb_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_nb_eod\\n')\n",
    "for i in tdd_nb_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "\n",
    "print(\"-----------------------Naive Bayes : SPD------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_nb_spd']=fair_preprocessor_nb_spd\n",
    "value['fair_smote_nb_spd']=fair_smote_nb_spd\n",
    "value['default_nb_spd']=default_nb_spd\n",
    "value['fair_mask_nb_spd']=fair_mask_nb_spd\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/nb_spd.txt',\"w\")\n",
    "path_nb_spd='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/nb_spd.txt'\n",
    "\n",
    "\n",
    "file.write('default_nb_spd\\n')\n",
    "for i in default_nb_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_nb_spd\\n')\n",
    "for i in fair_smote_nb_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_nb_spd\\n')\n",
    "for i in fair_preprocessor_nb_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_nb_spd\\n')\n",
    "for i in fair_mask_nb_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_nb_spd\\n')\n",
    "for i in reweigh_nb_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_nb_spd\\n')\n",
    "for i in tdd_nb_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Naive Bayes : DI------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "fair_preprocessor_nb_di=np.abs(fair_preprocessor_nb_di)\n",
    "fair_smote_nb_di=np.abs(fair_smote_nb_di)\n",
    "default_nb_di=np.abs(default_nb_di)\n",
    "fair_mask_nb_di=np.abs(fair_mask_nb_di)\n",
    "\n",
    "value['fair_preprocessor_nb_di']=fair_preprocessor_nb_di\n",
    "value['fair_smote_nb_di']=fair_smote_nb_di\n",
    "value['default_nb_di']=default_nb_di\n",
    "value['fair_mask_nb_di']=fair_mask_nb_di\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/nb_di.txt',\"w\")\n",
    "path_nb_di='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/nb_di.txt'\n",
    "\n",
    "\n",
    "file.write('default_nb_di\\n')\n",
    "for i in default_nb_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_smote_nb_di\\n')\n",
    "for i in fair_smote_nb_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_nb_di\\n')\n",
    "for i in fair_preprocessor_nb_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_mask_nb_di\\n')\n",
    "for i in fair_mask_nb_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('reweigh_nb_di\\n')\n",
    "for i in reweigh_nb_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('tdd_nb_di\\n')\n",
    "for i in tdd_nb_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7918224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac2436b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scott-knott Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2143f7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08776e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------Random Forest Start-----------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d7694b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   1 , fair_mask_rf_recall ,    0.87   , 0.04 (  -------   * -|------        ), 0.84,  0.87,  0.88,  0.89,  0.92\n",
      "   1 , reweigh_rf_recall ,    0.88   , 0.02 (           --* |     ----     ), 0.88,  0.88,  0.89,  0.92,  0.93\n",
      "   1 , fair_smote_rf_recall ,    0.89   , 0.03 (         ---  *|      --      ), 0.87,  0.88,  0.89,  0.92,  0.93\n",
      "   1 , fair_generate_rf_recall ,    0.89   , 0.02 (         ---  *|      --      ), 0.87,  0.88,  0.89,  0.92,  0.93\n",
      "   1 , default_rf_recall ,    0.89   , 0.03 (              *|     ---      ), 0.88,  0.88,  0.89,  0.92,  0.93\n",
      "   1 , tdd_rf_recall ,    0.9   , 0.02 (          ---- |*    ----     ), 0.87,  0.89,  0.90,  0.92,  0.93\n"
     ]
    }
   ],
   "source": [
    "cat $path_rf_recall | python2 Stats.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9e931c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   1 , fair_mask_rf_precision ,    0.86   , 0.02 (  --* -----    |              ), 0.85,  0.86,  0.86,  0.87,  0.89\n",
      "   2 , fair_generate_rf_precision ,    0.94   , 0.01 (               |  --  *  --   ), 0.92,  0.93,  0.94,  0.95,  0.96\n",
      "   2 , fair_smote_rf_precision ,    0.94   , 0.03 (               |  --  *  --   ), 0.92,  0.93,  0.94,  0.95,  0.96\n",
      "   2 , default_rf_precision ,    0.93   , 0.02 (               |  --   *  -   ), 0.92,  0.93,  0.94,  0.96,  0.96\n",
      "   2 , tdd_rf_precision ,    0.93   , 0.02 (               | ----  *-     ), 0.92,  0.93,  0.94,  0.95,  0.95\n",
      "   2 , reweigh_rf_precision ,    0.93   , 0.02 (               |  --   *--    ), 0.92,  0.93,  0.94,  0.95,  0.96\n"
     ]
    }
   ],
   "source": [
    "cat $path_rf_precision | python2 Stats.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f866e127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   1 , fair_mask_rf_accuracy ,    0.87   , 0.03 (         *  ---|              ), 0.85,  0.85,  0.88,  0.89,  0.90\n",
      "   2 , reweigh_rf_accuracy ,    0.92   , 0.01 (               |  --*   --    ), 0.91,  0.92,  0.92,  0.93,  0.94\n",
      "   2 , fair_generate_rf_accuracy ,    0.92   , 0.01 (               |  ---*        ), 0.91,  0.92,  0.92,  0.94,  0.94\n",
      "   2 , fair_smote_rf_accuracy ,    0.92   ,  0.0 (               |     *-----   ), 0.92,  0.92,  0.92,  0.92,  0.94\n",
      "   2 , default_rf_accuracy ,    0.92   ,  0.0 (               |------* --    ), 0.90,  0.92,  0.92,  0.93,  0.94\n",
      "   2 , tdd_rf_accuracy ,    0.92   ,  0.0 (               |  --  * ----  ), 0.91,  0.92,  0.92,  0.93,  0.94\n"
     ]
    }
   ],
   "source": [
    "cat $path_rf_accuracy | python2 Stats.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6d46890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   1 , fair_mask_rf_f1score ,    0.86   , 0.02 (  ---   *      |              ), 0.85,  0.86,  0.87,  0.89,  0.89\n",
      "   2 , reweigh_rf_f1score ,    0.91   , 0.01 (               |  - * -       ), 0.91,  0.91,  0.92,  0.92,  0.93\n",
      "   2 , tdd_rf_f1score ,    0.92   , 0.01 (               |  - *  ---    ), 0.91,  0.91,  0.92,  0.93,  0.94\n",
      "   2 , default_rf_f1score ,    0.92   , 0.01 (               |---- * -      ), 0.90,  0.92,  0.92,  0.93,  0.93\n",
      "   2 , fair_smote_rf_f1score ,    0.92   , 0.01 (               |     *----    ), 0.91,  0.91,  0.92,  0.92,  0.94\n",
      "   2 , fair_generate_rf_f1score ,    0.91   , 0.01 (               |--   *  --    ), 0.90,  0.91,  0.92,  0.93,  0.94\n"
     ]
    }
   ],
   "source": [
    "cat $path_rf_f1score | python2 Stats.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ca9c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec415659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   1 , fair_smote_rf_far ,    0.05   ,  0.0 (  ---* ----    |              ), 0.04,  0.05,  0.05,  0.06,  0.08\n",
      "   1 , fair_generate_rf_far ,    0.05   ,  0.0 (  ---* ----    |              ), 0.04,  0.05,  0.05,  0.06,  0.08\n",
      "   1 , default_rf_far ,    0.05   , 0.02 (  -  * ---     |              ), 0.04,  0.04,  0.05,  0.06,  0.08\n",
      "   1 , reweigh_rf_far ,    0.05   , 0.01 (  ---*---      |              ), 0.04,  0.05,  0.05,  0.06,  0.07\n",
      "   1 ,   tdd_rf_far ,    0.05   , 0.01 (    -* --      |              ), 0.05,  0.05,  0.05,  0.06,  0.07\n",
      "   2 , fair_mask_rf_far ,    0.12   , 0.03 (             --|---  * ----   ), 0.09,  0.12,  0.13,  0.14,  0.16\n"
     ]
    }
   ],
   "source": [
    "cat $path_rf_far | python2 Stats.py \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "30e1c112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   1 , fair_smote_rf_aod ,    0.02   , 0.02 (--   *    -----|              ), 0.00,  0.01,  0.02,  0.04,  0.06\n",
      "   1 , fair_mask_rf_aod ,    0.02   , 0.02 (     * -----   |              ), 0.01,  0.01,  0.02,  0.03,  0.05\n",
      "   1 ,   tdd_rf_aod ,    0.02   , 0.02 ( -    *  ------|--            ), 0.00,  0.01,  0.02,  0.04,  0.07\n",
      "   1 , default_rf_aod ,    0.02   , 0.02 ( --   * -------|              ), 0.01,  0.02,  0.02,  0.03,  0.06\n",
      "   1 , reweigh_rf_aod ,    0.02   , 0.01 (      * ----   |              ), 0.02,  0.02,  0.03,  0.03,  0.05\n",
      "   1 , fair_generate_rf_aod ,    0.02   , 0.04 (--     *    ---|              ), 0.00,  0.01,  0.03,  0.05,  0.06\n"
     ]
    }
   ],
   "source": [
    "cat $path_rf_aod | python2 Stats.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dfec309d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   1 , reweigh_rf_eod ,    0.03   , 0.02 (   -  *  ------|              ), 0.02,  0.03,  0.04,  0.06,  0.10\n",
      "   1 ,   tdd_rf_eod ,    0.05   , 0.03 (------ *   ----|--            ), 0.01,  0.04,  0.05,  0.08,  0.12\n",
      "   1 , default_rf_eod ,    0.05   , 0.02 (    -- *-------|---           ), 0.03,  0.04,  0.05,  0.06,  0.13\n",
      "   1 , fair_smote_rf_eod ,    0.05   , 0.02 (    -- * ------|--            ), 0.03,  0.04,  0.05,  0.06,  0.12\n",
      "   1 , fair_mask_rf_eod ,    0.05   , 0.01 (       * ---   |              ), 0.04,  0.04,  0.05,  0.06,  0.08\n",
      "   1 , fair_generate_rf_eod ,    0.05   , 0.02 (    -- * ------|--            ), 0.03,  0.04,  0.05,  0.06,  0.12\n"
     ]
    }
   ],
   "source": [
    "cat $path_rf_eod | python2 Stats.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57f257a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   1 , fair_mask_rf_spd ,    0.03   , 0.04 ( --    * ------|              ), 0.01,  0.02,  0.04,  0.05,  0.08\n",
      "   1 , default_rf_spd ,    0.03   , 0.06 ( ---      *    |  ---         ), 0.01,  0.02,  0.06,  0.10,  0.11\n",
      "   1 , fair_smote_rf_spd ,    0.04   , 0.07 ( --        *   |  --          ), 0.01,  0.02,  0.06,  0.10,  0.11\n",
      "   1 , reweigh_rf_spd ,    0.05   , 0.07 ( ----        * | --------     ), 0.01,  0.03,  0.07,  0.09,  0.13\n",
      "   1 ,   tdd_rf_spd ,    0.04   , 0.07 (             * |              ), 0.01,  0.01,  0.07,  0.12,  0.12\n",
      "   1 , fair_generate_rf_spd ,    0.04   , 0.09 ( --            |* ------      ), 0.01,  0.02,  0.09,  0.10,  0.13\n"
     ]
    }
   ],
   "source": [
    "cat $path_rf_spd | python2 Stats.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9dea53e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   1 , fair_mask_rf_di ,    0.05   , 0.08 ( --    *-----  |              ), 0.02,  0.05,  0.10,  0.11,  0.18\n",
      "   1 , default_rf_di ,    0.05   , 0.16 ( --      *     |  --          ), 0.02,  0.05,  0.12,  0.25,  0.28\n",
      "   1 , fair_smote_rf_di ,    0.08   , 0.18 (---       *    | ---          ), 0.01,  0.05,  0.14,  0.23,  0.28\n",
      "   1 , reweigh_rf_di ,    0.1   , 0.18 ( ---       *   | ------       ), 0.02,  0.06,  0.16,  0.24,  0.32\n",
      "   1 ,    tdd_rf_di ,    0.08   , 0.17 (            *  |              ), 0.01,  0.02,  0.17,  0.31,  0.32\n",
      "   1 , fair_generate_rf_di ,    0.08   , 0.22 (---            | *------      ), 0.01,  0.05,  0.23,  0.24,  0.33\n"
     ]
    }
   ],
   "source": [
    "cat $path_rf_di | python2 Stats.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10077c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8b052648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Standard Learner : Random Forest : Recall------------------------\n",
      "-----------------------Standard Learner : Random Forest : False Alarm------------------------\n",
      "-----------------------Standard Learner : Random Forest : Precision------------------------\n",
      "-----------------------Standard Learner : Random Forest : Accuracy------------------------\n",
      "-----------------------Standard Learner : Random Forest : F1Score------------------------\n",
      "-----------------------Standard Learner : Random Forest : AOD------------------------\n",
      "-----------------------Standard Learner : Random Forest : EOD------------------------\n",
      "-----------------------Standard Learner : Random Forest : SPD------------------------\n",
      "-----------------------Standard Learner : Random Forest : DI------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"-----------------------Standard Learner : Random Forest : Recall------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_rf_recall']=fair_preprocessor_rf_recall\n",
    "value['smote_rf_recall']=smote_rf_recall\n",
    "value['default_rf_recall']=default_rf_recall\n",
    "value['rus_rf_recall']=rus_rf_recall\n",
    "value['ros_rf_recall']=ros_rf_recall\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/sl_rf_recall.txt',\"w\")\n",
    "path_rf_recall='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/sl_rf_recall.txt'\n",
    "\n",
    "file.write('default_rf_recall\\n')\n",
    "for i in default_rf_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('smote_rf_recall\\n')\n",
    "for i in smote_rf_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_rf_recall\\n')\n",
    "for i in fair_preprocessor_rf_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('rus_rf_recall\\n')\n",
    "for i in rus_rf_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('ros_rf_recall\\n')\n",
    "for i in ros_rf_recall:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Standard Learner : Random Forest : False Alarm------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_rf_far']=fair_preprocessor_rf_far\n",
    "value['smote_rf_far']=smote_rf_far\n",
    "value['default_rf_far']=default_rf_far\n",
    "value['rus_rf_far']=rus_rf_far\n",
    "value['ros_rf_far']=ros_rf_far\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/sl_rf_far.txt',\"w\")\n",
    "path_rf_far='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/sl_rf_far.txt'\n",
    "\n",
    "file.write('default_rf_far\\n')\n",
    "for i in default_rf_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('smote_rf_far\\n')\n",
    "for i in smote_rf_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_rf_far\\n')\n",
    "for i in fair_preprocessor_rf_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('rus_rf_far\\n')\n",
    "for i in rus_rf_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('ros_rf_far\\n')\n",
    "for i in ros_rf_far:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Standard Learner : Random Forest : Precision------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_rf_precision']=fair_preprocessor_rf_precision\n",
    "value['smote_rf_precision']=smote_rf_precision\n",
    "value['default_rf_precision']=default_rf_precision\n",
    "value['rus_rf_precision']=rus_rf_precision\n",
    "value['ros_rf_precision']=ros_rf_precision\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/sl_rf_precision.txt',\"w\")\n",
    "path_rf_precision='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/sl_rf_precision.txt'\n",
    "\n",
    "file.write('default_rf_precision\\n')\n",
    "for i in default_rf_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('smote_rf_precision\\n')\n",
    "for i in smote_rf_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_rf_precision\\n')\n",
    "for i in fair_preprocessor_rf_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('rus_rf_precision\\n')\n",
    "for i in rus_rf_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('ros_rf_precision\\n')\n",
    "for i in ros_rf_precision:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Standard Learner : Random Forest : Accuracy------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_rf_accuracy']=fair_preprocessor_rf_accuracy\n",
    "value['smote_rf_accuracy']=smote_rf_accuracy\n",
    "value['default_rf_accuracy']=default_rf_accuracy\n",
    "value['rus_rf_accuracy']=rus_rf_accuracy\n",
    "value['ros_rf_accuracy']=ros_rf_accuracy\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/sl_rf_accuracy.txt',\"w\")\n",
    "path_rf_accuracy='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/sl_rf_accuracy.txt'\n",
    "\n",
    "file.write('default_rf_accuracy\\n')\n",
    "for i in default_rf_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('smote_rf_accuracy\\n')\n",
    "for i in smote_rf_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_rf_accuracy\\n')\n",
    "for i in fair_preprocessor_rf_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('rus_rf_accuracy\\n')\n",
    "for i in rus_rf_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('ros_rf_accuracy\\n')\n",
    "for i in ros_rf_accuracy:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Standard Learner : Random Forest : F1Score------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_rf_f1score']=fair_preprocessor_rf_f1score\n",
    "value['smote_rf_f1score']=smote_rf_f1score\n",
    "value['default_rf_f1score']=default_rf_f1score\n",
    "value['rus_rf_f1score']=rus_rf_f1score\n",
    "value['ros_rf_f1score']=ros_rf_f1score\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/sl_rf_f1score.txt',\"w\")\n",
    "path_rf_f1score='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/sl_rf_f1score.txt'\n",
    "\n",
    "\n",
    "file.write('default_rf_f1score\\n')\n",
    "for i in default_rf_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('smote_rf_f1score\\n')\n",
    "for i in smote_rf_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_rf_f1score\\n')\n",
    "for i in fair_preprocessor_rf_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('rus_rf_f1score\\n')\n",
    "for i in rus_rf_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('ros_rf_f1score\\n')\n",
    "for i in ros_rf_f1score:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Standard Learner : Random Forest : AOD------------------------\")\n",
    "value=pd.DataFrame()\n",
    "\n",
    "\n",
    "fair_preprocessor_rf_aod=np.abs(fair_preprocessor_rf_aod)\n",
    "smote_rf_aod=np.abs(smote_rf_aod)\n",
    "default_rf_aod=np.abs(default_rf_aod)\n",
    "rus_rf_aod=np.abs(rus_rf_aod)\n",
    "\n",
    "value['fair_preprocessor_rf_aod']=fair_preprocessor_rf_aod\n",
    "value['smote_rf_aod']=smote_rf_aod\n",
    "value['default_rf_aod']=default_rf_aod\n",
    "value['rus_rf_aod']=rus_rf_aod\n",
    "value['ros_rf_aod']=ros_rf_aod\n",
    "\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/sl_rf_aod.txt',\"w\")\n",
    "path_rf_aod='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/sl_rf_aod.txt'\n",
    "\n",
    "\n",
    "file.write('default_rf_aod\\n')\n",
    "for i in default_rf_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('smote_rf_aod\\n')\n",
    "for i in smote_rf_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_rf_aod\\n')\n",
    "for i in fair_preprocessor_rf_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('rus_rf_aod\\n')\n",
    "for i in rus_rf_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('ros_rf_aod\\n')\n",
    "for i in ros_rf_aod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Standard Learner : Random Forest : EOD------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "\n",
    "fair_preprocessor_rf_eod=np.abs(fair_preprocessor_rf_eod)\n",
    "smote_rf_eod=np.abs(smote_rf_eod)\n",
    "default_rf_eod=np.abs(default_rf_eod)\n",
    "rus_rf_eod=np.abs(rus_rf_eod)\n",
    "\n",
    "value['fair_preprocessor_rf_eod']=fair_preprocessor_rf_eod\n",
    "value['smote_rf_eod']=smote_rf_eod\n",
    "value['default_rf_eod']=default_rf_eod\n",
    "value['rus_rf_eod']=rus_rf_eod\n",
    "value['ros_rf_eod']=ros_rf_eod\n",
    "\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/sl_rf_eod.txt',\"w\")\n",
    "path_rf_eod='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/sl_rf_eod.txt'\n",
    "\n",
    "\n",
    "file.write('default_rf_eod\\n')\n",
    "for i in default_rf_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('smote_rf_eod\\n')\n",
    "for i in smote_rf_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_rf_eod\\n')\n",
    "for i in fair_preprocessor_rf_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('rus_rf_eod\\n')\n",
    "for i in rus_rf_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('ros_rf_eod\\n')\n",
    "for i in ros_rf_eod:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "\n",
    "print(\"-----------------------Standard Learner : Random Forest : SPD------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "value['fair_preprocessor_rf_spd']=fair_preprocessor_rf_spd\n",
    "value['smote_rf_spd']=smote_rf_spd\n",
    "value['default_rf_spd']=default_rf_spd\n",
    "value['rus_rf_spd']=rus_rf_spd\n",
    "value['ros_rf_spd']=ros_rf_spd\n",
    "\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/sl_rf_spd.txt',\"w\")\n",
    "path_rf_spd='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/sl_rf_spd.txt'\n",
    "\n",
    "\n",
    "file.write('default_rf_spd\\n')\n",
    "for i in default_rf_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('smote_rf_spd\\n')\n",
    "for i in smote_rf_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_rf_spd\\n')\n",
    "for i in fair_preprocessor_rf_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('rus_rf_spd\\n')\n",
    "for i in rus_rf_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('ros_rf_spd\\n')\n",
    "for i in ros_rf_spd:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(\"-----------------------Standard Learner : Random Forest : DI------------------------\")\n",
    "\n",
    "value=pd.DataFrame()\n",
    "\n",
    "fair_preprocessor_rf_di=np.abs(fair_preprocessor_rf_di)\n",
    "smote_rf_di=np.abs(smote_rf_di)\n",
    "default_rf_di=np.abs(default_rf_di)\n",
    "rus_rf_di=np.abs(rus_rf_di)\n",
    "\n",
    "value['fair_preprocessor_rf_di']=fair_preprocessor_rf_di\n",
    "value['smote_rf_di']=smote_rf_di\n",
    "value['default_rf_di']=default_rf_di\n",
    "value['rus_rf_di']=rus_rf_di\n",
    "value['ros_rf_di']=ros_rf_di\n",
    "\n",
    "\n",
    "file = open('StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/sl_rf_di.txt',\"w\")\n",
    "path_rf_di='StatisticalTest/'+folder_name+'/'+str(time_stamp)+'/sl_rf_di.txt'\n",
    "\n",
    "\n",
    "file.write('default_rf_di\\n')\n",
    "for i in default_rf_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('smote_rf_di\\n')\n",
    "for i in smote_rf_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('fair_preprocessor_rf_di\\n')\n",
    "for i in fair_preprocessor_rf_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('rus_rf_di\\n')\n",
    "for i in rus_rf_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.write('ros_rf_di\\n')\n",
    "for i in ros_rf_di:\n",
    "    file.write(str(i)+\"  \")\n",
    "file.write(\"\\n\\n\")\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "57c239c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   1 , rus_rf_recall ,    0.88   , 0.05 (--   *         | ----         ), 0.87,  0.88,  0.89,  0.92,  0.93\n",
      "   1 , fair_generate_rf_recall ,    0.89   , 0.02 (---    *       |  ---         ), 0.87,  0.88,  0.89,  0.92,  0.93\n",
      "   1 , default_rf_recall ,    0.89   , 0.03 (    -  *       | -----        ), 0.88,  0.88,  0.89,  0.92,  0.93\n",
      "   1 , smote_rf_recall ,    0.89   , 0.04 (    -    *     |     --       ), 0.88,  0.89,  0.90,  0.93,  0.93\n",
      "   1 , ros_rf_recall ,    0.89   , 0.02 (    -    *     |------        ), 0.88,  0.89,  0.90,  0.91,  0.93\n"
     ]
    }
   ],
   "source": [
    "cat $path_rf_recall | python2 Stats.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c845ee47-a427-4712-bb9a-4be403d08e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   1 , ros_rf_precision ,    0.93   , 0.01 (         -   * |    ----      ), 0.92,  0.92,  0.93,  0.95,  0.96\n",
      "   1 , fair_generate_rf_precision ,    0.94   , 0.01 (         ----  | *   ----     ), 0.92,  0.93,  0.94,  0.95,  0.96\n",
      "   1 , default_rf_precision ,    0.93   , 0.02 (         ----  |  *     --    ), 0.92,  0.93,  0.94,  0.96,  0.96\n",
      "   1 , rus_rf_precision ,    0.94   , 0.03 (   ------------|   *----      ), 0.90,  0.93,  0.94,  0.95,  0.96\n",
      "   1 , smote_rf_precision ,    0.92   , 0.03 (     ---       |   *----      ), 0.91,  0.92,  0.94,  0.95,  0.96\n"
     ]
    }
   ],
   "source": [
    "cat $path_rf_precision | python2 Stats.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "92a5ba74-0e24-4777-ae2d-e7ef4956887d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   1 , ros_rf_accuracy ,    0.92   , 0.03 (         ------*     --       ), 0.90,  0.92,  0.92,  0.93,  0.94\n",
      "   1 , fair_generate_rf_accuracy ,    0.92   , 0.01 (           ----|*             ), 0.91,  0.92,  0.92,  0.94,  0.94\n",
      "   1 , rus_rf_accuracy ,    0.92   , 0.01 (               |  *  --       ), 0.91,  0.91,  0.92,  0.93,  0.94\n",
      "   1 , default_rf_accuracy ,    0.92   ,  0.0 (         ------|--*  --       ), 0.90,  0.92,  0.92,  0.93,  0.94\n",
      "   1 , smote_rf_accuracy ,    0.92   ,  0.0 (         ------|  *-------    ), 0.90,  0.92,  0.92,  0.92,  0.94\n"
     ]
    }
   ],
   "source": [
    "cat $path_rf_accuracy | python2 Stats.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "98f7d87f-e45c-4e4a-bbe8-84092501b4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   1 , ros_rf_f1score ,    0.91   , 0.02 (        ---    *  ---         ), 0.90,  0.91,  0.92,  0.93,  0.93\n",
      "   1 , smote_rf_f1score ,    0.92   , 0.01 (        ------ *-------       ), 0.90,  0.92,  0.92,  0.92,  0.94\n",
      "   1 , rus_rf_f1score ,    0.91   , 0.01 (         --    *-----         ), 0.91,  0.91,  0.92,  0.92,  0.93\n",
      "   1 , default_rf_f1score ,    0.92   , 0.01 (        ------ |* --          ), 0.90,  0.92,  0.92,  0.93,  0.93\n",
      "   1 , fair_generate_rf_f1score ,    0.91   , 0.01 (       ----    |*   ----      ), 0.90,  0.91,  0.92,  0.93,  0.94\n"
     ]
    }
   ],
   "source": [
    "cat $path_rf_f1score | python2 Stats.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "22f5a41e-9ebc-431d-a7b1-7e428ffe6929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   1 , fair_generate_rf_far ,    0.05   ,  0.0 (     ----*   --|-----         ), 0.04,  0.05,  0.05,  0.06,  0.08\n",
      "   1 , default_rf_far ,    0.05   , 0.02 (    --   *    -|----          ), 0.04,  0.04,  0.05,  0.06,  0.08\n",
      "   1 ,   rus_rf_far ,    0.05   ,  0.0 (    -----  *   |------        ), 0.04,  0.05,  0.05,  0.06,  0.08\n",
      "   1 , smote_rf_far ,    0.05   , 0.02 (     ----  *   | ------       ), 0.04,  0.05,  0.05,  0.07,  0.09\n",
      "   1 ,   ros_rf_far ,    0.06   , 0.01 (     ------  * | ---          ), 0.04,  0.05,  0.06,  0.07,  0.08\n"
     ]
    }
   ],
   "source": [
    "cat $path_rf_far | python2 Stats.py \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032cb6c2-a2c6-4912-92b4-6606b5835237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "79f7fc9a-8300-4a5f-89e3-875b90ad7d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   1 , smote_rf_aod ,    0.02   , 0.01 (  --- *   -----|-             ), 0.01,  0.02,  0.02,  0.03,  0.05\n",
      "   1 , default_rf_aod ,    0.02   , 0.02 (  --   *  -----|---           ), 0.01,  0.02,  0.02,  0.03,  0.06\n",
      "   1 , fair_generate_rf_aod ,    0.02   , 0.04 (---      *     |---           ), 0.00,  0.01,  0.03,  0.05,  0.06\n",
      "   1 ,   rus_rf_aod ,    0.03   , 0.03 (     --   *    |---           ), 0.02,  0.02,  0.03,  0.05,  0.06\n",
      "   1 ,   ros_rf_aod ,    0.03   , 0.02 ( --       *----|---           ), 0.00,  0.01,  0.03,  0.03,  0.06\n"
     ]
    }
   ],
   "source": [
    "cat $path_rf_aod | python2 Stats.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ff3e4a21-5596-47c8-947d-7dd95d6d5827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   1 ,   rus_rf_eod ,    0.03   , 0.02 (   -  * -------|---           ), 0.02,  0.03,  0.04,  0.05,  0.13\n",
      "   1 , smote_rf_eod ,    0.05   , 0.03 (    -- *   ----|              ), 0.03,  0.04,  0.05,  0.08,  0.10\n",
      "   1 , default_rf_eod ,    0.05   , 0.02 (    -- *-------|---           ), 0.03,  0.04,  0.05,  0.06,  0.13\n",
      "   1 , fair_generate_rf_eod ,    0.05   , 0.02 (    -- * ------|--            ), 0.03,  0.04,  0.05,  0.06,  0.12\n",
      "   1 ,   ros_rf_eod ,    0.05   , 0.02 (    --- *  ----|---           ), 0.03,  0.05,  0.06,  0.08,  0.13\n"
     ]
    }
   ],
   "source": [
    "cat $path_rf_eod | python2 Stats.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6fafaf90-b36d-4782-8a8c-641ae568bb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   1 , default_rf_spd ,    0.03   , 0.06 ( ---      *    |  ---         ), 0.01,  0.02,  0.06,  0.10,  0.11\n",
      "   1 , smote_rf_spd ,    0.04   , 0.07 ( -          *  |------        ), 0.01,  0.02,  0.07,  0.08,  0.12\n",
      "   1 ,   rus_rf_spd ,    0.02   , 0.07 (  --           *  ---         ), 0.01,  0.02,  0.08,  0.10,  0.11\n",
      "   1 ,   ros_rf_spd ,    0.04   , 0.06 ( -----         *-------       ), 0.01,  0.03,  0.08,  0.08,  0.12\n",
      "   1 , fair_generate_rf_spd ,    0.04   , 0.09 ( --            |* ------      ), 0.01,  0.02,  0.09,  0.10,  0.13\n"
     ]
    }
   ],
   "source": [
    "cat $path_rf_spd | python2 Stats.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4e51c34c-4181-4467-88ba-f8ed7e82491d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   1 , default_rf_di ,    0.05   , 0.16 ( --      *     |  --          ), 0.02,  0.05,  0.12,  0.25,  0.28\n",
      "   1 ,  smote_rf_di ,    0.08   , 0.17 ( -        *   -|----          ), 0.02,  0.04,  0.15,  0.20,  0.28\n",
      "   1 ,    ros_rf_di ,    0.08   , 0.16 ( ----        * |-------       ), 0.02,  0.07,  0.19,  0.21,  0.31\n",
      "   1 ,    rus_rf_di ,    0.05   , 0.18 ( --           *| ----         ), 0.02,  0.04,  0.20,  0.24,  0.29\n",
      "   1 , fair_generate_rf_di ,    0.08   , 0.22 (---            | *------      ), 0.01,  0.05,  0.23,  0.24,  0.33\n"
     ]
    }
   ],
   "source": [
    "cat $path_rf_di | python2 Stats.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
